{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20240111 Changes to make: \n",
    "\n",
    "- Stream not attributed with CDW in LP: select streams that are adjacent/share a segment with CDW habitat. \n",
    "\n",
    "- The Canals and Raceways layer should be used to identify canals and mark them as unregulated in extra column.   maybe we just provide all ditches and canals (unless we can sort out the “canals”) with 50 ft riparian zones and note in the meta data that field conditions would dictate whether or not such features are regulated waters. \n",
    "\n",
    "- C1 upstream segments were not clipped at HUC14 boundary.   \n",
    "\n",
    "- Buffers on polygons not transitioning correctly between buffer sizes\n",
    "\n",
    "- Check problem areas Larry identified  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy, os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set paths\n",
    "home = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\RiparianZones_20240109.gdb\"\n",
    "newgdb = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Revision_20230809.gdb\"\n",
    "scratch1 = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\scratch1.gdb\"\n",
    "#scratch = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\scratch.gdb'\n",
    "lscratch = r'Q:\\WatershedNJ_KD\\local_scratch.gdb'\n",
    "background = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\Riparian_Zone_Input_Layers.gdb\"\n",
    "blayers = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\Riparian_Zone_Input_Layers.gdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def split_by_lines()\n",
    "#def classify_split_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete file function\n",
    "#Delete field function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split lines by a polygon and make a new field to code polygon overlap\n",
    "# Default if within is NO\n",
    "def split_by_polygon_zero(input_lines, splitting_polygon, field_name, output):\n",
    "    split_pts = arcpy.analysis.Intersect([input_lines, splitting_polygon], os.path.join(scratch1,\"temp_split_pts\"), output_type = 'POINT')\n",
    "    arcpy.management.SplitLineAtPoint(input_lines, split_pts, output, \"5 feet\")\n",
    "    if len(arcpy.ListFields(output, field_name)) == 0:\n",
    "         arcpy.AddField_management(output, field_name, \"SHORT\")\n",
    "    else:\n",
    "        print(\"Field exists\")\n",
    "    \n",
    "    #Select lines to recode upstream field\n",
    "    selection = arcpy.analysis.Intersect([output, splitting_polygon], os.path.join(scratch1, \"streams_to_update_Intersect\"), \"ONLY_FID\", None, \"LINE\")\n",
    "    \n",
    "    #Make a list from the selected features\n",
    "    filename = arcpy.Describe(output).file\n",
    "    list_field = f\"FID_{filename}\"\n",
    "    oidList = [oid[0] for oid in arcpy.da.SearchCursor(selection,[list_field])]\n",
    "    oidfield = arcpy.Describe(output).OIDFieldName\n",
    "    fields = [oidfield, field_name]\n",
    "    \n",
    "    #Code features in the list \n",
    "    with arcpy.da.UpdateCursor(output, fields) as curs:\n",
    "        for row in curs:\n",
    "            if row[0] in oidList: \n",
    "                row[1] = 0\n",
    "            else:\n",
    "                row[1] = 1\n",
    "            curs.updateRow(row)\n",
    "    del curs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split lines by a polygon and make a new field to code polygon overlap\n",
    "# Default if within is Yes\n",
    "def split_by_polygon_one(input_lines, splitting_polygon, field_name, output):\n",
    "    split_pts = arcpy.analysis.Intersect([input_lines, splitting_polygon], os.path.join(scratch1,\"temp_split_pts\"), output_type = 'POINT')\n",
    "    arcpy.management.SplitLineAtPoint(input_lines, split_pts, output, \"5 feet\")\n",
    "    if len(arcpy.ListFields(output, field_name)) == 0:\n",
    "         arcpy.AddField_management(output, field_name, \"SHORT\")\n",
    "    else:\n",
    "        print(\"Field exists\")\n",
    "    \n",
    "    #Select lines to recode upstream field\n",
    "    selection = arcpy.analysis.Intersect([output, splitting_polygon], os.path.join(scratch1, \"streams_to_update_Intersect\"), \"ONLY_FID\", None, \"LINE\")\n",
    "    \n",
    "    #Make a list from the selected features\n",
    "    filename = arcpy.Describe(output).file\n",
    "    list_field = f\"FID_{filename}\"\n",
    "    oidList = [oid[0] for oid in arcpy.da.SearchCursor(selection,[list_field])]\n",
    "    oidfield = arcpy.Describe(output).OIDFieldName\n",
    "    fields = [oidfield, field_name]\n",
    "    \n",
    "    #Code features in the list \n",
    "    with arcpy.da.UpdateCursor(output, fields) as curs:\n",
    "        for row in curs:\n",
    "            if row[0] in oidList: \n",
    "                row[1] = 1\n",
    "            else:\n",
    "                row[1] = 0\n",
    "            curs.updateRow(row)\n",
    "    del curs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for reordering fields\n",
    "\n",
    "def reorderfields(messy_input_file, out_path, out_name, new_field_order):\n",
    "    import numpy\n",
    "    arr = arcpy.da.TableToNumPyArray(messy_input_file, \n",
    "                                 new_field_order, \n",
    "                                 skip_nulls = False)\n",
    "    \n",
    "    #Copying messy file but just keeping OIDs and required fields. Probably better ways to do this\n",
    "    #Could use another ID field instead of OID\n",
    "    fieldmappings = arcpy.FieldMappings()\n",
    "\n",
    "    # Add all fields from inputs.\n",
    "    fieldmappings.addTable(messy_input_file)\n",
    "\n",
    "    # Name fields you want. Could get these names programmatically too.\n",
    "    oidfield = arcpy.Describe(messy_input_file).OIDFieldName\n",
    "    keepers = [oidfield]\n",
    "\n",
    "    # Remove all output fields you don't want.\n",
    "    for field in fieldmappings.fields:\n",
    "        if field.name not in keepers:\n",
    "            fieldmappings.removeFieldMap(fieldmappings.findFieldMapIndex(field.name))\n",
    "\n",
    "    #Copy your file using the field mapping to select OBJECTID only. This is the destination to join the reordered columns to\n",
    "    arcpy.conversion.FeatureClassToFeatureClass(messy_input_file, \n",
    "                                                out_path, \n",
    "                                                out_name,\n",
    "                                                field_mapping = fieldmappings\n",
    "                                               )\n",
    "    #Join the sorted columns array back to your stripped down copy\n",
    "    arcpy.da.ExtendTable(os.path.join(out_path, out_name), \n",
    "                         table_match_field = oidfield, \n",
    "                         in_array = arr, \n",
    "                         array_match_field = \"OBJECTID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Optional settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arcpy.env.addOutputsToMap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Clear project history to speed up performance\n",
    "from arcpy import metadata as md\n",
    "\n",
    "# Get the target item's Metadata object\n",
    "arcpy.env.workspace = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\scratch.gdb'\n",
    "scratch_files = [x for x in arcpy.ListFeatureClasses()]\n",
    "\n",
    "for fc in scratch_files:\n",
    "    tgt_item_md = md.Metadata(fc)\n",
    "    tgt_item_md.deleteContent('GPHISTORY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Import data and identify regulated segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Feature classes of interest. Ideally link a webservice feature here to automate. \n",
    "\n",
    "#Landscape project critically dependent on watersource polygons\n",
    "ani_polys = os.path.join(home, \"CDW_all_regions\")\n",
    "\n",
    "#Landscape project mussel streams\n",
    "ani_streams = r'X:\\projects\\njwrap\\Data\\NJDEP\\Landscape3-3\\Mussel_streams_v3_3.gdb\\Envr_hab_ls_v3_3_streamhabitat'\n",
    "\n",
    "#Natural heritage program rare plants streams and waterbodies\n",
    "plant_polys = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Streams_from_Larry_Torok\\CDW_Plant_waterbodies.shp'\n",
    "plant_streams = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Streams_from_Larry_Torok\\CDW_plant_streams.shp'\n",
    "\n",
    "# State HUC 14s\n",
    "huc14s = r'X:\\projects\\njwrap\\Data\\NJDEP\\Hydr_HUC14_bnd\\Hydr_HUC14_bnd.gdb\\Hydr_HUC14_bnd'\n",
    "\n",
    "# NJ 2015 NHD streams\n",
    "nj2015 = os.path.join(home, \"nj2015\")\n",
    "\n",
    "# NJ 2015 NHD waterbodies\n",
    "nj2015_polys = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\Hydr_NHD_2015_waterbody'\n",
    "\n",
    "#NJ 2015 LULC for wetlands\n",
    "nj2020_lulc = arcpy.management.MakeFeatureLayer(r\"https://services1.arcgis.com/QWdNfRs7lkPq4g4Q/arcgis/rest/services/Land_Use_2020/FeatureServer/5\", \"lulc2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nhd 2015 copy exists\n"
     ]
    }
   ],
   "source": [
    "# NJ 2015 NHD streams\n",
    "if arcpy.Exists(os.path.join(home, \"nj2015\")):\n",
    "    print(\"nhd 2015 copy exists\")\n",
    "    nj2015 = os.path.join(home, \"nj2015\")\n",
    "else:\n",
    "    print(\"Copying nhd 2015\")\n",
    "    nj2015_streams = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\Hydr_NHD_2015_streams'\n",
    "    #Copy flowlines out of the topology so that it can be more easily manipulated\n",
    "    arcpy.management.CopyFeatures(nj2015_streams, os.path.join(home, \"nj2015\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LP all exists\n"
     ]
    }
   ],
   "source": [
    "#E&T species critically dependent on the watercourse, from Landscape Project\n",
    "if arcpy.Exists(os.path.join(home, \"CDW_all_regions\")):\n",
    "    print(\"LP all exists\")\n",
    "    ani_polys = os.path.join(home, \"CDW_all_regions\")\n",
    "else: \n",
    "    print(\"Run the following Landscape Project CDW polygons code\")                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swqs aligned exists\n"
     ]
    }
   ],
   "source": [
    "#Align swqs streams to nhd streams\n",
    "if arcpy.Exists(r\"X:\\projects\\njwrap\\Data\\NJDEP\\NJ_surface_water_categories\\Hydr_water_stream_swqs.gdb\\Hydr_water_stream_swqs_aligned\"):\n",
    "    print(\"swqs aligned exists\")\n",
    "    swqs = r\"X:\\projects\\njwrap\\Data\\NJDEP\\NJ_surface_water_categories\\Hydr_water_stream_swqs.gdb\\Hydr_water_stream_swqs_aligned\"\n",
    "else: \n",
    "    print(\"swqs needs to be aligned\")\n",
    "    swqs1 = r'X:\\projects\\njwrap\\Data\\NJDEP\\NJ_surface_water_categories\\Hydr_water_stream_swqs.gdb\\Hydr_water_stream_swqs'\n",
    "    arcpy.edit.AlignFeatures(\n",
    "        in_features= swqs1,\n",
    "        target_features= nj2015,\n",
    "        search_distance= \"60 Feet\",\n",
    "        match_fields=None\n",
    "    ) #1 hour 45 min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Landscape Project CDW polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if arcpy.Exists(os.path.join(newgdb, 'Landscape_proj_all_cdw')):\n",
    "    print(\"LP all exists\")\n",
    " \n",
    "#Assemble Landscape Project data stored in separate gdbs (probably could have done a dictionary)\n",
    "arcpy.env.workspace = r'X:\\projects\\njwrap\\Data\\NJDEP\\Landscape3-3\\Region_data'\n",
    "\n",
    "# List all file geodatabases in the current workspace\n",
    "lp_gdbs = arcpy.ListWorkspaces(\"*\", \"FileGDB\")  \n",
    "\n",
    "lp_list = []\n",
    "for lp in lp_gdbs:\n",
    "    arcpy.env.workspace = lp\n",
    "    for fc in arcpy.ListFeatureClasses('E*'):\n",
    "        fc_path = os.path.join(arcpy.env.workspace, fc)\n",
    "        print(fc_path)\n",
    "        lp_list.append(fc_path)\n",
    "\n",
    "lp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Assemble Landscape Project data stored in separate gdbs (probably could have done a dictionary)\n",
    "#https://community.esri.com/t5/arcgis-pro-questions/arcgis-pro-join-one-to-many-join-by-attribute/td-p/589401/page/2\n",
    "arcpy.env.workspace = r'X:\\projects\\njwrap\\Data\\NJDEP\\Landscape3-3\\Region_data'\n",
    "\n",
    "spnum = 0\n",
    "\n",
    "for lp in lp_gdbs:\n",
    "    arcpy.env.workspace = lp\n",
    "    #copy polygons for permanent join\n",
    "    for fc in arcpy.ListFeatureClasses('E*'):\n",
    "        fc_path = os.path.join(arcpy.env.workspace, fc)\n",
    "        fc_copy = arcpy.management.CopyFeatures(fc_path, \"fc_copy\")\n",
    "    for tbl in arcpy.ListTables('*_sp*'):\n",
    "        tbl_path = os.path.join(arcpy.env.workspace, tbl)\n",
    "    # list the polygon feature class and table that want to be joined\n",
    "    tableList = [fc_copy, tbl_path]\n",
    "    # define the query for matching\n",
    "    whereclause = f\"fc_copy.LINKID = {tbl}.LINKID\"\n",
    "    # name the temporary layer name created by MakeQueryTable\n",
    "    lyrName = \"sp_layer\"\n",
    "    # name the output fc name\n",
    "    region_name = lp_list[spnum].split(\"_\")[-1]\n",
    "    print(region_name)\n",
    "    out_FeatureClass = os.path.join(scratch, f\"Envr_hab_ls_v3_3_{region_name}_sp\")\n",
    "    print(out_FeatureClass)   \n",
    "    arcpy.MakeQueryTable_management(tableList, lyrName,\"USE_KEY_FIELDS\", \"\", \"\", whereclause)\n",
    "    arcpy.CopyFeatures_management(lyrName, out_FeatureClass)\n",
    "    if spnum == 0:\n",
    "        LP_all = arcpy.management.CreateFeatureclass(out_path = newgdb, out_name = 'Landscape_proj_all_cdw', geometry_type = 'POLYGON', template = out_FeatureClass, spatial_reference = out_FeatureClass)#empty dataset to store each region data\n",
    "        arcpy.management.Append(out_FeatureClass, LP_all)\n",
    "        spnum += 1\n",
    "        print(lp)\n",
    "        continue\n",
    "    else: \n",
    "        arcpy.management.Append(out_FeatureClass, LP_all)\n",
    "        spnum += 1\n",
    "        print(lp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "LP_all = os.path.join(newgdb, \"Landscape_proj_all_cdw\")\n",
    "LP_sel = arcpy.management.MakeFeatureLayer(LP_all, \"LP_lyr\", where_clause = \"FHA_SCDW = 'Yes'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 12, 2024 9:45:05 AM\",\"Succeeded at Friday, January 12, 2024 9:46:06 AM (Elapsed Time: 1 minutes 1 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'streams'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj2015_polys = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\Hydr_NHD_2015_waterbody'\n",
    "\n",
    "arcpy.management.MakeFeatureLayer(nj2015_polys, \"streams\", where_clause = \"FTYPE_DESCRIPTION ='Stream/River' Or FTYPE_DESCRIPTION = 'Canal/Ditch' \")\n",
    "arcpy.management.SelectLayerByLocation(\"streams\", \"BOUNDARY_TOUCHES\", LP_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 12, 2024 9:46:47 AM\",\"Succeeded at Friday, January 12, 2024 9:46:49 AM (Elapsed Time: 2.25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\ET_streams_DR'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make a feature class of the selected waterbodies.  \n",
    "arcpy.conversion.ExportFeatures(\"streams\", os.path.join(home, \"ET_streams_non_Del\"), where_clause = \"GNIS_NAME <> 'Delaware River'\")\n",
    "arcpy.conversion.ExportFeatures(\"streams\", os.path.join(home, \"ET_streams_DR\"), where_clause = \"GNIS_NAME = 'Delaware River'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 12, 2024 9:48:54 AM\",\"Succeeded at Friday, January 12, 2024 9:48:56 AM (Elapsed Time: 2.30 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\ET_DR_SubdividePolygon'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chop up the polygons that are too long and thus are over-inclusive of stream stretches\n",
    "arcpy.management.SubdividePolygon(\n",
    "    in_polygons =os.path.join(home, \"ET_streams_non_Del\"),\n",
    "    out_feature_class = os.path.join(home, \"ET_non_Del_SubdividePolygon\"),\n",
    "    method=\"NUMBER_OF_EQUAL_PARTS\",\n",
    "    num_areas=10,\n",
    "    target_area=None,\n",
    "    target_width=None,\n",
    "    split_angle=0,\n",
    "    subdivision_type=\"STACKED_BLOCKS\"\n",
    ")\n",
    "\n",
    "arcpy.management.SubdividePolygon(\n",
    "    in_polygons =os.path.join(home, \"ET_streams_DR\"),\n",
    "    out_feature_class = os.path.join(home, \"ET_DR_SubdividePolygon\"),\n",
    "    method=\"NUMBER_OF_EQUAL_PARTS\",\n",
    "    num_areas=25,\n",
    "    target_area=None,\n",
    "    target_width=None,\n",
    "    split_angle=0,\n",
    "    subdivision_type=\"STACKED_BLOCKS\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 12, 2024 9:51:05 AM\",\"Succeeded at Friday, January 12, 2024 9:51:07 AM (Elapsed Time: 2.13 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\ET_DR_MultipartToSinglepart'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MultipartToSinglepart(\n",
    "    in_features= os.path.join(home, \"ET_non_Del_SubdividePolygon\"),\n",
    "    out_feature_class= os.path.join(home, \"ET_nonDel_MultipartToSinglepart\")\n",
    ")\n",
    "\n",
    "arcpy.management.MultipartToSinglepart(\n",
    "    in_features= os.path.join(home, \"ET_DR_SubdividePolygon\"),\n",
    "    out_feature_class= os.path.join(home, \"ET_DR_MultipartToSinglepart\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 12, 2024 9:51:19 AM\",\"Succeeded at Friday, January 12, 2024 9:51:23 AM (Elapsed Time: 3.94 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\ET_s_MultipartToSinglepart'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(home, \"ET_nonDel_MultipartToSinglepart\"), os.path.join(home, \"ET_DR_MultipartToSinglepart\")],\n",
    "                      os.path.join(home, \"ET_s_MultipartToSinglepart\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 12, 2024 9:53:08 AM\",\"Succeeded at Friday, January 12, 2024 9:53:11 AM (Elapsed Time: 3.50 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 's_singlepart'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(os.path.join(home, \"ET_s_MultipartToSinglepart\"), \"s_singlepart\")\n",
    "arcpy.management.SelectLayerByLocation(\"s_singlepart\", \"INTERSECT\", LP_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 12, 2024 9:55:15 AM\",\"Succeeded at Friday, January 12, 2024 9:55:18 AM (Elapsed Time: 3.34 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\s_selection'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(\"s_singlepart\", os.path.join(home,\"s_selection\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 11, 2024 3:18:20 PM\",\"Succeeded at Thursday, January 11, 2024 3:18:22 PM (Elapsed Time: 2.67 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\wb_selection'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select lakes/ponds/etc. adjacent to E&T\n",
    "#arcpy.management.MakeFeatureLayer(nj2015_polys, \"wb\", where_clause = \"FTYPE_DESCRIPTION <>'Stream/River' And FTYPE_DESCRIPTION <> 'Canal/Ditch' \")\n",
    "#arcpy.management.SelectLayerByLocation(\"wb\", \"BOUNDARY_TOUCHES\", LP_sel)\n",
    "#arcpy.management.CopyFeatures(\"wb\", os.path.join(home,\"wb_selection\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 2:38:04 PM\",\"Succeeded at Tuesday, January 16, 2024 2:39:07 PM (Elapsed Time: 1 minutes 3 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\fhascdw_and_streams'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.path.join(home,\"wb_selection\") Excluding for now\n",
    "arcpy.management.Merge([LP_sel, os.path.join(home,\"s_selection\")], os.path.join(home, \"fhascdw_and_streams\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 2:39:08 PM\",\"Dissolving...\",\"Succeeded at Tuesday, January 16, 2024 2:39:52 PM (Elapsed Time: 44.54 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\CDW_all_regions'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Dissolve(os.path.join(home, \"fhascdw_and_streams\"), \n",
    "                                    os.path.join(home, \"CDW_all_regions\"), \n",
    "                                    None, \n",
    "                                    None, \n",
    "                                    \"SINGLE_PART\", \n",
    "                                    \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Output of this process:\n",
    "ani_polys = os.path.join(home, \"CDW_all_regions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1/12 Notes on potential problems with this selection:\n",
    "- waterbodies are selected even with very small overlap with E&T. Do we want to set a minimum % or other type of contact requirement?\n",
    "- Some Delaware not selected if not touching, probably due to differences between datasets and not a real intention for them not to touch. Could select \"within a distance\"\n",
    "- How does this look? Too inclusive, not inclusive enough, just right?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Trace Network Clean Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Repair geometry\n",
    "- Remove coastlines\n",
    "- Identify dirty areas\n",
    "- Manually inspect for self-intersections and delete vertices as necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Transferring SWQS classes to nhd lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#copy swqs lines\n",
    "#select and attribute lines with the selection above so that nulls have all zeroes\n",
    "arcpy.management.CopyFeatures(swqs, os.path.join(home, \"swqs_copy\"))\n",
    "# Delete null CATEGORY row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n",
      "Field exists\n",
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "#Select higher regulated segments. Buffer SWQS and and transfer category from selected streams to buffer\n",
    "\n",
    "# Export segments with higher regulations C1, TP, TM\n",
    "swqs_sel = os.path.join(home, \"swqs_copy\")\n",
    "#arcpy.conversion.ExportFeatures(swqs, os.path.join(home, \"swqs_selection\"), \"(CATEGORY LIKE '%FW%' Or CATEGORY LIKE '%PL%') And (CATEGORY LIKE '%C1%' Or CATEGORY LIKE '%TP%' Or CATEGORY LIKE '%TM%')\")\n",
    "\n",
    "# Add field to NJ Streams for each type swqs\n",
    "if len(arcpy.ListFields(swqs_sel, 'C1')) == 0:\n",
    "         arcpy.AddField_management(swqs_sel, \"C1\", \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "if len(arcpy.ListFields(swqs_sel, 'TP')) == 0:\n",
    "         arcpy.AddField_management(swqs_sel, \"TP\", \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "if len(arcpy.ListFields(swqs_sel, 'TM')) == 0:\n",
    "         arcpy.AddField_management(swqs_sel, \"TM\", \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Parse codes to separate columns from swqs\n",
    "fc = swqs_sel\n",
    "fields = ['CATEGORY', 'C1', 'TP', 'TM']\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        if ('FW' in row[0] or 'PL' in row[0]):\n",
    "            if 'C1' in row[0]:\n",
    "                row[1] = 1\n",
    "            else:\n",
    "                row[1] = 0\n",
    "        else: \n",
    "            row[1] = 0\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        if ('FW' in row[0] or 'PL' in row[0]):\n",
    "            if 'TP' in row[0]:\n",
    "                row[2] = 1\n",
    "            else:\n",
    "                row[2] = 0\n",
    "        else: \n",
    "            row[2] = 0\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor\n",
    "\n",
    "with arcpy.da.UpdateCursor(fc, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        if ('FW' in row[0] or 'PL' in row[0]):\n",
    "            if 'TM' in row[0]:\n",
    "                row[3] = 1\n",
    "            else:\n",
    "                row[3] = 0\n",
    "        else: \n",
    "            row[3] = 0\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "#Calculate transfer field on swqs lines \"Transfer_code\"\n",
    "new_field = \"Transfer_code\"\n",
    "\n",
    "if len(arcpy.ListFields(swqs_sel, new_field)) == 0:\n",
    "         arcpy.AddField_management(swqs_sel, new_field, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "fields = [\"C1\", \"TP\", \"TM\", new_field]\n",
    "\n",
    "# Create update cursor for feature class \n",
    "with arcpy.da.UpdateCursor(swqs_sel, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        if (row[0] == 0 and row[2] == 1):\n",
    "            row[3] = 1\n",
    "        elif row[0] == 1 and row[1] == 1:\n",
    "            row[3] = 2\n",
    "        elif row[0] == 1 and row [2] == 1:\n",
    "            row[3] = 3\n",
    "        elif row[0] == 1 and row[1] == 1:\n",
    "            row[3] = 4\n",
    "        elif row[0] == 1 and row[1] == 0 and row[2] == 0:\n",
    "            row[3] = 5\n",
    "        else:\n",
    "            row[3] = 0\n",
    "\n",
    "        # Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, January 15, 2024 4:15:13 PM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Monday, January 15, 2024 4:19:37 PM (Elapsed Time: 4 minutes 23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\swqs_select_diss_single'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dissolve by category to cut down on individual line segments that all get the same buffer\n",
    "swqs_sel = os.path.join(home, \"swqs_copy\")\n",
    "arcpy.management.Dissolve(in_features = swqs_sel, \n",
    "                          out_feature_class = os.path.join(home,\"swqs_select_diss_single\"),\n",
    "                          dissolve_field = ['C1', 'TP', 'TM',\"Transfer_code\"], \n",
    "                          statistics_fields = \"\",\n",
    "                          multi_part = \"MULTI_PART\",\n",
    "                          unsplit_lines = \"DISSOLVE_LINES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Remove coastlines from flowlines\n",
    "no_coast = arcpy.management.MakeFeatureLayer(nj2015, \n",
    "                                             \"no_coast\", \n",
    "                                             where_clause = \"FCODE <> 56600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Dissolve nhd streams for a cleaner transfer\n",
    "nhd_diss = arcpy.management.Dissolve(no_coast, os.path.join(home,\"nj2015_diss\"), \n",
    "                                     \"GNIS_NAME\", \n",
    "                                     \"\",\n",
    "                                     \"SINGLE_PART\",\n",
    "                                     \"UNSPLIT_LINES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading variables without rerunning\n",
    "nhd_diss = os.path.join(home,\"nj2015_diss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#make end points and start points\n",
    "swqs_ends = arcpy.management.FeatureVerticesToPoints(os.path.join(home,\"swqs_select_diss_single\"), os.path.join(scratch1,\"swqs_end_pts\"), 'BOTH_ENDS')\n",
    "#delete identical points\n",
    "swqs_ends = arcpy.management.DeleteIdentical(os.path.join(scratch1, \"swqs_end_pts\"), \"Shape\", \"1 foot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "swqs_ends = os.path.join(scratch1, \"swqs_end_pts\")\n",
    "\n",
    "#Field mapping\n",
    "#  https://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#//00080000000q000000\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "\n",
    "# Add all fields from inputs.\n",
    "fieldmappings.addTable(swqs_ends)\n",
    "fieldmappings.addTable(os.path.join(home,\"swqs_select_diss_single\"))\n",
    "\n",
    "# Name fields you want. Could get these names programmatically too.\n",
    "featureclass = swqs_ends\n",
    "keepers = [f.name for f in arcpy.ListFields(featureclass)]\n",
    "keepers.append(\"Transfer_code\")\n",
    "\n",
    "# Remove all output fields you don't want.\n",
    "for field in fieldmappings.fields:\n",
    "    if field.name not in keepers:\n",
    "        fieldmappings.removeFieldMap(fieldmappings.findFieldMapIndex(field.name))\n",
    "\n",
    "\n",
    "TransferFieldIndex = fieldmappings.findFieldMapIndex(\"Transfer_code\")\n",
    "fieldmap = fieldmappings.getFieldMap(TransferFieldIndex)\n",
    "fieldmap.mergeRule = \"count\" #If there is more than one value, this is a transition point\n",
    "fieldmappings.replaceFieldMap(TransferFieldIndex, fieldmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 11:27:17 AM\",\"Succeeded at Tuesday, January 16, 2024 11:44:14 AM (Elapsed Time: 16 minutes 57 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\swqs_split_pts_SpatialJoin'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only keep points that overlap transitions between two different swqs types\n",
    "#Spatial join points and swqs to see where points overlap changes in classifications. Those are the only points we need to retain\n",
    "arcpy.analysis.SpatialJoin(swqs_ends, \n",
    "                           os.path.join(home,\"swqs_select_diss_single\"), \n",
    "                           os.path.join(scratch1, \"swqs_split_pts_SpatialJoin\"), \n",
    "                           \"JOIN_ONE_TO_ONE\", \n",
    "                           \"KEEP_ALL\", \n",
    "                           field_mapping = fieldmappings,\n",
    "                           match_option = \"INTERSECT\"\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 1:42:35 PM\",\"Succeeded at Tuesday, January 16, 2024 1:42:35 PM (Elapsed Time: 0.20 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'overlap_pts'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select points at transitions between swqs codes\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"swqs_split_pts_SpatialJoin\"), \"overlap_pts\", where_clause = \"Join_Count > 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 2:21:47 PM\",\"Succeeded at Tuesday, January 16, 2024 2:24:18 PM (Elapsed Time: 2 minutes 31 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'overlap_pts'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.edit.Snap(\n",
    "    in_features=\"overlap_pts\",\n",
    "    snap_environment=f\"{nhd_diss} EDGE '100 Feet'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 2:28:03 PM\",\"Succeeded at Tuesday, January 16, 2024 2:28:05 PM (Elapsed Time: 2.30 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\overlap_pts'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(\"overlap_pts\", os.path.join(home,\"overlap_pts\"))\n",
    "#Some hand editing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 4:06:06 PM\",\"Succeeded at Tuesday, January 16, 2024 4:06:42 PM (Elapsed Time: 36.22 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\nhd_swqs_split1'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split nhd by points where classifications change in the middle of a segment rather than at confluences\n",
    "arcpy.management.SplitLineAtPoint(nhd_diss, os.path.join(home,\"overlap_pts\"), os.path.join(home, \"nhd_swqs_split1\"), \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Loading variables without rerunning\n",
    "swqs_sel_diss = arcpy.management.MakeFeatureLayer(os.path.join(home,\"swqs_select_diss_single\"), \"selected_swqs\", where_clause = \"Transfer_code <> 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Field mapping\n",
    "#  https://help.arcgis.com/en/arcgisdesktop/10.0/help/index.html#//00080000000q000000\n",
    "fieldmappings = arcpy.FieldMappings()\n",
    "\n",
    "# Add all fields from inputs.\n",
    "fieldmappings.addTable(os.path.join(home, \"nhd_swqs_split1\"))\n",
    "fieldmappings.addTable(swqs_sel_diss)\n",
    "\n",
    "# Name fields you want. Could get these names programmatically too.\n",
    "featureclass = os.path.join(home, \"nhd_swqs_split1\")\n",
    "keepers = [f.name for f in arcpy.ListFields(featureclass)]\n",
    "keepers.extend([\"C1\", \"TP\", \"TM\", \"Transfer_code\"])\n",
    "\n",
    "# Remove all output fields you don't want.\n",
    "for field in fieldmappings.fields:\n",
    "    if field.name not in keepers:\n",
    "        fieldmappings.removeFieldMap(fieldmappings.findFieldMapIndex(field.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 4:06:45 PM\",\"Succeeded at Tuesday, January 16, 2024 4:10:50 PM (Elapsed Time: 4 minutes 5 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\nhd_swqs_join'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spatial join\n",
    "arcpy.analysis.SpatialJoin(os.path.join(home,\"nhd_swqs_split1\"),\n",
    "                                         swqs_sel_diss,\n",
    "                                         os.path.join(home,\"nhd_swqs_join\"), \n",
    "                                         \"JOIN_ONE_TO_ONE\", \n",
    "                                         join_type = \"KEEP_ALL\", \n",
    "                                         field_mapping = fieldmappings, \n",
    "                                         match_option = \"SHARE_A_LINE_SEGMENT_WITH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some missed  classifications lingering in coastal areas. Not very bad problem. Can be fixed within polygons. Perhaps use SWQS copy to attribute waterbodies later on. Perhaps clip at coast and sub in SWQS lines directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, January 16, 2024 4:13:43 PM\",\"WARNING 000986: C:\\\\Users\\\\kdd56\\\\AppData\\\\Local\\\\Temp\\\\ArcGISProTemp11540\\\\nhd_swqs_join0.txt contains the full list of non simple features.\",\"WARNING 000461: Repaired feature 129781 because of short segments\",\"WARNING 003598: Updated feature class extent.\",\"Succeeded at Tuesday, January 16, 2024 4:13:52 PM (Elapsed Time: 8.49 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\nhd_swqs_join'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj2015_swqs = os.path.join(home,\"nhd_swqs_join\")\n",
    "arcpy.management.RepairGeometry(nj2015_swqs, \"DELETE_NULL\", \"ESRI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split NJ 2015 streamlines by Threatened and Endangered species lines and polys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Add mussel and plant stream lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nj2015_swqs = os.path.join(home,\"nhd_swqs_join\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if arcpy.Exists(os.path.join(scratch1,\"cdw_temp_linesA\")):\n",
    "    print(\"File exists. It takes 3 hours to align it, so don't overwrite!\")\n",
    "else:\n",
    "    inputs = [ani_streams, plant_streams]\n",
    "    output = os.path.join(scratch1,\"cdw_streams\")\n",
    "    arcpy.management.Merge(inputs, output)\n",
    "    arcpy.management.Dissolve(output, \n",
    "                              os.path.join(scratch1,\"cdw_temp_linesA\"),\n",
    "                              multi_part = \"SINGLE_PART\",\n",
    "                              unsplit_lines = \"UNSPLIT_LINES\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 17, 2024 12:17:16 PM\",\"Analyzing source data...\",\"Analyzing target data...\",\"Aligning geometries...\",\"Processing...\",\"Processing...\",\"Processing...\",\"Succeeded at Wednesday, January 17, 2024 12:47:44 PM (Elapsed Time: 30 minutes 27 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_temp_linesA'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 hour run\n",
    "arcpy.edit.AlignFeatures(\n",
    "        in_features= os.path.join(scratch1,\"cdw_temp_linesA\"),\n",
    "        target_features= nj2015_swqs,\n",
    "        search_distance= \"60 Feet\",\n",
    "        match_fields=None\n",
    "    )\n",
    "#Didn't work that well. Maybe just skip and make end points and snap them to stream lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fc = os.path.join(scratch1,\"cdw_temp_linesA\")\n",
    "buffer2 = arcpy.analysis.Buffer(input_fc, os.path.join(scratch1,\"temp_buffer2\"), \"80 Feet\", \"FULL\", \"FLAT\", \"ALL\", None, \"PLANAR\")                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 17, 2024 2:47:37 PM\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Wednesday, January 17, 2024 2:47:52 PM (Elapsed Time: 14.86 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_temp_linesA_Clip'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Clip(\n",
    "    in_features=os.path.join(scratch1,\"cdw_temp_linesA\"),\n",
    "    clip_features=buffer2,\n",
    "    out_feature_class= os.path.join(scratch1,\"cdw_temp_linesA_Clip\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 17, 2024 2:39:13 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Wednesday, January 17, 2024 2:40:10 PM (Elapsed Time: 56.88 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\cdw_swqs_intersect'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create split points\n",
    "arcpy.analysis.Intersect(\n",
    "    in_features= [buffer2, nj2015_swqs],\n",
    "    out_feature_class=os.path.join(home,\"cdw_swqs_intersect\"),\n",
    "    join_attributes=\"ONLY_FID\",\n",
    "    cluster_tolerance=None,\n",
    "    output_type=\"POINT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#split streams by cdw streams\n",
    "nj2015_temp1 = arcpy.management.SplitLineAtPoint(nj2015_swqs, \n",
    "                                                 os.path.join(home,\"cdw_swqs_intersect\"), \n",
    "                                                 os.path.join(home,\"nhd_cdw_split\"), \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 17, 2024 2:52:30 PM\",\"Succeeded at Wednesday, January 17, 2024 2:52:56 PM (Elapsed Time: 26.01 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'cdw_lines1'>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(nj2015_temp1, \"cdw_lines1\")\n",
    "arcpy.management.SelectLayerByLocation(\"cdw_lines1\", \"SHARE_A_LINE_SEGMENT_WITH\", \"cdw_temp_linesA_Clip\")\n",
    "arcpy.management.SelectLayerByLocation(\"cdw_lines1\", \n",
    "                                       \"WITHIN\", \n",
    "                                       buffer2, \n",
    "                                       selection_type = \"SUBSET_SELECTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fc = nj2015_temp1\n",
    "field_name = \"all_cdw\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"cdw_lines1\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"cdw_lines1\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        else:\n",
    "            row[0] = 0 \n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Add cdw plant and animal polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Combine 2 CDW sets of polygons into one set\n",
    "in_features = [ani_polys, plant_polys]\n",
    "arcpy.management.Merge(in_features, os.path.join(scratch1,\"all_cdw_polys\"), \"ONLY_FID\")\n",
    "cdw_polys = arcpy.management.Dissolve(os.path.join(scratch1,\"all_cdw_polys\"), \n",
    "                                      os.path.join(scratch1,\"all_cdw_polys_diss\"), \n",
    "                                      \"\", \n",
    "                                      \"\", \n",
    "                                      \"SINGLE_PART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Split lines by cdw polygons and recode\n",
    "input_lines = nj2015_temp1\n",
    "splitting_polygon = cdw_polys\n",
    "field_name = \"all_cdw\"\n",
    "output =  os.path.join(home,\"nhd_cdw_split1\")\n",
    "\n",
    "split_by_polygon_one(input_lines, splitting_polygon, field_name, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### A long version of this function in case it doesn't work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 17, 2024 3:08:51 PM\",\"Reading Features...\",\"Processing Tiles...\",\"Assembling Tile Features...\",\"Assembling Tile Features...\",\"Succeeded at Wednesday, January 17, 2024 3:09:38 PM (Elapsed Time: 46.56 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\temp_pts1'>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create split points\n",
    "arcpy.analysis.Intersect(\n",
    "    in_features= [cdw_polys, nj2015_temp1],\n",
    "    out_feature_class= os.path.join(scratch1,\"temp_pts1\"),\n",
    "    join_attributes=\"ONLY_FID\",\n",
    "    cluster_tolerance=None,\n",
    "    output_type=\"POINT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#split streams by cdw streams\n",
    "nj2015_temp2 = arcpy.management.SplitLineAtPoint(nj2015_temp1, os.path.join(scratch1,\"temp_pts1\"), os.path.join(home,\"nhd_cdw_split1\"), \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 17, 2024 3:14:21 PM\",\"Succeeded at Wednesday, January 17, 2024 3:15:07 PM (Elapsed Time: 46.26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'cdw_lines2'>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(nj2015_temp2, \"cdw_lines2\")\n",
    "arcpy.management.SelectLayerByLocation(\"cdw_lines2\", \"WITHIN\", cdw_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fc = nj2015_temp2\n",
    "field_name = \"all_cdw\"\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"cdw_lines2\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"cdw_lines2\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Excluding unregulated streams\n",
    "See table: https://rutgersconnect-my.sharepoint.com/:w:/r/personal/kdd56_crssa_rutgers_edu/Documents/NJWRAP/NJWRAP_Task2_shared_documents/Regulatory_Riparian_Areas/20230912_Riparian_regulatory_buffer_report_revised.docx?d=wf10f0e61df20477eb0c6270674056ca0&csf=1&web=1&e=tgsIj3\n",
    "Still do this at the top of the project because it affects upstream selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Convert null values to 0\n",
    "fieldNames = ['all_cdw', 'C1', 'TP', 'TM']\n",
    "fieldCount = len(fieldNames)\n",
    "\n",
    "with arcpy.da.UpdateCursor(nj2015_temp2, fieldNames) as curU:  \n",
    "    for row in curU:  \n",
    "        rowU = row  \n",
    "        for field in range(fieldCount):  \n",
    "            if rowU[field] == None:  \n",
    "                rowU[field] = 0\n",
    "            elif rowU[field] == \"\":\n",
    "                rowU[field] = 0\n",
    "            curU.updateRow(rowU)\n",
    "del curU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Labeling unregulated LULC classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nj2015_temp2 = os.path.join(home,\"nhd_CDW_split1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 1:49:02 PM\",\"Dissolving...\",\"Succeeded at Thursday, January 18, 2024 1:49:14 PM (Elapsed Time: 11.96 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\lulc_exclusions_diss'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LULC excluded classes--identify them so that there is no upstream trace from theres\n",
    "\n",
    "#5120 (Canals) \n",
    "#7310, 7320, 7330 (Stone Quarries, Sand and Gravel Pits (Borrow Pits), Other Mining)\n",
    "#5430 (Atlantic Ocean) \n",
    "#5420 (Dredged Lagoon)\n",
    "#6111      Saline Marsh (Low marsh) \n",
    "#6112      Saline Marsh (High marsh) \n",
    "#6130      Vegetated Dune Communities \n",
    "#6141      Phragmites Dominate Coastal Wetlands \n",
    "\n",
    "\n",
    "nj2020_lulc = arcpy.management.MakeFeatureLayer(r\"https://services1.arcgis.com/QWdNfRs7lkPq4g4Q/arcgis/rest/services/Land_Use_2020/FeatureServer/5\", \"lulc2020\")\n",
    "splitting_polygon1 = arcpy.management.MakeFeatureLayer(lulc, \n",
    "                                                       \"lulc_unregulated\", \n",
    "                                                       where_clause = \"LU15 = 5120 Or LU15 = 7310 Or LU15 = 7320 Or LU15 = 7330 Or LU15 = 5430 Or LU15 = 6111 Or LU15 = 6112 Or LU15 = 6130 OR LU15 = 6141\"\n",
    "                                                       )\n",
    "\n",
    "arcpy.management.Dissolve(\"lulc_unregulated\", os.path.join(home,\"lulc_exclusions_diss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Add exclusion field for LULC\n",
    "input_lines = nj2015_temp2\n",
    "splitting_polygon = os.path.join(home,\"lulc_exclusions_diss\")\n",
    "field_name = \"regulated\"\n",
    "output =  os.path.join(home, \"stream_regs_with_exclusions_v1\")\n",
    "\n",
    "split_by_polygon_zero(input_lines, splitting_polygon, field_name, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Labeling canals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 17, 2024 4:14:06 PM\",\"Succeeded at Wednesday, January 17, 2024 4:14:07 PM (Elapsed Time: 0.48 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'canals'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add canals and raceways\n",
    "arcpy.management.MakeFeatureLayer(r\"https://mapsdep.nj.gov/arcgis/rest/services/Features/Hydrography/MapServer/45\", \n",
    "                                  \"canals\", \n",
    "                                  where_clause = \"CONDITION = 'Water'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 9:11:37 AM\",\"Succeeded at Thursday, January 18, 2024 9:11:42 AM (Elapsed Time: 5.22 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\canals_PolygonToCenterline'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to select and include the Canals\n",
    "arcpy.topographic.PolygonToCenterline(\n",
    "    in_features=\"canals\",\n",
    "    out_feature_class= os.path.join(scratch1, \"canals_PolygonToCenterline\"),\n",
    "    connecting_features=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 9:12:19 AM\",\"Analyzing source data...\",\"Analyzing target data...\",\"Aligning geometries...\",\"Processing...\",\"Processing...\",\"Processing...\",\"Succeeded at Thursday, January 18, 2024 10:00:41 AM (Elapsed Time: 48 minutes 21 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\canals_PolygonToCenterline'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.edit.AlignFeatures(\n",
    "        in_features= os.path.join(scratch1, \"canals_PolygonToCenterline\"),\n",
    "        target_features= nj2015,\n",
    "        search_distance= \"60 Feet\",\n",
    "        match_fields=None\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buffer2 = arcpy.analysis.Buffer(os.path.join(scratch1, \"canals_PolygonToCenterline\"), os.path.join(scratch1,\"temp_buffer2\"), \"80 Feet\", \"FULL\", \"FLAT\", \"ALL\", None, \"PLANAR\")                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 12:42:44 PM\",\"Analyzing input features...\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Thursday, January 18, 2024 12:42:47 PM (Elapsed Time: 2.95 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\canals_Centerline_clip'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Clip(\n",
    "    in_features= os.path.join(scratch1, \"canals_PolygonToCenterline\"),\n",
    "    clip_features=buffer2,\n",
    "    out_feature_class= os.path.join(scratch1, \"canals_Centerline_clip\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 12:42:55 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, January 18, 2024 12:43:30 PM (Elapsed Time: 35.71 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\canals_swqs_intersect'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create split points\n",
    "arcpy.analysis.Intersect(\n",
    "    in_features= [buffer2, nj2015],\n",
    "    out_feature_class=os.path.join(home,\"canals_swqs_intersect\"),\n",
    "    join_attributes=\"ONLY_FID\",\n",
    "    cluster_tolerance=None,\n",
    "    output_type=\"POINT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 12:51:28 PM\",\"Succeeded at Thursday, January 18, 2024 12:51:28 PM (Elapsed Time: 0.05 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'pts_lyr'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(os.path.join(home,\"canals_swqs_intersect\"), \"pts_lyr\")\n",
    "arcpy.management.SelectLayerByLocation(\"pts_lyr\", \"INTERSECT\", os.path.join(scratch1, \"canals_Centerline_clip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 12:51:57 PM\",\"Succeeded at Thursday, January 18, 2024 12:52:02 PM (Elapsed Time: 4.18 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\pts_lyr_sel'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(\"pts_lyr\", os.path.join(scratch1,\"pts_lyr_sel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 1:54:34 PM\",\"Succeeded at Thursday, January 18, 2024 1:54:57 PM (Elapsed Time: 22.98 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\stream_regs_with_exclusions_v2'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split streams by cdw streams\n",
    "arcpy.management.SplitLineAtPoint(os.path.join(home, \"stream_regs_with_exclusions_v1\"), \n",
    "                                  os.path.join(scratch1,\"pts_lyr_sel\"), \n",
    "                                  os.path.join(home, \"stream_regs_with_exclusions_v2\"), \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 1:55:00 PM\",\"Succeeded at Thursday, January 18, 2024 1:55:01 PM (Elapsed Time: 0.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'lyr_lines1'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(os.path.join(home, \"stream_regs_with_exclusions_v2\"), \"lyr_lines1\")\n",
    "#arcpy.management.SelectLayerByLocation(\"lyr_lines1\", \"SHARE_A_LINE_SEGMENT_WITH\", os.path.join(scratch1, \"canals_Centerline_clip\"))\n",
    "arcpy.management.SelectLayerByLocation(\"lyr_lines1\", \n",
    "                                       \"WITHIN\", \n",
    "                                       buffer2)\n",
    "arcpy.management.SelectLayerByAttribute(\"lyr_lines1\",\n",
    "                                        selection_type = \"ADD_TO_SELECTION\",\n",
    "                                        where_clause = \"GNIS_NAME LIKE '%Canal'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "input_fc = os.path.join(home, \"stream_regs_with_exclusions_v2\")\n",
    "field_name = \"regulated\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"lyr_lines1\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"lyr_lines1\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 0\n",
    "        else:\n",
    "            row[0] = 1 \n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fc = os.path.join(home, \"stream_regs_with_exclusions_v2\")\n",
    "field_name = \"Canal\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"lyr_lines1\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"lyr_lines1\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        else:\n",
    "            row[0] = 0 \n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select upstream reaches for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nj2015_temp2 = os.path.join(home, \"stream_regs_with_exclusions_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create trace network for TP/C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Create feature dataset for trace network\n",
    "#arcpy.management.CreateFeatureDataset(r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\20221104_Regulatory_buffers.gdb\", \"combined_lines\", nj2015_merge)\n",
    "#arcpy.env.workspace = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\20221104_Regulatory_buffers.gdb\\combined_lines\"\n",
    "#arcpy.conversion.ExportFeatures(r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\Hydr_NHD_2015_streams', \"nj2015a\")\n",
    "arcpy.conversion.ExportFeatures(r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\20221104_Regulatory_buffers.gdb\\topology_test\\nj2015_merge_diss1\", \"nj2015_merge_diss1_copy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Clean up steps\n",
    "\n",
    "#Select by location,Intersection with Atlantic ocean from NHD Waterbodies to clean up unneded\n",
    "#arcpy.management.SelectLayerByAttribute(nj2015_polys, \"NEW_SELECTION\", \"FCODE = 49300 Or FCODE = 44500\", None)\n",
    "#arcpy.management.SelectLayerByLocation(\"nj2015_merge_diss1_copy\", \"INTERSECT\", nj2015_polys, None, \"ADD_TO_SELECTION\", \"NOT_INVERT\")\n",
    "#arcpy.management.DeleteRows(\"nj2015_merge_diss1_copy\")\n",
    "arcpy.management.SelectLayerByAttribute(\"nj2015_merge_diss1_copy\", \"NEW_SELECTION\", \"FCODE = 56600\", None\n",
    "arcpy.management.RepairGeometry(\"nj2015_merge_diss1_copy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Set workspace and create variable for new copy of lines\n",
    "arcpy.env.workspace = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\20221104_Regulatory_buffers.gdb\\combined_lines\"\n",
    "nj2015_merge = \"nj2015_merge_diss1_copy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Create trace network from merged lines with TP start points as input junctions\n",
    "#The fact that this is needed is concerting. When I ran topology checks there were no overlaps...\n",
    "\n",
    "in_feature_dataset = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\20221104_Regulatory_buffers.gdb\\combined_lines\"\n",
    "#input_junctions = \"TP_start_pts\"\n",
    "#arcpy.management.RepairGeometry(nj2015_merge)\n",
    "input_edges = nj2015_merge\n",
    "\n",
    "arcpy.tn.CreateTraceNetwork(in_feature_dataset, \"nj_merge_network\",\"\",[[input_edges, 'SIMPLE_EDGE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#arcpy.tn.EnableNetworkTopology(\"nj_TP_merge_network\", \"\", \"ONLY_ERRORS\")\n",
    "#arcpy.management.RepairGeometry(\"nj2015a\")\n",
    "#arcpy.topographic.RepairSelfIntersection(\"nj2015_merge_diss1_copy\", \"SPLIT\", None, \"IGNORE_ENDS\")\n",
    "#arcpy.tn.EnableNetworkTopology(\"nj_merge_network\")\n",
    "arcpy.tn.ValidateNetworkTopology(\"nj_merge_network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Copy network streams to put all changes on rather than the network itselft\n",
    "arcpy.conversion.ExportFeatures(\"streams_from_featureservice\", r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\streams_from_fs_copy\",\n",
    "                                '', \"NOT_USE_ALIAS\", \n",
    "                                'COMID \"ComID\" true true false 4 Long 0 0,First,#,streams_from_featureservice,COMID,-1,-1;PERMANENT_IDENTIFIER \"PERMANENT_IDENTIFIER\" true true false 40 Text 0 0,First,#,streams_from_featureservice,PERMANENT_IDENTIFIER,0,40;FDATE \"FDATE\" true true false 8 Date 0 0,First,#,streams_from_featureservice,FDATE,-1,-1;RESOLUTION \"Resolution\" true true false 4 Long 0 0,First,#,streams_from_featureservice,RESOLUTION,-1,-1;GNIS_ID \"GNIS_ID\" true true false 10 Text 0 0,First,#,streams_from_featureservice,GNIS_ID,0,10;GNIS_NAME \"GNIS_NAME\" true true false 65 Text 0 0,First,#,streams_from_featureservice,GNIS_NAME,0,65;LENGTHKM \"LENGTHKM\" true true false 8 Double 0 0,First,#,streams_from_featureservice,LENGTHKM,-1,-1;REACHCODE \"REACHCODE\" true true false 14 Text 0 0,First,#,streams_from_featureservice,REACHCODE,0,14;FLOWDIR \"FlowDir\" true true false 4 Long 0 0,First,#,streams_from_featureservice,FLOWDIR,-1,-1;WBAREACOMID \"WBAREACOMID\" true true false 4 Long 0 0,First,#,streams_from_featureservice,WBAREACOMID,-1,-1;WBAREA_PERMANENT_IDENTIFIER \"WBAREA_PERMANENT_IDENTIFIER\" true true false 40 Text 0 0,First,#,streams_from_featureservice,WBAREA_PERMANENT_IDENTIFIER,0,40;FTYPE \"FType\" true true false 4 Long 0 0,First,#,streams_from_featureservice,FTYPE,-1,-1;FCODE \"FCode\" true true false 4 Long 0 0,First,#,streams_from_featureservice,FCODE,-1,-1;ENABLED \"Enabled\" true true false 2 Short 0 0,First,#,streams_from_featureservice,ENABLED,-1,-1;STREAMLEVEL \"STREAMLEVEL\" true true false 4 Long 0 0,First,#,streams_from_featureservice,STREAMLEVEL,-1,-1;STREAMORDER \"STREAMORDER\" true true false 4 Long 0 0,First,#,streams_from_featureservice,STREAMORDER,-1,-1;FTYPE_DESCRIPTION \"FTYPE_DESCRIPTION\" true true false 50 Text 0 0,First,#,streams_from_featureservice,FTYPE_DESCRIPTION,0,50;FCODE_DESCRIPTION \"FCODE_DESCRIPTION\" true true false 255 Text 0 0,First,#,streams_from_featureservice,FCODE_DESCRIPTION,0,255;HU8 \"HU8\" true true false 8 Text 0 0,First,#,streams_from_featureservice,HU8,0,8;CREATED_USER \"CREATED_USER\" true true false 255 Text 0 0,First,#,streams_from_featureservice,CREATED_USER,0,255;CREATED_DATE \"CREATED_DATE\" true true false 8 Date 0 0,First,#,streams_from_featureservice,CREATED_DATE,-1,-1;LAST_EDITED_USER \"LAST_EDITED_USER\" true true false 255 Text 0 0,First,#,streams_from_featureservice,LAST_EDITED_USER,0,255;LAST_EDITED_DATE \"LAST_EDITED_DATE\" true true false 8 Date 0 0,First,#,streams_from_featureservice,LAST_EDITED_DATE,-1,-1;GLOBALID \"GLOBALID\" false false true 38 GlobalID 0 0,First,#,streams_from_featureservice,GLOBALID,-1,-1;Shape_Length \"Shape_Length\" false true true 8 Double 0 0,First,#,streams_from_featureservice,Shape_Length,-1,-1;FLOWDIRECTION \"Flow direction\" true true false 2 Short 0 0,First,#,streams_from_featureservice,FLOWDIRECTION,-1,-1;FLOWDIRECTION_1 \"Flow direction\" true true false 2 Short 0 0,First,#,streams_from_featureservice,FLOWDIRECTION_1,-1,-1;FLOWDIRECTION_2 \"Flow direction\" true true false 2 Short 0 0,First,#,streams_from_featureservice,FLOWDIRECTION_2,-1,-1;FLOWDIRECTION_3 \"Flow direction\" true true true 2 Short 0 0,First,#,streams_from_featureservice,FLOWDIRECTION_3,-1,-1', \n",
    "                                None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create starting points and run traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Trout Production Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Data sources\n",
    "nj2015_swqs = os.path.join(home,\"nhd_swqs_join\") #original layer with just the swqs--fewest splits\n",
    "nj2015_temp2 = os.path.join(home, \"stream_regs_with_exclusions_v2\")\n",
    "streams_TN = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\"\n",
    "#arcpy.tn.EnableNetworkTopology(streams_TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 2:46:27 PM\",\"Succeeded at Thursday, January 18, 2024 2:46:31 PM (Elapsed Time: 4.34 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\TP_start_pts'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dissolve lines and make starting points for traces\n",
    "arcpy.management.Dissolve(nj2015_swqs, os.path.join(scratch1,\"nj2015_diss_TP\"), ['GNIS_NAME', 'TP'], \"\", \"SINGLE_PART\", \"UNSPLIT_LINES\")\n",
    "in_features = os.path.join(scratch1,\"nj2015_diss_TP\")\n",
    "arcpy.management.MakeFeatureLayer(in_features, 'TP_streams', \"TP = 1\")\n",
    "arcpy.management.FeatureVerticesToPoints('TP_streams', os.path.join(scratch1,\"TP_start_pts\"), 'START') #Create starting points by selecting segments from each category (cdw, c1, tp, tm) and creating a start point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 18, 2024 2:51:01 PM\",\"Succeeded at Thursday, January 18, 2024 2:52:19 PM (Elapsed Time: 1 minutes 17 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'Trace_Results_Aggregated_Points'>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trace all upstream for Trout Production Streams\n",
    "arcpy.Trace_tn(in_trace_network=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\", \n",
    "               trace_type=\"UPSTREAM\", \n",
    "               starting_points=os.path.join(scratch1,\"TP_start_pts\"), \n",
    "               barriers=\"\", \n",
    "               result_types=\"AGGREGATED_GEOMETRY\", \n",
    "               aggregated_lines = os.path.join(home, \"TP_upstream_trace\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 5:40:43 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, February 20, 2024 5:40:52 PM (Elapsed Time: 9.20 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\TP_upstream_only'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Erase TP from TP upstream\n",
    "in_features = os.path.join(scratch1,\"nj2015_diss_TP\")\n",
    "arcpy.management.MakeFeatureLayer(in_features, 'TP_streams', \"TP = 1\")\n",
    "arcpy.analysis.Erase(os.path.join(home, \"TP_upstream_trace\"), 'TP_streams', os.path.join(home, \"TP_upstream_only\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 5:43:00 PM\",\"Succeeded at Tuesday, February 20, 2024 5:43:07 PM (Elapsed Time: 6.74 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'lyr_streams'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select upstream segments \n",
    "arcpy.management.MakeFeatureLayer(nj2015_temp2, \"lyr_streams\")\n",
    "arcpy.management.SelectLayerByLocation(\"lyr_streams\", \"SHARE_A_LINE_SEGMENT_WITH\", os.path.join(home, \"TP_upstream_only\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "#Add TP upstream column\n",
    "input_fc = nj2015_temp2\n",
    "field_name = \"TP_upstream\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "    arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"lyr_streams\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"lyr_streams\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        else:\n",
    "            row[1] = 0\n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category 1 Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run main trace and clip operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data sources\n",
    "nj2015_swqs = os.path.join(home,\"nhd_swqs_join\") #original layer with just the swqs--fewest splits\n",
    "nj2015_temp2 = os.path.join(home, \"stream_regs_with_exclusions_v2\")\n",
    "streams_TN = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\"\n",
    "#arcpy.tn.EnableNetworkTopology(streams_TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, January 28, 2024 4:28:00 PM\",\"Succeeded at Sunday, January 28, 2024 4:28:07 PM (Elapsed Time: 7.46 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_start_pts'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dissolve lines and make starting points for traces\n",
    "arcpy.management.MakeFeatureLayer(nj2015_temp2, \"C1_streams\", where_clause = \"C1 = 1 And regulated = 1\")\n",
    "#arcpy.management.Dissolve('C1_streams', os.path.join(scratch1,\"diss_C1\"), ['GNIS_NAME', 'C1'], \"\", \"SINGLE_PART\", \"UNSPLIT_LINES\")\n",
    "arcpy.management.FeatureVerticesToPoints(\"C1_streams\", \n",
    "                                         os.path.join(scratch1,\"C1_start_pts\"), \n",
    "                                         'START') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, January 28, 2024 5:15:55 PM\",\"Succeeded at Sunday, January 28, 2024 5:16:17 PM (Elapsed Time: 22.52 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\huc14_00ft_inner_buffer'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inner buffer before intersect to avoid the inaccuracies of the HUC14 layer\n",
    "arcpy.analysis.Buffer(huc14s, \n",
    "                      os.path.join(scratch1, \"huc14_00ft_inner_buffer\"), \n",
    "                      buffer_distance_or_field= \"-300 feet\", \n",
    "                      dissolve_option = \"NONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, January 28, 2024 5:16:23 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Sunday, January 28, 2024 5:16:48 PM (Elapsed Time: 24.67 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_streams_hucbuff_int'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Intersect(\n",
    "    in_features=[\"C1_streams\", os.path.join(scratch1, \"huc14_00ft_inner_buffer\")],\n",
    "    out_feature_class=os.path.join(scratch1, \"C1_streams_hucbuff_int\"),\n",
    "    join_attributes=\"ONLY_FID\",\n",
    "    cluster_tolerance=None,\n",
    "    output_type=\"POINT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, January 28, 2024 5:16:49 PM\",\"Succeeded at Sunday, January 28, 2024 5:16:52 PM (Elapsed Time: 3.07 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_streams_hucbuff_SP'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OR singlepoint\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"C1_streams_hucbuff_int\"), os.path.join(scratch1, \"C1_streams_hucbuff_SP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, January 28, 2024 5:17:09 PM\",\"Succeeded at Sunday, January 28, 2024 5:17:14 PM (Elapsed Time: 4.80 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_starts_merge'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(scratch1,\"C1_start_pts\"), os.path.join(scratch1, \"C1_streams_hucbuff_SP\")], \n",
    "                       os.path.join(scratch1, \"C1_starts_merge\")\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Sunday, January 28, 2024 5:17:22 PM\",\"Succeeded at Sunday, January 28, 2024 5:17:22 PM (Elapsed Time: 0.16 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'HUC14_map'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = True\n",
    "#List HUC 14s with C1 in them\n",
    "pt_layer = arcpy.MakeFeatureLayer_management(os.path.join(scratch1,\"C1_start_pts\"), \"C1_start_pts_layer\")\n",
    "HUC14_map = arcpy.MakeFeatureLayer_management(r'X:\\projects\\njwrap\\Data\\NJDEP\\Hydr_HUC14_bnd\\Hydr_HUC14_bnd.gdb\\Hydr_HUC14_bnd', \"HUC14_map\")\n",
    "selection = arcpy.management.SelectLayerByLocation(HUC14_map, \"CONTAINS\", pt_layer, selection_type = \"NEW_SELECTION\")\n",
    "\n",
    "def unique_values(table , field):\n",
    "    with arcpy.da.SearchCursor(table, [field]) as cursor:\n",
    "        return sorted({row[0] for row in cursor})\n",
    "\n",
    "HUC14s = unique_values(selection, 'HUC14')\n",
    "arcpy.management.SelectLayerByAttribute(HUC14_map, \"CLEAR_SELECTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HUC_test = HUC14s[0]\n",
    "len(HUC14s)\n",
    "#HUC14s1 = HUC14s[311:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    " #\n",
    "test_hucs = ['02020007020020', '02020007020030', '02020007010070', '02020007020060', '02040105040020']\n",
    "#['02020007010030', '02020007010010', '02020007010020']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty feature class\n",
    "hucclips = arcpy.management.CreateFeatureclass(home, \n",
    "                                               \"C1_HUC14_1_28\", \n",
    "                                               geometry_type = \"POLYLINE\", \n",
    "                                               template = os.path.join(scratch1, \"stream_clippy_1_02020007010010\"),  \n",
    "                                               spatial_reference = arcpy.Describe(os.path.join(scratch1, \"stream_clippy_1_02020007010010\")).spatialReference \n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 392 complete in 25.037843465805054 seconds\n",
      "2 of 392 complete in 31.036492347717285 seconds\n",
      "3 of 392 complete in 31.324048042297363 seconds\n",
      "4 of 392 complete in 29.10905933380127 seconds\n",
      "5 of 392 complete in 30.15512442588806 seconds\n",
      "6 of 392 complete in 29.070045709609985 seconds\n",
      "7 of 392 complete in 28.947082996368408 seconds\n",
      "8 of 392 complete in 29.189042329788208 seconds\n",
      "9 of 392 complete in 47.4405882358551 seconds\n",
      "10 of 392 complete in 55.40707230567932 seconds\n",
      "11 of 392 complete in 54.36269736289978 seconds\n",
      "12 of 392 complete in 54.95132827758789 seconds\n",
      "13 of 392 complete in 58.45238018035889 seconds\n",
      "14 of 392 complete in 57.252164125442505 seconds\n",
      "15 of 392 complete in 59.45846652984619 seconds\n",
      "16 of 392 complete in 58.74195408821106 seconds\n",
      "17 of 392 complete in 59.74283218383789 seconds\n",
      "18 of 392 complete in 54.92136549949646 seconds\n",
      "19 of 392 complete in 54.70310091972351 seconds\n",
      "20 of 392 complete in 54.64168691635132 seconds\n",
      "21 of 392 complete in 54.33280873298645 seconds\n",
      "22 of 392 complete in 54.33693289756775 seconds\n",
      "23 of 392 complete in 54.622260332107544 seconds\n",
      "24 of 392 complete in 55.05787420272827 seconds\n",
      "25 of 392 complete in 54.041465520858765 seconds\n",
      "26 of 392 complete in 56.88660454750061 seconds\n",
      "27 of 392 complete in 55.50618243217468 seconds\n",
      "28 of 392 complete in 54.70062780380249 seconds\n",
      "29 of 392 complete in 58.50449752807617 seconds\n",
      "30 of 392 complete in 58.11504626274109 seconds\n",
      "31 of 392 complete in 56.115219831466675 seconds\n",
      "32 of 392 complete in 58.481818199157715 seconds\n",
      "33 of 392 complete in 56.45473790168762 seconds\n",
      "34 of 392 complete in 53.52014231681824 seconds\n",
      "35 of 392 complete in 56.07259821891785 seconds\n",
      "36 of 392 complete in 56.51425361633301 seconds\n",
      "37 of 392 complete in 55.96157121658325 seconds\n",
      "38 of 392 complete in 57.96036767959595 seconds\n",
      "39 of 392 complete in 54.41316103935242 seconds\n",
      "40 of 392 complete in 55.51653861999512 seconds\n",
      "41 of 392 complete in 56.91905665397644 seconds\n",
      "42 of 392 complete in 58.40567445755005 seconds\n",
      "43 of 392 complete in 55.891281843185425 seconds\n",
      "44 of 392 complete in 56.68277192115784 seconds\n",
      "45 of 392 complete in 57.97263693809509 seconds\n",
      "46 of 392 complete in 56.91536235809326 seconds\n",
      "47 of 392 complete in 59.69391655921936 seconds\n",
      "48 of 392 complete in 58.281347036361694 seconds\n",
      "49 of 392 complete in 58.46546673774719 seconds\n",
      "50 of 392 complete in 53.585899114608765 seconds\n",
      "51 of 392 complete in 59.04394865036011 seconds\n",
      "52 of 392 complete in 57.07494807243347 seconds\n",
      "53 of 392 complete in 55.43506860733032 seconds\n",
      "54 of 392 complete in 55.22254180908203 seconds\n",
      "55 of 392 complete in 54.767094373703 seconds\n",
      "56 of 392 complete in 57.51547360420227 seconds\n",
      "57 of 392 complete in 56.100117683410645 seconds\n",
      "58 of 392 complete in 54.8768150806427 seconds\n",
      "59 of 392 complete in 58.13468527793884 seconds\n",
      "60 of 392 complete in 53.39785051345825 seconds\n",
      "61 of 392 complete in 57.9838752746582 seconds\n",
      "62 of 392 complete in 58.950098514556885 seconds\n",
      "63 of 392 complete in 60.35496139526367 seconds\n",
      "64 of 392 complete in 55.10763740539551 seconds\n",
      "65 of 392 complete in 57.41459345817566 seconds\n",
      "66 of 392 complete in 54.862446308135986 seconds\n",
      "67 of 392 complete in 54.571375131607056 seconds\n",
      "68 of 392 complete in 54.45460247993469 seconds\n",
      "69 of 392 complete in 54.733924865722656 seconds\n",
      "70 of 392 complete in 56.30443334579468 seconds\n",
      "71 of 392 complete in 56.27481269836426 seconds\n",
      "72 of 392 complete in 53.723594665527344 seconds\n",
      "73 of 392 complete in 54.95642066001892 seconds\n",
      "74 of 392 complete in 54.98596739768982 seconds\n",
      "75 of 392 complete in 55.24306297302246 seconds\n",
      "76 of 392 complete in 55.44710898399353 seconds\n",
      "77 of 392 complete in 54.81064748764038 seconds\n",
      "78 of 392 complete in 55.3516800403595 seconds\n",
      "79 of 392 complete in 54.842235803604126 seconds\n",
      "80 of 392 complete in 54.890459299087524 seconds\n",
      "81 of 392 complete in 53.92168354988098 seconds\n",
      "82 of 392 complete in 56.77551317214966 seconds\n",
      "83 of 392 complete in 55.131802797317505 seconds\n",
      "84 of 392 complete in 53.97598361968994 seconds\n",
      "85 of 392 complete in 53.93710732460022 seconds\n",
      "86 of 392 complete in 55.348201751708984 seconds\n",
      "87 of 392 complete in 55.93106150627136 seconds\n",
      "88 of 392 complete in 54.96839427947998 seconds\n",
      "89 of 392 complete in 54.67121958732605 seconds\n",
      "90 of 392 complete in 54.42600107192993 seconds\n",
      "91 of 392 complete in 56.43669009208679 seconds\n",
      "92 of 392 complete in 53.86615967750549 seconds\n",
      "93 of 392 complete in 55.29955244064331 seconds\n",
      "94 of 392 complete in 54.464510679244995 seconds\n",
      "95 of 392 complete in 55.479549407958984 seconds\n",
      "96 of 392 complete in 56.2692551612854 seconds\n",
      "97 of 392 complete in 57.082032442092896 seconds\n",
      "98 of 392 complete in 56.88363480567932 seconds\n",
      "99 of 392 complete in 55.87527942657471 seconds\n",
      "100 of 392 complete in 57.10822677612305 seconds\n",
      "101 of 392 complete in 62.97148370742798 seconds\n",
      "102 of 392 complete in 61.918811559677124 seconds\n",
      "103 of 392 complete in 58.640936851501465 seconds\n",
      "104 of 392 complete in 56.85179018974304 seconds\n",
      "105 of 392 complete in 59.49641466140747 seconds\n",
      "106 of 392 complete in 56.04531717300415 seconds\n",
      "107 of 392 complete in 62.642910957336426 seconds\n",
      "108 of 392 complete in 57.27378582954407 seconds\n",
      "109 of 392 complete in 57.58552837371826 seconds\n",
      "110 of 392 complete in 59.58528399467468 seconds\n",
      "111 of 392 complete in 55.8005805015564 seconds\n",
      "112 of 392 complete in 59.14653944969177 seconds\n",
      "113 of 392 complete in 60.472631216049194 seconds\n",
      "114 of 392 complete in 55.72323179244995 seconds\n",
      "115 of 392 complete in 56.777151584625244 seconds\n",
      "116 of 392 complete in 56.60277843475342 seconds\n",
      "117 of 392 complete in 54.220075607299805 seconds\n",
      "118 of 392 complete in 58.212827920913696 seconds\n",
      "119 of 392 complete in 61.97806906700134 seconds\n",
      "120 of 392 complete in 54.976891040802 seconds\n",
      "121 of 392 complete in 58.50971007347107 seconds\n",
      "122 of 392 complete in 56.828635931015015 seconds\n",
      "123 of 392 complete in 58.715399503707886 seconds\n",
      "124 of 392 complete in 57.00413632392883 seconds\n",
      "125 of 392 complete in 55.54602932929993 seconds\n",
      "126 of 392 complete in 62.086296796798706 seconds\n",
      "127 of 392 complete in 60.10788297653198 seconds\n",
      "128 of 392 complete in 55.00586175918579 seconds\n",
      "129 of 392 complete in 57.6903862953186 seconds\n",
      "130 of 392 complete in 55.52790594100952 seconds\n",
      "131 of 392 complete in 56.93494391441345 seconds\n",
      "132 of 392 complete in 57.04303002357483 seconds\n",
      "133 of 392 complete in 58.37283158302307 seconds\n",
      "134 of 392 complete in 56.799795389175415 seconds\n",
      "135 of 392 complete in 58.30724859237671 seconds\n",
      "136 of 392 complete in 55.36314797401428 seconds\n",
      "137 of 392 complete in 55.59130787849426 seconds\n",
      "138 of 392 complete in 55.58083510398865 seconds\n",
      "139 of 392 complete in 53.750977516174316 seconds\n",
      "140 of 392 complete in 53.51085686683655 seconds\n",
      "141 of 392 complete in 55.145771741867065 seconds\n",
      "142 of 392 complete in 55.572551012039185 seconds\n",
      "143 of 392 complete in 55.5795841217041 seconds\n",
      "144 of 392 complete in 56.39923024177551 seconds\n",
      "145 of 392 complete in 54.32593035697937 seconds\n",
      "146 of 392 complete in 53.97838234901428 seconds\n",
      "147 of 392 complete in 54.78889203071594 seconds\n",
      "148 of 392 complete in 55.78162884712219 seconds\n",
      "149 of 392 complete in 56.0882306098938 seconds\n",
      "150 of 392 complete in 54.99373269081116 seconds\n",
      "151 of 392 complete in 58.56370663642883 seconds\n",
      "152 of 392 complete in 55.95727205276489 seconds\n",
      "153 of 392 complete in 54.88696646690369 seconds\n",
      "154 of 392 complete in 56.00641465187073 seconds\n",
      "155 of 392 complete in 55.63491177558899 seconds\n",
      "156 of 392 complete in 58.90042519569397 seconds\n",
      "157 of 392 complete in 56.407896518707275 seconds\n",
      "158 of 392 complete in 56.75921630859375 seconds\n",
      "159 of 392 complete in 56.0600311756134 seconds\n",
      "160 of 392 complete in 60.167181730270386 seconds\n",
      "161 of 392 complete in 59.049859046936035 seconds\n",
      "162 of 392 complete in 58.60098457336426 seconds\n",
      "163 of 392 complete in 57.23213052749634 seconds\n",
      "164 of 392 complete in 55.820929527282715 seconds\n",
      "165 of 392 complete in 61.824270248413086 seconds\n",
      "166 of 392 complete in 57.80928659439087 seconds\n",
      "167 of 392 complete in 58.644636392593384 seconds\n",
      "168 of 392 complete in 57.83495020866394 seconds\n",
      "169 of 392 complete in 59.7371871471405 seconds\n",
      "170 of 392 complete in 61.52906250953674 seconds\n",
      "171 of 392 complete in 58.47300386428833 seconds\n",
      "172 of 392 complete in 59.83772301673889 seconds\n",
      "173 of 392 complete in 61.23979640007019 seconds\n",
      "174 of 392 complete in 64.50080251693726 seconds\n",
      "175 of 392 complete in 69.19714331626892 seconds\n",
      "176 of 392 complete in 66.0318386554718 seconds\n",
      "177 of 392 complete in 60.34945273399353 seconds\n",
      "178 of 392 complete in 59.328773975372314 seconds\n",
      "179 of 392 complete in 69.03802418708801 seconds\n",
      "180 of 392 complete in 57.63318705558777 seconds\n",
      "181 of 392 complete in 66.30761671066284 seconds\n",
      "182 of 392 complete in 60.040203332901 seconds\n",
      "183 of 392 complete in 61.01511478424072 seconds\n",
      "184 of 392 complete in 61.17701029777527 seconds\n",
      "185 of 392 complete in 60.52337908744812 seconds\n",
      "186 of 392 complete in 63.02925229072571 seconds\n",
      "187 of 392 complete in 58.59684729576111 seconds\n",
      "188 of 392 complete in 59.5479097366333 seconds\n",
      "189 of 392 complete in 60.452149391174316 seconds\n",
      "190 of 392 complete in 60.5875129699707 seconds\n",
      "191 of 392 complete in 62.51596450805664 seconds\n",
      "192 of 392 complete in 58.27899146080017 seconds\n",
      "193 of 392 complete in 59.4694299697876 seconds\n",
      "194 of 392 complete in 63.5988290309906 seconds\n",
      "195 of 392 complete in 58.04800820350647 seconds\n",
      "196 of 392 complete in 56.29635143280029 seconds\n",
      "197 of 392 complete in 63.102723836898804 seconds\n",
      "198 of 392 complete in 57.77179217338562 seconds\n",
      "199 of 392 complete in 59.343666076660156 seconds\n",
      "200 of 392 complete in 61.597890853881836 seconds\n",
      "201 of 392 complete in 55.79386258125305 seconds\n",
      "202 of 392 complete in 59.96044993400574 seconds\n",
      "203 of 392 complete in 59.47444295883179 seconds\n",
      "204 of 392 complete in 58.745548725128174 seconds\n",
      "205 of 392 complete in 57.07335925102234 seconds\n",
      "206 of 392 complete in 57.72788906097412 seconds\n",
      "207 of 392 complete in 58.18128705024719 seconds\n",
      "208 of 392 complete in 57.22203516960144 seconds\n",
      "209 of 392 complete in 60.00464940071106 seconds\n",
      "210 of 392 complete in 61.9203462600708 seconds\n",
      "211 of 392 complete in 58.75204801559448 seconds\n",
      "212 of 392 complete in 58.68907284736633 seconds\n",
      "213 of 392 complete in 58.178295850753784 seconds\n",
      "214 of 392 complete in 61.23742914199829 seconds\n",
      "215 of 392 complete in 58.7840621471405 seconds\n",
      "216 of 392 complete in 64.4527530670166 seconds\n",
      "217 of 392 complete in 65.7851037979126 seconds\n",
      "218 of 392 complete in 59.62624144554138 seconds\n",
      "219 of 392 complete in 59.52809238433838 seconds\n",
      "220 of 392 complete in 62.36052393913269 seconds\n",
      "221 of 392 complete in 61.587449073791504 seconds\n",
      "222 of 392 complete in 61.46149301528931 seconds\n",
      "223 of 392 complete in 60.77989864349365 seconds\n",
      "224 of 392 complete in 59.008129835128784 seconds\n",
      "225 of 392 complete in 63.99647331237793 seconds\n",
      "226 of 392 complete in 64.28434777259827 seconds\n",
      "227 of 392 complete in 58.53497076034546 seconds\n",
      "228 of 392 complete in 58.86114168167114 seconds\n",
      "229 of 392 complete in 55.75024700164795 seconds\n",
      "230 of 392 complete in 56.99976181983948 seconds\n",
      "231 of 392 complete in 58.63408446311951 seconds\n",
      "232 of 392 complete in 57.80948281288147 seconds\n",
      "233 of 392 complete in 58.02405858039856 seconds\n",
      "234 of 392 complete in 60.17177391052246 seconds\n",
      "235 of 392 complete in 59.78696966171265 seconds\n",
      "236 of 392 complete in 136.6559817790985 seconds\n",
      "237 of 392 complete in 154.49965643882751 seconds\n",
      "238 of 392 complete in 62.11992692947388 seconds\n",
      "239 of 392 complete in 142.52298617362976 seconds\n",
      "240 of 392 complete in 56.47450351715088 seconds\n",
      "241 of 392 complete in 58.88348388671875 seconds\n",
      "242 of 392 complete in 60.06370282173157 seconds\n",
      "243 of 392 complete in 61.13381814956665 seconds\n",
      "244 of 392 complete in 61.01093602180481 seconds\n",
      "245 of 392 complete in 59.937198638916016 seconds\n",
      "246 of 392 complete in 59.40505814552307 seconds\n",
      "247 of 392 complete in 58.42478322982788 seconds\n",
      "248 of 392 complete in 59.68736672401428 seconds\n",
      "249 of 392 complete in 58.22621703147888 seconds\n",
      "250 of 392 complete in 59.869853258132935 seconds\n",
      "251 of 392 complete in 57.967190980911255 seconds\n",
      "252 of 392 complete in 61.629002809524536 seconds\n",
      "253 of 392 complete in 58.69329619407654 seconds\n",
      "254 of 392 complete in 57.19837307929993 seconds\n",
      "255 of 392 complete in 56.80027389526367 seconds\n",
      "256 of 392 complete in 58.33543801307678 seconds\n",
      "257 of 392 complete in 57.17951536178589 seconds\n",
      "258 of 392 complete in 57.33427715301514 seconds\n",
      "259 of 392 complete in 58.99978566169739 seconds\n",
      "260 of 392 complete in 58.786054849624634 seconds\n",
      "261 of 392 complete in 57.91093373298645 seconds\n",
      "262 of 392 complete in 58.697553396224976 seconds\n",
      "263 of 392 complete in 57.010966062545776 seconds\n",
      "264 of 392 complete in 58.218628883361816 seconds\n",
      "265 of 392 complete in 59.51629328727722 seconds\n",
      "266 of 392 complete in 59.29080295562744 seconds\n",
      "267 of 392 complete in 59.447129011154175 seconds\n",
      "268 of 392 complete in 58.408491373062134 seconds\n",
      "269 of 392 complete in 62.95524191856384 seconds\n",
      "270 of 392 complete in 58.931666135787964 seconds\n",
      "271 of 392 complete in 61.48103666305542 seconds\n",
      "272 of 392 complete in 84.49720740318298 seconds\n",
      "273 of 392 complete in 69.06472444534302 seconds\n",
      "274 of 392 complete in 86.3922815322876 seconds\n",
      "275 of 392 complete in 61.36330580711365 seconds\n",
      "276 of 392 complete in 56.621277809143066 seconds\n",
      "277 of 392 complete in 58.1651074886322 seconds\n",
      "278 of 392 complete in 58.26651453971863 seconds\n",
      "279 of 392 complete in 57.99293088912964 seconds\n",
      "280 of 392 complete in 56.53580617904663 seconds\n",
      "281 of 392 complete in 58.303932905197144 seconds\n",
      "282 of 392 complete in 60.312047481536865 seconds\n",
      "283 of 392 complete in 79.23017692565918 seconds\n",
      "284 of 392 complete in 67.51067590713501 seconds\n",
      "285 of 392 complete in 67.29771113395691 seconds\n",
      "286 of 392 complete in 58.98721218109131 seconds\n",
      "287 of 392 complete in 58.444644927978516 seconds\n",
      "288 of 392 complete in 57.76079082489014 seconds\n",
      "289 of 392 complete in 56.71125864982605 seconds\n",
      "290 of 392 complete in 56.73159098625183 seconds\n",
      "291 of 392 complete in 56.76570439338684 seconds\n",
      "292 of 392 complete in 56.531893253326416 seconds\n",
      "293 of 392 complete in 56.65623331069946 seconds\n",
      "294 of 392 complete in 33.1558563709259 seconds\n",
      "295 of 392 complete in 36.90133213996887 seconds\n",
      "296 of 392 complete in 38.63742709159851 seconds\n",
      "297 of 392 complete in 43.07446074485779 seconds\n",
      "298 of 392 complete in 47.19792819023132 seconds\n",
      "299 of 392 complete in 43.188087463378906 seconds\n",
      "300 of 392 complete in 39.051568269729614 seconds\n",
      "301 of 392 complete in 43.693878412246704 seconds\n",
      "302 of 392 complete in 46.00050163269043 seconds\n",
      "303 of 392 complete in 41.7292685508728 seconds\n",
      "304 of 392 complete in 45.55727410316467 seconds\n",
      "305 of 392 complete in 41.667160987854004 seconds\n",
      "306 of 392 complete in 46.23301696777344 seconds\n",
      "307 of 392 complete in 41.262245893478394 seconds\n",
      "308 of 392 complete in 32.31903958320618 seconds\n",
      "309 of 392 complete in 34.2227828502655 seconds\n",
      "310 of 392 complete in 46.974456548690796 seconds\n",
      "311 of 392 complete in 47.035128355026245 seconds\n",
      "312 of 392 complete in 48.286407232284546 seconds\n",
      "313 of 392 complete in 56.49375033378601 seconds\n",
      "314 of 392 complete in 45.62700057029724 seconds\n",
      "315 of 392 complete in 47.88901996612549 seconds\n",
      "316 of 392 complete in 45.8138165473938 seconds\n",
      "317 of 392 complete in 45.523064613342285 seconds\n",
      "318 of 392 complete in 46.548616886138916 seconds\n",
      "319 of 392 complete in 47.29793453216553 seconds\n",
      "320 of 392 complete in 46.209354639053345 seconds\n",
      "321 of 392 complete in 45.69076871871948 seconds\n",
      "322 of 392 complete in 46.394474267959595 seconds\n",
      "323 of 392 complete in 45.13529872894287 seconds\n",
      "324 of 392 complete in 47.57059931755066 seconds\n",
      "325 of 392 complete in 45.40634322166443 seconds\n",
      "326 of 392 complete in 47.26082110404968 seconds\n",
      "327 of 392 complete in 45.59170460700989 seconds\n",
      "328 of 392 complete in 45.888567209243774 seconds\n",
      "329 of 392 complete in 47.793739557266235 seconds\n",
      "330 of 392 complete in 44.908796548843384 seconds\n",
      "331 of 392 complete in 45.637903928756714 seconds\n",
      "332 of 392 complete in 45.05297899246216 seconds\n",
      "333 of 392 complete in 49.6530339717865 seconds\n",
      "334 of 392 complete in 46.78322744369507 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 of 392 complete in 45.267879247665405 seconds\n",
      "336 of 392 complete in 45.78307557106018 seconds\n",
      "337 of 392 complete in 45.77750873565674 seconds\n",
      "338 of 392 complete in 44.89330434799194 seconds\n",
      "339 of 392 complete in 46.04755973815918 seconds\n",
      "340 of 392 complete in 46.8677442073822 seconds\n",
      "341 of 392 complete in 44.909703493118286 seconds\n",
      "342 of 392 complete in 47.824540853500366 seconds\n",
      "343 of 392 complete in 52.83918309211731 seconds\n",
      "344 of 392 complete in 44.90011167526245 seconds\n",
      "345 of 392 complete in 45.85874795913696 seconds\n",
      "346 of 392 complete in 45.09551119804382 seconds\n",
      "347 of 392 complete in 69.38450622558594 seconds\n",
      "348 of 392 complete in 54.897093772888184 seconds\n",
      "349 of 392 complete in 52.67980694770813 seconds\n",
      "350 of 392 complete in 45.08375597000122 seconds\n",
      "351 of 392 complete in 51.056915044784546 seconds\n",
      "352 of 392 complete in 49.5820152759552 seconds\n",
      "353 of 392 complete in 48.68724989891052 seconds\n",
      "354 of 392 complete in 53.37075448036194 seconds\n",
      "355 of 392 complete in 45.09384894371033 seconds\n",
      "356 of 392 complete in 45.324671268463135 seconds\n",
      "357 of 392 complete in 45.258766889572144 seconds\n",
      "358 of 392 complete in 45.377758741378784 seconds\n",
      "359 of 392 complete in 56.78291964530945 seconds\n",
      "360 of 392 complete in 50.020254611968994 seconds\n",
      "361 of 392 complete in 47.69980549812317 seconds\n",
      "362 of 392 complete in 45.74497580528259 seconds\n",
      "363 of 392 complete in 57.698747396469116 seconds\n",
      "364 of 392 complete in 45.23676633834839 seconds\n",
      "365 of 392 complete in 100.85835909843445 seconds\n",
      "366 of 392 complete in 101.08368182182312 seconds\n",
      "367 of 392 complete in 67.36560893058777 seconds\n",
      "368 of 392 complete in 50.93071484565735 seconds\n",
      "369 of 392 complete in 46.08702540397644 seconds\n",
      "370 of 392 complete in 44.503645181655884 seconds\n",
      "371 of 392 complete in 47.10054588317871 seconds\n",
      "372 of 392 complete in 56.31536149978638 seconds\n",
      "373 of 392 complete in 45.15524482727051 seconds\n",
      "374 of 392 complete in 48.47062039375305 seconds\n",
      "375 of 392 complete in 47.56655979156494 seconds\n",
      "376 of 392 complete in 45.975160360336304 seconds\n",
      "377 of 392 complete in 45.517242193222046 seconds\n",
      "378 of 392 complete in 44.91224765777588 seconds\n",
      "379 of 392 complete in 46.26204538345337 seconds\n",
      "380 of 392 complete in 45.60528564453125 seconds\n",
      "381 of 392 complete in 47.56654167175293 seconds\n",
      "382 of 392 complete in 47.053016662597656 seconds\n",
      "383 of 392 complete in 49.840731143951416 seconds\n",
      "384 of 392 complete in 45.83233165740967 seconds\n",
      "385 of 392 complete in 55.438477516174316 seconds\n",
      "386 of 392 complete in 47.46434450149536 seconds\n",
      "387 of 392 complete in 58.67270064353943 seconds\n",
      "388 of 392 complete in 47.98872518539429 seconds\n",
      "389 of 392 complete in 50.928640604019165 seconds\n",
      "390 of 392 complete in 56.630143880844116 seconds\n",
      "391 of 392 complete in 49.39120554924011 seconds\n",
      "392 of 392 complete in 575.2765870094299 seconds\n",
      "total runtime was 373.18712785243986 minutes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# runtime was 373.18712785243986 minutes\n",
    "arcpy.env.addOutputsToMap = False\n",
    "i = 1\n",
    "hucs = HUC14s\n",
    "list_length = len(hucs)\n",
    "HUC14_map = arcpy.MakeFeatureLayer_management(r'X:\\projects\\njwrap\\Data\\NJDEP\\Hydr_HUC14_bnd\\Hydr_HUC14_bnd.gdb\\Hydr_HUC14_bnd', \"HUC14_map\")\n",
    "pt_layer = arcpy.MakeFeatureLayer_management(os.path.join(scratch1, \"C1_starts_merge\"), \"C1_start_pts_layer\")\n",
    "agg_lines = os.path.join(scratch1, \"temp_C1HUC_test3\")\n",
    "error_list = [] #list of hucs caused an error\n",
    "\n",
    "start = time.time()\n",
    "for huc in hucs:\n",
    "    try:\n",
    "        start1 = time.time()\n",
    "        where = (\"HUC14 = '\" + huc +\"'\")\n",
    "        select_huc = arcpy.management.MakeFeatureLayer(HUC14_map, \"select_huc\", where)\n",
    "        selection = arcpy.management.SelectLayerByLocation(pt_layer, \"WITHIN\", select_huc, selection_type = \"NEW_SELECTION\")\n",
    "        output_pts = arcpy.management.CopyFeatures(selection, os.path.join(scratch1, \"huc_pts\"))#must be features, does not honor selection or layer\n",
    "        \n",
    "        #print(f\"C1 start points within {huc} selected\")\n",
    "        arcpy.Trace_tn(in_trace_network=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\", \n",
    "                       trace_type=\"UPSTREAM\", \n",
    "                       starting_points= output_pts, \n",
    "                       barriers=\"\", \n",
    "                       result_types=\"AGGREGATED_GEOMETRY\",\n",
    "                       clear_all_previous_trace_results = \"CLEAR_ALL_PREVIOUS_TRACE_RESULTS\",\n",
    "                       aggregated_lines = agg_lines)\n",
    "        #print(\"Upstream trace done\")\n",
    "        output_clip = arcpy.analysis.Clip(agg_lines, select_huc, os.path.join(scratch1, \"temp_huc14_clips\"))\n",
    "        arcpy.management.Append(output_clip, hucclips) #Append clip to new fc\n",
    "    except:\n",
    "        error_list.append(huc)\n",
    "    finally: \n",
    "        elapsed_time = time.time() - start1\n",
    "        print(f\"{i} of {list_length} complete in {elapsed_time} seconds\")\n",
    "        i = i+1\n",
    "end = (time.time() - start)/360\n",
    "error_list\n",
    "print(f\"total runtime was {end} hours\")\n",
    "arcpy.env.addOutputsToMap = True\n",
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = True\n",
    "error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Mopping up missed segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1 = arcpy.management.MakeFeatureLayer(nj2015_temp2, \"C1_streams\", where_clause = \"C1 = 1 And regulated = 1\")\n",
    "#arcpy.analysis.Erase(hucclips, \"C1_streams\", os.path.join(home, \"C1_upstream_huc_erase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1_and_upstream = arcpy.management.Merge([\"C1_streams\", \n",
    "                                          os.path.join(home, \"C1_upstream_huc_erase\")], \n",
    "                                         os.path.join(scratch1, \"C1_andupstream_merge\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, January 29, 2024 10:10:04 AM\",\"Succeeded at Monday, January 29, 2024 10:10:09 AM (Elapsed Time: 5.31 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_end_pts'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run upstream C1 from C1 endpoints\n",
    "arcpy.management.FeatureVerticesToPoints(\"C1_streams\", \n",
    "                                         os.path.join(scratch1,\"C1_end_pts\"), \n",
    "                                         'END') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, January 29, 2024 10:12:21 AM\",\"Succeeded at Monday, January 29, 2024 10:23:42 AM (Elapsed Time: 11 minutes 20 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\Trace_Results_Aggregated_Points'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trace all upstream for Trout Production Streams\n",
    "arcpy.Trace_tn(in_trace_network=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\", \n",
    "               trace_type=\"UPSTREAM\", \n",
    "               starting_points=os.path.join(scratch1,\"C1_end_pts\"), \n",
    "               barriers=\"\", \n",
    "               result_types=\"AGGREGATED_GEOMETRY\", \n",
    "               aggregated_lines = os.path.join(home, \"C1_upstream_trace_all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, January 29, 2024 11:03:01 AM\",\"Succeeded at Monday, January 29, 2024 11:03:09 AM (Elapsed Time: 7.71 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\non_C1_upstream_SP'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Capture any stubs that were clipped that shouldn't have been\n",
    "#After trace, erase trace from all upstream lines. \n",
    "arcpy.analysis.Erase(os.path.join(home, \"C1_upstream_trace_all\"), os.path.join(scratch1, \"C1_andupstream_merge\"), os.path.join(scratch1, \"non_C1_upstream\"))\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"non_C1_upstream\"), os.path.join(scratch1, \"non_C1_upstream_SP\"))\n",
    "\n",
    "\n",
    "#An alternative is to use segment ID or COMID. This could be good, but maybe many steps? Not sure how to implement\n",
    "#Spatial join Hucs IDs to original stream network OID to C1 upstream. Then spatial join hucs by count if count > 1 select and assign to original HUC . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUC14 in ('02020007020020', '02020007020030', '02020007010070', '02020007020060', '02040105040020')\n"
     ]
    }
   ],
   "source": [
    "#Erase HUCs not used to cut down buffer time. \n",
    "# Path to the Layer\n",
    "arcpy.management.MakeFeatureLayer(huc14s, \"huc14_lyr\")\n",
    "\n",
    "# Integer list of OBJECTID(s)\n",
    "test_hucs = ['02020007020020', '02020007020030', '02020007010070', '02020007020060', '02040105040020']\n",
    "shucs = \", \".join(f\"'{s}'\" for s in test_hucs)\n",
    "where_clause = f\"HUC14 IN ({shucs})\"\n",
    "\n",
    "print(where_clause)\n",
    "# Tool Execution\n",
    "#arcpy.management.SelectLayerByAttribute(lyr, \"NEW_SELECTION\", where_clause)‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍‍\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field does not exist\n"
     ]
    }
   ],
   "source": [
    "field_name = \"transfer_code\"\n",
    "target_lines = os.path.join(scratch1, \"non_C1_upstream_SP\")\n",
    "if len(arcpy.ListFields(target_lines, field_name)) == 0:\n",
    "    print(\"Field does not exist\")       \n",
    "else:\n",
    "    arcpy.management.DeleteField(target_lines, field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buffer0 = arcpy.analysis.Buffer(target_lines, \n",
    "                                os.path.join(scratch1,\"non_c1_buffer\"), \n",
    "                                \"1 Feet\", \n",
    "                                \"FULL\", \n",
    "                                \"ROUND\", \n",
    "                                \"ALL\", \n",
    "                                None, \n",
    "                                \"PLANAR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buffer1 = arcpy.management.MultipartToSinglepart(buffer0, os.path.join(scratch1,\"c1_upstream_buffer_MultipartToSi1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create composite non-c1 segments to select between a and upstream segments that are already short enough and don't need to be traced\n",
    "#https://gis.stackexchange.com/questions/174752/dissolve-a-polyline-feature-class-so-that-touching-features-dissolve-into-a-sing\n",
    "field_name = \"transfer_code\"\n",
    "target_lines = os.path.join(scratch1, \"non_C1_upstream_SP\")\n",
    "\n",
    "    \n",
    "#buffer0 = arcpy.analysis.Buffer(target_lines, os.path.join(scratch1,\"non_c1_buffer\"), \"1 Feet\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "#buffer1 = arcpy.management.MultipartToSinglepart(buffer0, os.path.join(scratch1,\"c1_upstream_buffer_MultipartToSi1\"))\n",
    "arcpy.management.CalculateField(buffer1, field_name, \"!OBJECTID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "buffer_join = arcpy.analysis.SpatialJoin(target_lines, \n",
    "                                         buffer1, \n",
    "                                         os.path.join(scratch1,\"non_c1_buffer_join\"), \n",
    "                                         \"JOIN_ONE_TO_ONE\", \n",
    "                                         \"KEEP_ALL\")\n",
    "non_C1_diss = arcpy.management.Dissolve(buffer_join, \n",
    "                                        os.path.join(scratch1, \"non_c1_buffer_Dissolve\"), \n",
    "                                        field_name, \n",
    "                                        None, \n",
    "                                        \"MULTI_PART\", \n",
    "                                        \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 12:41:01 PM\",\"Succeeded at Monday, February 12, 2024 12:41:06 PM (Elapsed Time: 4.62 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_andupstream_start_pts'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints(os.path.join(scratch1, \"C1_andupstream_merge\"), \n",
    "                                         os.path.join(scratch1,\"C1_andupstream_start_pts\"), \n",
    "                                         'START') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "c1_starts = arcpy.MakeFeatureLayer_management(os.path.join(scratch1,\"C1andupstream_start_pts\"), \"c1_starts_lyr\")\n",
    "non_c1_lyr = arcpy.MakeFeatureLayer_management(os.path.join(scratch1, \"non_c1_buffer_Dissolve\"), \"non_c1_disslyr\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 12:51:15 PM\",\"Succeeded at Monday, February 12, 2024 12:51:16 PM (Elapsed Time: 0.15 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'non_c1_disslyr'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select c1 upstream segments that might have been missed for flukey network reasons\n",
    "#Select any lines that intersect upstream trace or C1 start points that are less than a certain length.\n",
    "\n",
    "#Select non-cdw segments that intersect start point and are less than 5280'\n",
    "arcpy.management.SelectLayerByAttribute(non_c1_lyr, \"NEW_SELECTION\", \"Shape_Length < 4000\", None)\n",
    "arcpy.management.SelectLayerByLocation(non_c1_lyr, \"INTERSECT\", c1_starts, selection_type = \"SUBSET_SELECTION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 12:58:22 PM\",\"Succeeded at Monday, February 12, 2024 12:58:25 PM (Elapsed Time: 2.66 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_upstream_tips'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(non_c1_lyr, os.path.join(scratch1, \"C1_upstream_tips\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 1:00:20 PM\",\"Succeeded at Monday, February 12, 2024 1:00:21 PM (Elapsed Time: 1.44 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'non_c1_disslyr'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.SelectLayerByAttribute(non_c1_lyr, \"NEW_SELECTION\", \"Shape_Length < 4000\", None)\n",
    "arcpy.management.SelectLayerByLocation(non_c1_lyr, \"INTERSECT\", c1, selection_type = \"SUBSET_SELECTION\")\n",
    "arcpy.management.SelectLayerByLocation(non_c1_lyr, \"INTERSECT\", os.path.join(scratch1,\"C1_end_pts\"), selection_type = \"SUBSET_SELECTION\", invert_spatial_relationship = \"INVERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 1:11:30 PM\",\"Succeeded at Monday, February 12, 2024 1:11:33 PM (Elapsed Time: 2.57 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\C1_network_errors'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(non_c1_lyr, os.path.join(scratch1, \"C1_network_errors\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 1:16:41 PM\",\"Dissolving...\",\"Succeeded at Monday, February 12, 2024 1:17:16 PM (Elapsed Time: 34.81 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\C1_upstream_final'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(scratch1, \"C1_upstream_tips\"),\n",
    "                                          os.path.join(scratch1, \"C1_network_errors\"),\n",
    "                                          os.path.join(home, \"C1_upstream_huc_erase\")], \n",
    "                                         os.path.join(scratch1, \"C1_upstream_final\"))\n",
    "\n",
    "arcpy.management.Dissolve(os.path.join(scratch1, \"C1_upstream_final\"), \n",
    "                          os.path.join(home, \"C1_upstream_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 1:24:46 PM\",\"Succeeded at Monday, February 12, 2024 1:24:48 PM (Elapsed Time: 2.61 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\Riparian_Zone_Input_Layers.gdb\\\\C1_upstream'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(os.path.join(home, \"C1_upstream_final\"), os.path.join(background, \"C1_upstream\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create trace network for TM/CDW--needs to be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### TM/CDW combined split network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Set workspace and create variable for new copy of lines\n",
    "nj2015_temp3 = \"nhd_c1_split1\"\n",
    "streams_TN = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\stream_buffers1.gdb\\Stream_buffers\\TM_streams_network\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, September 5, 2023 11:39:15 AM\",\"Succeeded at Tuesday, September 5, 2023 11:39:21 AM (Elapsed Time: 6.53 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\scratch.gdb\\\\TM_start_pts'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dissolve lines and make starting points for TM generic\n",
    "arcpy.management.MakeFeatureLayer(nj2015_temp3, 'TM_streams', \"TM = 1 And regulated = 1\")\n",
    "arcpy.management.Dissolve('TM_streams', \"nhd_diss_TM\", ['GNIS_NAME', 'TM'], \"\", \"SINGLE_PART\", \"UNSPLIT_LINES\")\n",
    "in_features = \"nhd_diss_TM\"\n",
    "arcpy.management.FeatureVerticesToPoints(in_features, \"TM_start_pts\", 'START') #Create starting points by selecting segments from each category (cdw, c1, tp, tm) and creating a start point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Trace all upstream for Trout Maintenance Streams\n",
    "arcpy.env.workspace = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\"\n",
    "selected_streams = arcpy.Trace_tn(in_trace_network=\"streams_featureservice_Network\", \n",
    "                                  trace_type=\"UPSTREAM\", \n",
    "                                  starting_points=\"TM_start_pts\", \n",
    "                                  barriers=\"\", \n",
    "                                  result_types=\"AGGREGATED_GEOMETRY\", \n",
    "                                  aggregated_lines = os.path.join(scratch, \"TM_upstream_temp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, September 5, 2023 1:32:27 PM\",\"Succeeded at Tuesday, September 5, 2023 1:32:49 PM (Elapsed Time: 21.56 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\Hydr_NHD_2015.gdb\\\\Hydr_NHD_2015\\\\cdw_start_pts'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cdw upstream generic trace\n",
    "#Dissolve lines and make starting points for cdw generic\n",
    "arcpy.management.MakeFeatureLayer(nj2015_temp3, 'cdw_streams', \"all_cdw = 1 And regulated = 1\")\n",
    "arcpy.management.Dissolve('cdw_streams', \"nhd_diss_cdw\", ['GNIS_NAME', 'all_cdw'], \"\", \"SINGLE_PART\", \"UNSPLIT_LINES\")\n",
    "in_features = \"nhd_diss_cdw\"\n",
    "arcpy.management.FeatureVerticesToPoints(in_features, \"cdw_start_pts\", 'START') #Create starting points by selecting segments from each category (cdw, c1, tp, tm) and creating a start point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Trace all upstream for CDW Streams\n",
    "arcpy.env.workspace = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\"\n",
    "selected_streams = arcpy.Trace_tn(in_trace_network=\"streams_featureservice_Network\", \n",
    "                                  trace_type=\"UPSTREAM\", \n",
    "                                  starting_points=\"cdw_start_pts\", \n",
    "                                  barriers=\"\", \n",
    "                                  result_types=\"AGGREGATED_GEOMETRY\", \n",
    "                                  aggregated_lines = os.path.join(scratch, \"cdw_upstream_temp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Network set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# select TM and cdw upstream from stream network\n",
    "#generate points every 264'\n",
    "# split network by point\n",
    "# Create network and troubleshoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\stream_buffers.gdb\\Stream_buffers\\TM_all_upstream_264_split1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#SET UP TRACE NETWORK\n",
    "#Point along line every 264, split by points\n",
    "#Repair Geometry\n",
    "arcpy.management.RepairGeometry(r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\\TM_all_upstream_264_split1\", \"DELETE_NULL\", \"ESRI\")\n",
    "\n",
    "#Add attribute for shape length that isn't shape length that can be added to network\n",
    "#arcpy.management.CalculateField(r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\\TM_all_upstream_264_split1\", \"Segment_Length\", \"!Shape_Length!\", \"PYTHON3\", '', \"DOUBLE\", \"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "#Create trace network\n",
    "arcpy.tn.CreateTraceNetwork(r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\", \"TM_streams_network\", None, \"TM_all_upstream_264_split1 SIMPLE_EDGE\")\n",
    "\n",
    "#Add network attribute\n",
    "arcpy.tn.AddNetworkAttribute(r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\\TM_streams_network\", \"Segment_Length\", \"DOUBLE\", \"NULLABLE\")\n",
    "\n",
    "#Set network attribute\n",
    "arcpy.tn.SetNetworkAttribute(r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\\TM_streams_network\", \"Segment_Length\", \"TM_all_upstream_264_split1\", \"Segment_Length\")\n",
    "\n",
    "#Enable network topology\n",
    "#Crashes when run from python window. Run from Geoprocessing pane\n",
    "\n",
    "#There were a number of duplicate vertices. Unfortunately I could not find a way to fix these automatically and had to manually delete vertices. When deleting some vertices, it changed the line so that the trace points were no longer on the line. Points should be snapped back to the lines before tracing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\"\n",
    "\n",
    "#Select and copy CDW upstream lines. The ones from the trace are all dissolved so the generate points along lines tool fails\n",
    "arcpy.analysis.Clip(in_features, \"CDW_upstream\", \"CDW_upstream_clip\")\n",
    "\n",
    "#Generate points along lines every 264'\n",
    "arcpy.management.GeneratePointsAlongLines(\"CDW_upstream_clip\", r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\CDW_264_pts\", \"DISTANCE\", \"264 Feet\", None, None)\n",
    "\n",
    "#Split lines at 264' points \n",
    "arcpy.management.SplitLineAtPoint(\"CDW_upstream_clip\", \"CDW_264_pts\", \"CDW_264_split\", \"1 Feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arcpy.env.workspace = r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Create and troubleshoot TRACE NETWORK\n",
    "#Repair Geometry\n",
    "#arcpy.management.RepairGeometry(\"CDW_264_split\", \"DELETE_NULL\", \"ESRI\")\n",
    "\n",
    "#Add attribute for shape length that isn't shape length that can be added to network\n",
    "arcpy.management.CalculateField(\"CDW_264_split\", \"Segment_Length\", \"!Shape_Length!\", \"PYTHON3\", '', \"DOUBLE\", \"NO_ENFORCE_DOMAINS\")\n",
    "\n",
    "#Create trace network\n",
    "arcpy.tn.CreateTraceNetwork(r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\", \"CDW_streams_network\", None, \"CDW_264_split SIMPLE_EDGE\")\n",
    "\n",
    "#Add network attribute\n",
    "arcpy.tn.AddNetworkAttribute(\"CDW_streams_network\", \"Segment_Length\", \"DOUBLE\", \"NULLABLE\")\n",
    "\n",
    "#Set network attribute\n",
    "arcpy.tn.SetNetworkAttribute(\"CDW_streams_network\", \"Segment_Length\", \"CDW_264_split\", \"Segment_Length\")\n",
    "\n",
    "#Enable network topology\n",
    "arcpy.tn.EnableNetworkTopology(\"CDW_streams_network\") #Crashes when run from python window. Run from Geoprocessing pane\n",
    "\n",
    "#Check Line errors and edit as needed, see script below to delete duplicate vertices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Remove Duplicate Vertices from network if needed\n",
    "\n",
    "import arcpy\n",
    "import math\n",
    "#https://tereshenkov.wordpress.com/2017/11/08/removing-redundant-polyline-vertices-using-arcpy/\n",
    "#https://gis.stackexchange.com/questions/226982/delete-middle-vertex-of-multiple-3-vertex-polylines\n",
    "\n",
    "#Remove Duplicate Vertices\n",
    "\n",
    "#———————————————————————-\n",
    "def distance_between(p1, p2, p3, tolerance=0.1):\n",
    "    \"\"\"return True if 3 points are collinear.\n",
    "    tolerance value will decide whether lines are collinear; may need\n",
    "    to adjust it based on the XY tolerance value used for feature class\"\"\"\n",
    "    x1, y1 = p1[0], p1[1]\n",
    "    x2, y2 = p2[0], p2[1]\n",
    "    x3, y3 = p3[0], p3[1]\n",
    "    res1 = math.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    res2 = math.sqrt((x3 - x2)**2 + (y3 - y2)**2)\n",
    "    if (-tolerance <= res1 <= tolerance) or (-tolerance <= res2 <= tolerance):\n",
    "        return True\n",
    "\n",
    "\n",
    "#———————————————————————-\n",
    "def get_redundant_vertices(vertices):\n",
    "    \"\"\"get redundant vertices from a line shape vertices\"\"\"\n",
    "    indexes_of_vertices_to_remove = []\n",
    "    start_idx, middle_index, end_index = 0, 1, 2\n",
    "    for i in range(len(vertices)):\n",
    "        p1, p2, p3 = vertices[start_idx:end_index + 1]\n",
    "        if distance_between(p1, p2, p3):\n",
    "            indexes_of_vertices_to_remove.append(middle_index)\n",
    "\n",
    "        start_idx += 1\n",
    "        middle_index += 1\n",
    "        end_index += 1\n",
    "        if end_index == len(vertices):\n",
    "            break\n",
    "    return indexes_of_vertices_to_remove\n",
    "\n",
    "\n",
    "#———————————————————————-\n",
    "def clean_geometries(fc, densify_curves=False):\n",
    "    \"\"\"clean polyline features in the fc removing redundant vertices\"\"\"\n",
    "    in_sr = arcpy.Describe(fc).spatialReference.factoryCode\n",
    "\n",
    "    with arcpy.da.UpdateCursor(fc, ['SHAPE@', 'OID@']) as ucur:\n",
    "        for row in ucur:\n",
    "            #print(\"OBJECTID\", row[1])\n",
    "            cleaned_parts = []\n",
    "            shape = row[0]\n",
    "\n",
    "            for part in range(shape.partCount):\n",
    "                vertices = [(p.X, p.Y) for p in shape.getPart(part)]\n",
    "                if len(vertices) < 3:  #polyline's part consists of 2 vertices\n",
    "                    continue\n",
    "                vertices_to_remove = get_redundant_vertices(vertices)\n",
    "                vertices_to_keep = [\n",
    "                    val for idx, val in enumerate(vertices)\n",
    "                    if idx not in vertices_to_remove\n",
    "                ]\n",
    "                cleaned_part_as_array = arcpy.Array(\n",
    "                    [arcpy.Point(*coords) for coords in vertices_to_keep])\n",
    "                cleaned_parts.append(cleaned_part_as_array)\n",
    "\n",
    "            if cleaned_parts:\n",
    "                cleaned_shape = arcpy.Polyline(\n",
    "                    arcpy.Array(cleaned_parts), in_sr)\n",
    "                row[0] = cleaned_shape\n",
    "                ucur.updateRow(row)\n",
    "\n",
    "\n",
    "\n",
    "#fc = \"CDW_264_split\"  \n",
    "#clean_geometries(fc, densify_curves=False)\n",
    "workspace = r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\"\n",
    "with arcpy.da.Editor(workspace) as edit:\n",
    "    fc = r\"C:\\Users\\kdd56\\Documents\\Kate_GIS_Local\\Stream_buffers\\stream_buffers.gdb\\Stream_buffers\\CDW_264_split\"  \n",
    "    clean_geometries(fc, densify_curves=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Create starting points and run traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Trout Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### TM Trace Point selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Set workspace and create variable for new copy of lines\n",
    "nj2015_swqs = os.path.join(home,\"nhd_swqs_join\")\n",
    "nj2015_temp2 = os.path.join(home, \"stream_regs_with_exclusions_v2\")\n",
    "\n",
    "# See TM/CDW combined split network to run a generic upstream trace to help cut down the lines in the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arcpy.env.addOutputsToMap = True\n",
    "arcpy.management.MakeFeatureLayer(nj2015_swqs, 'TM_streams_lyr', \"TM = 1\")\n",
    "non_TM = arcpy.management.MakeFeatureLayer(nj2015_temp2, \"non-TM_lyr\", \"TM <> 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 11:27:10 AM\",\"Succeeded at Friday, January 26, 2024 11:27:14 AM (Elapsed Time: 4.13 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\TM_clip_end_pts'>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints('TM_streams_lyr', os.path.join(scratch1, \"TM_end_pts\"), 'END')\n",
    "arcpy.analysis.Buffer(os.path.join(scratch1, \"TM_end_pts\"), \n",
    "                      os.path.join(scratch1, \"TM_end_pt_buff\"), \n",
    "                      buffer_distance_or_field = '10 feet'\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 11:31:12 AM\",\"Succeeded at Friday, January 26, 2024 11:31:16 AM (Elapsed Time: 4.09 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\TM_clip_end_pts'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Erase('TM_streams_lyr', \n",
    "                    os.path.join(scratch1, \"TM_end_pt_buff\"), \n",
    "                   os.path.join(scratch1, \"TM_stream_buff_clips\"))\n",
    "arcpy.management.FeatureVerticesToPoints(os.path.join(scratch1, \"TM_stream_buff_clips\"), os.path.join(scratch1, \"TM_clip_end_pts\"), 'END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 11:33:33 AM\",\"Succeeded at Friday, January 26, 2024 11:33:33 AM (Elapsed Time: 0.60 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'TM_mod_pts_lyr'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints('TM_streams_lyr', os.path.join(scratch1, \"TM_start_pts\"), 'START')\n",
    "arcpy.management.Merge([os.path.join(scratch1, \"TM_start_pts\"), os.path.join(scratch1, \"TM_clip_end_pts\")], os.path.join(scratch1, \"TM_mod_pts\"))\n",
    "untraced_waterways = arcpy.management.MakeFeatureLayer(nj2015_polys, \"Delaware_and_canals\", where_clause = \"GNIS_NAME = 'Delaware River' Or GNIS_NAME = 'Delaware and Raritan Canal'\")\n",
    "\n",
    "mod_pts = arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"TM_mod_pts\"), \"TM_mod_pts_lyr\")\n",
    "arcpy.management.SelectLayerByLocation(mod_pts, \n",
    "                                       \"INTERSECT\", \n",
    "                                       untraced_waterways, \n",
    "                                       selection_type = \"NEW_SELECTION\", invert_spatial_relationship = \"INVERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is here. Let me clean that up for you\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 11:42:18 AM\",\"Succeeded at Friday, January 26, 2024 11:42:33 AM (Elapsed Time: 14.97 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\selected_TM_mods'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if arcpy.Exists(os.path.join(scratch1, \"selected_TM_mods\")):\n",
    "    print(\"File is here. Let me clean that up for you\")\n",
    "    arcpy.management.Delete(os.path.join(scratch1, \"selected_TM_mods\")) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "\n",
    "arcpy.management.CopyFeatures(mod_pts, os.path.join(scratch1, \"selected_TM_mods\"))\n",
    "arcpy.edit.Snap(os.path.join(scratch1, \"selected_TM_mods\"), \n",
    "                [[r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_from_featureservice\", 'EDGE', '3 feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class doesn't exist\n"
     ]
    }
   ],
   "source": [
    "#Get all upstream reaches\n",
    "streams_TN = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\"\n",
    "starting_pts = os.path.join(scratch1, \"selected_TM_mods\")\n",
    "agglines = os.path.join(lscratch, \"TM_upstream_all\")\n",
    "\n",
    "if arcpy.Exists(agglines):\n",
    "    print(\"File is here. Let me clean that up for you\")\n",
    "    arcpy.management.Delete(agglines) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "    \n",
    "selected_streams = arcpy.Trace_tn(in_trace_network=streams_TN, \n",
    "                                  trace_type=\"UPSTREAM\", \n",
    "                                  starting_points= starting_pts, \n",
    "                                  barriers=\"\", \n",
    "                                  result_types=\"AGGREGATED_GEOMETRY\", \n",
    "                                  aggregated_lines = agglines\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 11:45:05 AM\",\"Succeeded at Friday, January 26, 2024 11:45:16 AM (Elapsed Time: 11.15 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\TM_upstream_all_SP'>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Erase actual TM streams from upstream\n",
    "agglines = os.path.join(lscratch, \"TM_upstream_all\")\n",
    "arcpy.management.MultipartToSinglepart(agglines,os.path.join(scratch1, \"TM_upstream_all_SP\"))\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"TM_upstream_all_SP\"), 'TM_streams_lyr', os.path.join(scratch1, \"TM_upstream_erase\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 25, 2024 1:00:49 PM\",\"Succeeded at Thursday, January 25, 2024 1:00:49 PM (Elapsed Time: 0.26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'TM_streams_lyr'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(nj2015_swqs, 'TM_streams_lyr', \"TM = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field does not exists\n"
     ]
    }
   ],
   "source": [
    "#Create composite non-TM segments to select between a and upstream segments that are already short enough and don't need to be traced\n",
    "#https://gis.stackexchange.com/questions/174752/dissolve-a-polyline-feature-class-so-that-touching-features-dissolve-into-a-sing\n",
    "buffer = arcpy.analysis.Buffer(os.path.join(scratch1, \"TM_upstream_erase\"), os.path.join(scratch1,\"non_TM_buffer\"), \"1 Feet\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "buffer1 = arcpy.management.MultipartToSinglepart(buffer, os.path.join(scratch1,\"TM_upstream_buffer_MultipartToSi1\"))\n",
    "\n",
    "field_name = \"transfer_code\"\n",
    "target_lines = os.path.join(scratch1, \"TM_upstream_erase\")\n",
    "if len(arcpy.ListFields(target_lines, field_name)) == 0:\n",
    "    print(\"Field does not exists\")\n",
    "         \n",
    "else:\n",
    "    arcpy.management.DeleteField(target_lines, field_name)\n",
    "        \n",
    "arcpy.management.CalculateField(buffer1, field_name, \"!OBJECTID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "buffer_join = arcpy.analysis.SpatialJoin(target_lines, buffer1, os.path.join(scratch1,\"non_TM_buffer_join\"), \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\")\n",
    "non_TM_diss = arcpy.management.Dissolve(buffer_join, os.path.join(scratch1, \"non_TM_buffer_Dissolve\"), field_name, None, \"MULTI_PART\", \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, January 24, 2024 4:40:15 PM\",\"Succeeded at Wednesday, January 24, 2024 4:40:15 PM (Elapsed Time: 0.07 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'non_TM_disslyr'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Upstream startpoints of TM segments\n",
    "TM_starts = arcpy.MakeFeatureLayer_management(os.path.join(scratch1, \"TM_start_pts\"), \"TM_starts_lyr\")\n",
    "non_TM_lyr = arcpy.MakeFeatureLayer_management(non_TM_diss, \"non_TM_disslyr\")\n",
    "\n",
    "#Select non-TM segments that intersect start point and are less than 5280'\n",
    "arcpy.management.SelectLayerByAttribute(non_TM_lyr, \"NEW_SELECTION\", \"Shape_Length < 5280\", None)\n",
    "arcpy.management.SelectLayerByLocation(non_TM_lyr, \"INTERSECT\", TM_starts, selection_type = \"SUBSET_SELECTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if arcpy.Exists(os.path.join(home,\"TM_Trace_results_partbeween_upstream\")):\n",
    "    arcpy.management.Delete(os.path.join(home,\"TM_Trace_results_partbeween_upstream\")) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "bw_upstream = arcpy.management.CopyFeatures(non_TM_lyr, os.path.join(home,\"TM_Trace_results_partbeween_upstream1a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#These are TM upstream segments that can be added already. Any of the trace points that overlap the end points can be removed from the set\n",
    "os.path.join(home,\"TM_Trace_results_partbeween_upstream1a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 25, 2024 1:10:12 PM\",\"Succeeded at Thursday, January 25, 2024 1:10:19 PM (Elapsed Time: 6.17 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\tm_non_tm_int_SP'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arcpy.analysis.Intersect(['TM_streams_lyr', \"non-TM_lyr\"], os.path.join(scratch1, \"tm_non_tm_intersections\"), output_type = \"POINT\")\n",
    "#all_intersections = arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"tm_non_tm_intersections\"), os.path.join(scratch1, \"tm_non_tm_int_SP\"))\n",
    "#arcpy.edit.Snap(all_intersections, [[r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_from_featureservice\", 'EDGE', '3 feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 25, 2024 1:52:53 PM\",\"Succeeded at Thursday, January 25, 2024 1:52:54 PM (Elapsed Time: 0.14 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'TM_starts_lyr'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select start points that DO NOT intersect the between/upstream lines already seleced\n",
    "bw_upstream = os.path.join(home,\"TM_Trace_results_partbeween_upstream1a\")\n",
    "TM_int = arcpy.MakeFeatureLayer_management(all_intersections, \"TM_starts_lyr\")\n",
    "arcpy.management.SelectLayerByLocation(TM_int, \"INTERSECT\", bw_upstream, invert_spatial_relationship = \"INVERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is here. Let me get rid of that for you.\n"
     ]
    }
   ],
   "source": [
    "if arcpy.Exists(os.path.join(scratch1, \"selected_TM_trace_pts\")):\n",
    "    print(\"file is here. Let me get rid of that for you.\")\n",
    "    arcpy.management.Delete(os.path.join(scratch1, \"selected_TM_trace_pts\")) \n",
    "    arcpy.management.CopyFeatures(TM_int, \n",
    "                              os.path.join(scratch1, \"selected_TM_trace_pts\"))\n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "    arcpy.management.CopyFeatures(TM_int, \n",
    "                              os.path.join(scratch1, \"selected_TM_trace_pts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 25, 2024 1:56:04 PM\",\"Succeeded at Thursday, January 25, 2024 1:56:10 PM (Elapsed Time: 5.88 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\selected_TM_trace_pts'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Snap points to edited stream lines\n",
    "arcpy.edit.Snap(os.path.join(scratch1, \"selected_TM_trace_pts\"), \n",
    "                r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\stream_buffers_1.gdb\\Stream_buffers\\CDW_264_split EDGE '5 Feet'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Trace Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#List Starting Points\n",
    "TM_trace_pts1 = os.path.join(scratch1,\"selected_TM_trace_pts\")\n",
    "oid_fieldname = arcpy.Describe(TM_trace_pts1).OIDFieldName\n",
    "\n",
    "def unique_values(table , field):\n",
    "    with arcpy.da.SearchCursor(table, [field]) as cursor:\n",
    "        return sorted({row[0] for row in cursor})\n",
    "\n",
    "TM_trace_oids = unique_values(TM_trace_pts1, oid_fieldname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TM_trace_oids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Subset trace points if not tracing all in one loop\n",
    "#TM_trace_oids = unique_values(TM_trace_pts1, oid_fieldname)\n",
    "\n",
    "test_oids = [1, 3, 4, 5, 6, 8, 9, 10, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is here. I will destroy it for you\n",
      "start time is 14:04:10\n",
      "1 of 857 complete\n",
      "2 of 857 complete\n",
      "3 of 857 complete\n",
      "4 of 857 complete\n",
      "5 of 857 complete\n",
      "6 of 857 complete\n",
      "7 of 857 complete\n",
      "8 of 857 complete\n",
      "9 of 857 complete\n",
      "10 of 857 complete\n",
      "11 of 857 complete\n",
      "12 of 857 complete\n",
      "13 of 857 complete\n",
      "14 of 857 complete\n",
      "15 of 857 complete\n",
      "16 of 857 complete\n",
      "17 of 857 complete\n",
      "18 of 857 complete\n",
      "19 of 857 complete\n",
      "20 of 857 complete\n",
      "21 of 857 complete\n",
      "22 of 857 complete\n",
      "23 of 857 complete\n",
      "24 of 857 complete\n",
      "25 of 857 complete\n",
      "26 of 857 complete\n",
      "27 of 857 complete\n",
      "28 of 857 complete\n",
      "29 of 857 complete\n",
      "30 of 857 complete\n",
      "31 of 857 complete\n",
      "32 of 857 complete\n",
      "33 of 857 complete\n",
      "34 of 857 complete\n",
      "35 failed\n",
      "35 of 857 complete\n",
      "36 of 857 complete\n",
      "37 of 857 complete\n",
      "38 of 857 complete\n",
      "39 of 857 complete\n",
      "40 of 857 complete\n",
      "41 of 857 complete\n",
      "42 of 857 complete\n",
      "43 of 857 complete\n",
      "44 of 857 complete\n",
      "45 of 857 complete\n",
      "46 of 857 complete\n",
      "47 of 857 complete\n",
      "48 of 857 complete\n",
      "49 of 857 complete\n",
      "50 of 857 complete\n",
      "51 of 857 complete\n",
      "52 of 857 complete\n",
      "53 of 857 complete\n",
      "54 of 857 complete\n",
      "55 of 857 complete\n",
      "56 failed\n",
      "56 of 857 complete\n",
      "57 of 857 complete\n",
      "58 of 857 complete\n",
      "59 of 857 complete\n",
      "60 of 857 complete\n",
      "61 of 857 complete\n",
      "62 of 857 complete\n",
      "63 of 857 complete\n",
      "64 of 857 complete\n",
      "65 of 857 complete\n",
      "66 of 857 complete\n",
      "67 of 857 complete\n",
      "68 of 857 complete\n",
      "69 of 857 complete\n",
      "70 of 857 complete\n",
      "71 of 857 complete\n",
      "72 of 857 complete\n",
      "73 of 857 complete\n",
      "74 of 857 complete\n",
      "75 of 857 complete\n",
      "76 of 857 complete\n",
      "77 of 857 complete\n",
      "78 of 857 complete\n",
      "79 of 857 complete\n",
      "80 of 857 complete\n",
      "81 of 857 complete\n",
      "82 of 857 complete\n",
      "83 of 857 complete\n",
      "84 of 857 complete\n",
      "85 of 857 complete\n",
      "86 of 857 complete\n",
      "87 of 857 complete\n",
      "88 of 857 complete\n",
      "89 of 857 complete\n",
      "90 of 857 complete\n",
      "91 of 857 complete\n",
      "92 of 857 complete\n",
      "93 of 857 complete\n",
      "94 of 857 complete\n",
      "95 of 857 complete\n",
      "96 of 857 complete\n",
      "97 of 857 complete\n",
      "98 of 857 complete\n",
      "99 of 857 complete\n",
      "100 of 857 complete\n",
      "101 of 857 complete\n",
      "102 of 857 complete\n",
      "103 of 857 complete\n",
      "104 of 857 complete\n",
      "105 of 857 complete\n",
      "106 of 857 complete\n",
      "107 of 857 complete\n",
      "108 of 857 complete\n",
      "109 of 857 complete\n",
      "110 of 857 complete\n",
      "111 of 857 complete\n",
      "112 of 857 complete\n",
      "113 of 857 complete\n",
      "114 of 857 complete\n",
      "115 of 857 complete\n",
      "116 of 857 complete\n",
      "117 of 857 complete\n",
      "118 of 857 complete\n",
      "119 of 857 complete\n",
      "120 of 857 complete\n",
      "121 of 857 complete\n",
      "122 of 857 complete\n",
      "123 of 857 complete\n",
      "124 of 857 complete\n",
      "125 of 857 complete\n",
      "126 of 857 complete\n",
      "127 of 857 complete\n",
      "128 of 857 complete\n",
      "129 of 857 complete\n",
      "130 of 857 complete\n",
      "131 of 857 complete\n",
      "132 of 857 complete\n",
      "133 of 857 complete\n",
      "134 of 857 complete\n",
      "135 of 857 complete\n",
      "136 of 857 complete\n",
      "137 of 857 complete\n",
      "138 of 857 complete\n",
      "139 of 857 complete\n",
      "140 of 857 complete\n",
      "141 of 857 complete\n",
      "142 of 857 complete\n",
      "143 of 857 complete\n",
      "144 of 857 complete\n",
      "145 of 857 complete\n",
      "146 of 857 complete\n",
      "147 of 857 complete\n",
      "148 of 857 complete\n",
      "149 of 857 complete\n",
      "150 of 857 complete\n",
      "151 of 857 complete\n",
      "152 of 857 complete\n",
      "153 of 857 complete\n",
      "154 of 857 complete\n",
      "155 of 857 complete\n",
      "156 of 857 complete\n",
      "157 of 857 complete\n",
      "158 of 857 complete\n",
      "159 of 857 complete\n",
      "160 of 857 complete\n",
      "161 of 857 complete\n",
      "162 of 857 complete\n",
      "163 of 857 complete\n",
      "164 of 857 complete\n",
      "165 of 857 complete\n",
      "166 of 857 complete\n",
      "167 of 857 complete\n",
      "168 of 857 complete\n",
      "169 of 857 complete\n",
      "170 of 857 complete\n",
      "171 of 857 complete\n",
      "172 of 857 complete\n",
      "173 of 857 complete\n",
      "174 of 857 complete\n",
      "175 of 857 complete\n",
      "176 of 857 complete\n",
      "177 of 857 complete\n",
      "178 of 857 complete\n",
      "179 of 857 complete\n",
      "180 of 857 complete\n",
      "181 of 857 complete\n",
      "182 of 857 complete\n",
      "183 of 857 complete\n",
      "184 of 857 complete\n",
      "185 of 857 complete\n",
      "186 of 857 complete\n",
      "187 failed\n",
      "187 of 857 complete\n",
      "188 failed\n",
      "188 of 857 complete\n",
      "189 of 857 complete\n",
      "190 failed\n",
      "190 of 857 complete\n",
      "191 failed\n",
      "191 of 857 complete\n",
      "192 failed\n",
      "192 of 857 complete\n",
      "193 failed\n",
      "193 of 857 complete\n",
      "194 failed\n",
      "194 of 857 complete\n",
      "195 of 857 complete\n",
      "196 failed\n",
      "196 of 857 complete\n",
      "197 failed\n",
      "197 of 857 complete\n",
      "198 failed\n",
      "198 of 857 complete\n",
      "199 failed\n",
      "199 of 857 complete\n",
      "200 failed\n",
      "200 of 857 complete\n",
      "201 of 857 complete\n",
      "202 of 857 complete\n",
      "203 failed\n",
      "203 of 857 complete\n",
      "204 failed\n",
      "204 of 857 complete\n",
      "205 failed\n",
      "205 of 857 complete\n",
      "206 of 857 complete\n",
      "207 failed\n",
      "207 of 857 complete\n",
      "208 failed\n",
      "208 of 857 complete\n",
      "209 of 857 complete\n",
      "210 of 857 complete\n",
      "211 failed\n",
      "211 of 857 complete\n",
      "212 failed\n",
      "212 of 857 complete\n",
      "213 failed\n",
      "213 of 857 complete\n",
      "214 failed\n",
      "214 of 857 complete\n",
      "215 failed\n",
      "215 of 857 complete\n",
      "216 failed\n",
      "216 of 857 complete\n",
      "217 of 857 complete\n",
      "218 of 857 complete\n",
      "219 of 857 complete\n",
      "220 of 857 complete\n",
      "221 of 857 complete\n",
      "222 of 857 complete\n",
      "223 of 857 complete\n",
      "224 of 857 complete\n",
      "225 of 857 complete\n",
      "226 of 857 complete\n",
      "227 of 857 complete\n",
      "228 of 857 complete\n",
      "229 of 857 complete\n",
      "230 of 857 complete\n",
      "231 of 857 complete\n",
      "232 of 857 complete\n",
      "233 of 857 complete\n",
      "234 of 857 complete\n",
      "235 of 857 complete\n",
      "236 of 857 complete\n",
      "237 of 857 complete\n",
      "238 of 857 complete\n",
      "239 of 857 complete\n",
      "240 of 857 complete\n",
      "241 of 857 complete\n",
      "242 of 857 complete\n",
      "243 of 857 complete\n",
      "244 of 857 complete\n",
      "245 of 857 complete\n",
      "246 of 857 complete\n",
      "247 of 857 complete\n",
      "248 failed\n",
      "248 of 857 complete\n",
      "249 failed\n",
      "249 of 857 complete\n",
      "250 of 857 complete\n",
      "251 of 857 complete\n",
      "252 of 857 complete\n",
      "253 of 857 complete\n",
      "254 of 857 complete\n",
      "255 of 857 complete\n",
      "256 of 857 complete\n",
      "257 of 857 complete\n",
      "258 of 857 complete\n",
      "259 of 857 complete\n",
      "260 of 857 complete\n",
      "261 of 857 complete\n",
      "262 of 857 complete\n",
      "263 of 857 complete\n",
      "264 of 857 complete\n",
      "265 of 857 complete\n",
      "266 of 857 complete\n",
      "267 of 857 complete\n",
      "268 of 857 complete\n",
      "269 of 857 complete\n",
      "270 of 857 complete\n",
      "271 of 857 complete\n",
      "272 of 857 complete\n",
      "273 of 857 complete\n",
      "274 of 857 complete\n",
      "275 of 857 complete\n",
      "276 of 857 complete\n",
      "277 of 857 complete\n",
      "278 of 857 complete\n",
      "279 of 857 complete\n",
      "280 of 857 complete\n",
      "281 of 857 complete\n",
      "282 of 857 complete\n",
      "283 of 857 complete\n",
      "284 of 857 complete\n",
      "285 of 857 complete\n",
      "286 of 857 complete\n",
      "287 of 857 complete\n",
      "288 of 857 complete\n",
      "289 of 857 complete\n",
      "290 of 857 complete\n",
      "291 of 857 complete\n",
      "292 of 857 complete\n",
      "293 of 857 complete\n",
      "294 of 857 complete\n",
      "295 of 857 complete\n",
      "296 of 857 complete\n",
      "297 of 857 complete\n",
      "298 of 857 complete\n",
      "299 of 857 complete\n",
      "300 of 857 complete\n",
      "301 of 857 complete\n",
      "302 of 857 complete\n",
      "303 of 857 complete\n",
      "304 of 857 complete\n",
      "305 of 857 complete\n",
      "306 of 857 complete\n",
      "307 of 857 complete\n",
      "308 of 857 complete\n",
      "309 of 857 complete\n",
      "310 of 857 complete\n",
      "311 of 857 complete\n",
      "312 failed\n",
      "312 of 857 complete\n",
      "313 failed\n",
      "313 of 857 complete\n",
      "314 failed\n",
      "314 of 857 complete\n",
      "315 failed\n",
      "315 of 857 complete\n",
      "316 of 857 complete\n",
      "317 of 857 complete\n",
      "318 of 857 complete\n",
      "319 of 857 complete\n",
      "320 of 857 complete\n",
      "321 of 857 complete\n",
      "322 of 857 complete\n",
      "323 of 857 complete\n",
      "324 of 857 complete\n",
      "325 of 857 complete\n",
      "326 of 857 complete\n",
      "327 of 857 complete\n",
      "328 of 857 complete\n",
      "329 of 857 complete\n",
      "330 of 857 complete\n",
      "331 of 857 complete\n",
      "332 of 857 complete\n",
      "333 of 857 complete\n",
      "334 of 857 complete\n",
      "335 of 857 complete\n",
      "336 of 857 complete\n",
      "337 of 857 complete\n",
      "338 of 857 complete\n",
      "339 of 857 complete\n",
      "340 of 857 complete\n",
      "341 of 857 complete\n",
      "342 of 857 complete\n",
      "343 of 857 complete\n",
      "344 of 857 complete\n",
      "345 of 857 complete\n",
      "346 of 857 complete\n",
      "347 of 857 complete\n",
      "348 of 857 complete\n",
      "349 of 857 complete\n",
      "350 of 857 complete\n",
      "351 of 857 complete\n",
      "352 of 857 complete\n",
      "353 of 857 complete\n",
      "354 of 857 complete\n",
      "355 of 857 complete\n",
      "356 failed\n",
      "356 of 857 complete\n",
      "357 failed\n",
      "357 of 857 complete\n",
      "358 of 857 complete\n",
      "359 of 857 complete\n",
      "360 of 857 complete\n",
      "361 of 857 complete\n",
      "362 of 857 complete\n",
      "363 of 857 complete\n",
      "364 of 857 complete\n",
      "365 of 857 complete\n",
      "366 of 857 complete\n",
      "367 of 857 complete\n",
      "368 of 857 complete\n",
      "369 of 857 complete\n",
      "370 of 857 complete\n",
      "371 of 857 complete\n",
      "372 of 857 complete\n",
      "373 of 857 complete\n",
      "374 of 857 complete\n",
      "375 of 857 complete\n",
      "376 of 857 complete\n",
      "377 of 857 complete\n",
      "378 of 857 complete\n",
      "379 of 857 complete\n",
      "380 of 857 complete\n",
      "381 of 857 complete\n",
      "382 of 857 complete\n",
      "383 of 857 complete\n",
      "384 of 857 complete\n",
      "385 of 857 complete\n",
      "386 of 857 complete\n",
      "387 of 857 complete\n",
      "388 of 857 complete\n",
      "389 of 857 complete\n",
      "390 of 857 complete\n",
      "391 of 857 complete\n",
      "392 of 857 complete\n",
      "393 of 857 complete\n",
      "394 failed\n",
      "394 of 857 complete\n",
      "395 failed\n",
      "395 of 857 complete\n",
      "396 failed\n",
      "396 of 857 complete\n",
      "397 failed\n",
      "397 of 857 complete\n",
      "398 of 857 complete\n",
      "399 of 857 complete\n",
      "400 of 857 complete\n",
      "401 of 857 complete\n",
      "402 of 857 complete\n",
      "403 of 857 complete\n",
      "404 of 857 complete\n",
      "405 of 857 complete\n",
      "406 of 857 complete\n",
      "407 of 857 complete\n",
      "408 of 857 complete\n",
      "409 of 857 complete\n",
      "410 of 857 complete\n",
      "411 of 857 complete\n",
      "412 of 857 complete\n",
      "413 of 857 complete\n",
      "414 of 857 complete\n",
      "415 of 857 complete\n",
      "416 of 857 complete\n",
      "417 of 857 complete\n",
      "418 of 857 complete\n",
      "419 of 857 complete\n",
      "420 of 857 complete\n",
      "421 of 857 complete\n",
      "422 of 857 complete\n",
      "423 of 857 complete\n",
      "424 of 857 complete\n",
      "425 of 857 complete\n",
      "426 of 857 complete\n",
      "427 of 857 complete\n",
      "428 of 857 complete\n",
      "429 of 857 complete\n",
      "430 of 857 complete\n",
      "431 of 857 complete\n",
      "432 of 857 complete\n",
      "433 of 857 complete\n",
      "434 of 857 complete\n",
      "435 of 857 complete\n",
      "436 of 857 complete\n",
      "437 of 857 complete\n",
      "438 of 857 complete\n",
      "439 of 857 complete\n",
      "440 of 857 complete\n",
      "441 of 857 complete\n",
      "442 of 857 complete\n",
      "443 of 857 complete\n",
      "444 of 857 complete\n",
      "445 of 857 complete\n",
      "446 of 857 complete\n",
      "447 of 857 complete\n",
      "448 of 857 complete\n",
      "449 failed\n",
      "449 of 857 complete\n",
      "450 failed\n",
      "450 of 857 complete\n",
      "451 of 857 complete\n",
      "452 of 857 complete\n",
      "453 of 857 complete\n",
      "454 of 857 complete\n",
      "455 of 857 complete\n",
      "456 of 857 complete\n",
      "457 of 857 complete\n",
      "458 of 857 complete\n",
      "459 of 857 complete\n",
      "460 of 857 complete\n",
      "461 of 857 complete\n",
      "462 of 857 complete\n",
      "463 of 857 complete\n",
      "464 of 857 complete\n",
      "465 of 857 complete\n",
      "466 of 857 complete\n",
      "467 of 857 complete\n",
      "468 of 857 complete\n",
      "469 of 857 complete\n",
      "470 of 857 complete\n",
      "471 of 857 complete\n",
      "472 of 857 complete\n",
      "473 of 857 complete\n",
      "474 of 857 complete\n",
      "475 of 857 complete\n",
      "476 of 857 complete\n",
      "477 of 857 complete\n",
      "478 of 857 complete\n",
      "479 of 857 complete\n",
      "480 of 857 complete\n",
      "481 of 857 complete\n",
      "482 of 857 complete\n",
      "483 of 857 complete\n",
      "484 of 857 complete\n",
      "485 of 857 complete\n",
      "486 of 857 complete\n",
      "487 of 857 complete\n",
      "488 of 857 complete\n",
      "489 of 857 complete\n",
      "490 of 857 complete\n",
      "491 of 857 complete\n",
      "492 of 857 complete\n",
      "493 of 857 complete\n",
      "494 of 857 complete\n",
      "495 of 857 complete\n",
      "496 of 857 complete\n",
      "497 of 857 complete\n",
      "498 of 857 complete\n",
      "499 of 857 complete\n",
      "500 of 857 complete\n",
      "501 of 857 complete\n",
      "502 of 857 complete\n",
      "503 of 857 complete\n",
      "504 of 857 complete\n",
      "505 of 857 complete\n",
      "506 of 857 complete\n",
      "507 of 857 complete\n",
      "508 of 857 complete\n",
      "509 of 857 complete\n",
      "510 of 857 complete\n",
      "511 of 857 complete\n",
      "512 of 857 complete\n",
      "513 of 857 complete\n",
      "514 of 857 complete\n",
      "515 of 857 complete\n",
      "516 of 857 complete\n",
      "517 of 857 complete\n",
      "518 failed\n",
      "518 of 857 complete\n",
      "519 failed\n",
      "519 of 857 complete\n",
      "520 failed\n",
      "520 of 857 complete\n",
      "521 of 857 complete\n",
      "522 of 857 complete\n",
      "523 of 857 complete\n",
      "524 of 857 complete\n",
      "525 of 857 complete\n",
      "526 of 857 complete\n",
      "527 of 857 complete\n",
      "528 of 857 complete\n",
      "529 of 857 complete\n",
      "530 of 857 complete\n",
      "531 of 857 complete\n",
      "532 of 857 complete\n",
      "533 of 857 complete\n",
      "534 of 857 complete\n",
      "535 of 857 complete\n",
      "536 of 857 complete\n",
      "537 of 857 complete\n",
      "538 of 857 complete\n",
      "539 of 857 complete\n",
      "540 of 857 complete\n",
      "541 of 857 complete\n",
      "542 of 857 complete\n",
      "543 of 857 complete\n",
      "544 of 857 complete\n",
      "545 of 857 complete\n",
      "546 of 857 complete\n",
      "547 of 857 complete\n",
      "548 of 857 complete\n",
      "549 of 857 complete\n",
      "550 of 857 complete\n",
      "551 of 857 complete\n",
      "552 failed\n",
      "552 of 857 complete\n",
      "553 of 857 complete\n",
      "554 of 857 complete\n",
      "555 of 857 complete\n",
      "556 of 857 complete\n",
      "557 of 857 complete\n",
      "558 of 857 complete\n",
      "559 of 857 complete\n",
      "560 of 857 complete\n",
      "561 of 857 complete\n",
      "562 of 857 complete\n",
      "563 of 857 complete\n",
      "564 of 857 complete\n",
      "565 of 857 complete\n",
      "566 of 857 complete\n",
      "567 of 857 complete\n",
      "568 of 857 complete\n",
      "569 of 857 complete\n",
      "570 of 857 complete\n",
      "571 of 857 complete\n",
      "572 of 857 complete\n",
      "573 of 857 complete\n",
      "574 of 857 complete\n",
      "575 of 857 complete\n",
      "576 of 857 complete\n",
      "577 of 857 complete\n",
      "578 of 857 complete\n",
      "579 of 857 complete\n",
      "580 of 857 complete\n",
      "581 failed\n",
      "581 of 857 complete\n",
      "582 of 857 complete\n",
      "583 of 857 complete\n",
      "584 of 857 complete\n",
      "585 of 857 complete\n",
      "586 of 857 complete\n",
      "587 of 857 complete\n",
      "588 of 857 complete\n",
      "589 of 857 complete\n",
      "590 of 857 complete\n",
      "591 of 857 complete\n",
      "592 of 857 complete\n",
      "593 of 857 complete\n",
      "594 of 857 complete\n",
      "595 of 857 complete\n",
      "596 of 857 complete\n",
      "597 of 857 complete\n",
      "598 of 857 complete\n",
      "599 of 857 complete\n",
      "600 of 857 complete\n",
      "601 of 857 complete\n",
      "602 of 857 complete\n",
      "603 of 857 complete\n",
      "604 of 857 complete\n",
      "605 of 857 complete\n",
      "606 of 857 complete\n",
      "607 of 857 complete\n",
      "608 of 857 complete\n",
      "609 of 857 complete\n",
      "610 of 857 complete\n",
      "611 of 857 complete\n",
      "612 of 857 complete\n",
      "613 of 857 complete\n",
      "614 of 857 complete\n",
      "615 of 857 complete\n",
      "616 of 857 complete\n",
      "617 of 857 complete\n",
      "618 of 857 complete\n",
      "619 of 857 complete\n",
      "620 of 857 complete\n",
      "621 of 857 complete\n",
      "622 of 857 complete\n",
      "623 of 857 complete\n",
      "624 of 857 complete\n",
      "625 of 857 complete\n",
      "626 of 857 complete\n",
      "627 of 857 complete\n",
      "628 of 857 complete\n",
      "629 of 857 complete\n",
      "630 of 857 complete\n",
      "631 of 857 complete\n",
      "632 of 857 complete\n",
      "633 of 857 complete\n",
      "634 of 857 complete\n",
      "635 of 857 complete\n",
      "636 of 857 complete\n",
      "637 of 857 complete\n",
      "638 of 857 complete\n",
      "639 of 857 complete\n",
      "640 of 857 complete\n",
      "641 of 857 complete\n",
      "642 of 857 complete\n",
      "643 of 857 complete\n",
      "644 of 857 complete\n",
      "645 of 857 complete\n",
      "646 of 857 complete\n",
      "647 failed\n",
      "647 of 857 complete\n",
      "648 failed\n",
      "648 of 857 complete\n",
      "649 failed\n",
      "649 of 857 complete\n",
      "650 of 857 complete\n",
      "651 of 857 complete\n",
      "652 of 857 complete\n",
      "653 of 857 complete\n",
      "654 of 857 complete\n",
      "655 of 857 complete\n",
      "656 of 857 complete\n",
      "657 of 857 complete\n",
      "658 of 857 complete\n",
      "659 of 857 complete\n",
      "660 of 857 complete\n",
      "661 of 857 complete\n",
      "662 of 857 complete\n",
      "663 of 857 complete\n",
      "664 of 857 complete\n",
      "665 of 857 complete\n",
      "666 of 857 complete\n",
      "667 of 857 complete\n",
      "668 of 857 complete\n",
      "669 of 857 complete\n",
      "670 of 857 complete\n",
      "671 of 857 complete\n",
      "672 of 857 complete\n",
      "673 of 857 complete\n",
      "674 of 857 complete\n",
      "675 of 857 complete\n",
      "676 of 857 complete\n",
      "677 of 857 complete\n",
      "678 of 857 complete\n",
      "679 of 857 complete\n",
      "680 of 857 complete\n",
      "681 of 857 complete\n",
      "682 of 857 complete\n",
      "683 of 857 complete\n",
      "684 of 857 complete\n",
      "685 of 857 complete\n",
      "686 of 857 complete\n",
      "687 of 857 complete\n",
      "688 of 857 complete\n",
      "689 of 857 complete\n",
      "690 of 857 complete\n",
      "691 of 857 complete\n",
      "692 of 857 complete\n",
      "693 of 857 complete\n",
      "694 of 857 complete\n",
      "695 of 857 complete\n",
      "696 of 857 complete\n",
      "697 of 857 complete\n",
      "698 of 857 complete\n",
      "699 of 857 complete\n",
      "700 of 857 complete\n",
      "701 of 857 complete\n",
      "702 of 857 complete\n",
      "703 of 857 complete\n",
      "704 of 857 complete\n",
      "705 of 857 complete\n",
      "706 of 857 complete\n",
      "707 of 857 complete\n",
      "708 of 857 complete\n",
      "709 of 857 complete\n",
      "710 of 857 complete\n",
      "711 of 857 complete\n",
      "712 of 857 complete\n",
      "713 of 857 complete\n",
      "714 of 857 complete\n",
      "715 of 857 complete\n",
      "716 failed\n",
      "716 of 857 complete\n",
      "717 failed\n",
      "717 of 857 complete\n",
      "718 of 857 complete\n",
      "719 of 857 complete\n",
      "720 of 857 complete\n",
      "721 of 857 complete\n",
      "722 failed\n",
      "722 of 857 complete\n",
      "723 failed\n",
      "723 of 857 complete\n",
      "724 of 857 complete\n",
      "725 of 857 complete\n",
      "726 of 857 complete\n",
      "727 of 857 complete\n",
      "728 of 857 complete\n",
      "729 of 857 complete\n",
      "730 of 857 complete\n",
      "731 of 857 complete\n",
      "732 of 857 complete\n",
      "733 of 857 complete\n",
      "734 failed\n",
      "734 of 857 complete\n",
      "735 failed\n",
      "735 of 857 complete\n",
      "736 of 857 complete\n",
      "737 of 857 complete\n",
      "738 of 857 complete\n",
      "739 of 857 complete\n",
      "740 of 857 complete\n",
      "741 of 857 complete\n",
      "742 of 857 complete\n",
      "743 of 857 complete\n",
      "744 failed\n",
      "744 of 857 complete\n",
      "745 failed\n",
      "745 of 857 complete\n",
      "746 of 857 complete\n",
      "747 of 857 complete\n",
      "748 of 857 complete\n",
      "749 of 857 complete\n",
      "750 of 857 complete\n",
      "751 of 857 complete\n",
      "752 of 857 complete\n",
      "753 of 857 complete\n",
      "754 failed\n",
      "754 of 857 complete\n",
      "755 failed\n",
      "755 of 857 complete\n",
      "756 of 857 complete\n",
      "757 of 857 complete\n",
      "758 of 857 complete\n",
      "759 of 857 complete\n",
      "760 of 857 complete\n",
      "761 of 857 complete\n",
      "762 of 857 complete\n",
      "763 of 857 complete\n",
      "764 of 857 complete\n",
      "765 of 857 complete\n",
      "766 failed\n",
      "766 of 857 complete\n",
      "767 failed\n",
      "767 of 857 complete\n",
      "768 of 857 complete\n",
      "769 of 857 complete\n",
      "770 of 857 complete\n",
      "771 of 857 complete\n",
      "772 of 857 complete\n",
      "773 of 857 complete\n",
      "774 of 857 complete\n",
      "775 of 857 complete\n",
      "776 of 857 complete\n",
      "777 of 857 complete\n",
      "778 failed\n",
      "778 of 857 complete\n",
      "779 failed\n",
      "779 of 857 complete\n",
      "780 failed\n",
      "780 of 857 complete\n",
      "781 failed\n",
      "781 of 857 complete\n",
      "782 failed\n",
      "782 of 857 complete\n",
      "783 failed\n",
      "783 of 857 complete\n",
      "784 failed\n",
      "784 of 857 complete\n",
      "785 failed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785 of 857 complete\n",
      "786 of 857 complete\n",
      "787 of 857 complete\n",
      "788 of 857 complete\n",
      "789 of 857 complete\n",
      "790 of 857 complete\n",
      "791 of 857 complete\n",
      "792 of 857 complete\n",
      "793 of 857 complete\n",
      "794 of 857 complete\n",
      "795 of 857 complete\n",
      "796 of 857 complete\n",
      "797 of 857 complete\n",
      "798 of 857 complete\n",
      "799 of 857 complete\n",
      "800 of 857 complete\n",
      "801 of 857 complete\n",
      "802 of 857 complete\n",
      "803 of 857 complete\n",
      "804 of 857 complete\n",
      "805 of 857 complete\n",
      "806 of 857 complete\n",
      "807 of 857 complete\n",
      "808 of 857 complete\n",
      "809 of 857 complete\n",
      "810 of 857 complete\n",
      "811 of 857 complete\n",
      "812 of 857 complete\n",
      "813 of 857 complete\n",
      "814 of 857 complete\n",
      "815 of 857 complete\n",
      "816 of 857 complete\n",
      "817 of 857 complete\n",
      "818 of 857 complete\n",
      "819 of 857 complete\n",
      "820 of 857 complete\n",
      "821 of 857 complete\n",
      "822 of 857 complete\n",
      "823 of 857 complete\n",
      "824 of 857 complete\n",
      "825 of 857 complete\n",
      "826 of 857 complete\n",
      "827 of 857 complete\n",
      "828 of 857 complete\n",
      "829 of 857 complete\n",
      "830 of 857 complete\n",
      "831 of 857 complete\n",
      "832 of 857 complete\n",
      "833 of 857 complete\n",
      "834 of 857 complete\n",
      "835 of 857 complete\n",
      "836 of 857 complete\n",
      "837 failed\n",
      "837 of 857 complete\n",
      "838 of 857 complete\n",
      "839 failed\n",
      "839 of 857 complete\n",
      "840 failed\n",
      "840 of 857 complete\n",
      "841 failed\n",
      "841 of 857 complete\n",
      "842 failed\n",
      "842 of 857 complete\n",
      "843 of 857 complete\n",
      "844 of 857 complete\n",
      "845 failed\n",
      "845 of 857 complete\n",
      "846 failed\n",
      "846 of 857 complete\n",
      "847 of 857 complete\n",
      "848 of 857 complete\n",
      "849 failed\n",
      "849 of 857 complete\n",
      "850 failed\n",
      "850 of 857 complete\n",
      "851 failed\n",
      "851 of 857 complete\n",
      "852 of 857 complete\n",
      "853 of 857 complete\n",
      "854 of 857 complete\n",
      "855 of 857 complete\n",
      "856 of 857 complete\n",
      "857 of 857 complete\n",
      "[35, 56, 187, 188, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 203, 204, 205, 207, 208, 211, 212, 213, 214, 215, 216, 248, 249, 312, 313, 314, 315, 356, 357, 394, 395, 396, 397, 449, 450, 518, 519, 520, 552, 581, 647, 648, 649, 716, 717, 722, 723, 734, 735, 744, 745, 754, 755, 766, 767, 778, 779, 780, 781, 782, 783, 784, 785, 837, 839, 840, 841, 842, 845, 846, 849, 850, 851]\n",
      "17:06:19\n",
      "loop took 182.1539209206899 minutes to run\n"
     ]
    }
   ],
   "source": [
    "#Inputs\n",
    "TM_trace_pts1 = os.path.join(scratch1,\"selected_TM_trace_pts\")\n",
    "oid_list = TM_trace_oids\n",
    "agglines = os.path.join(lscratch, \"TM_trace_results_part1\")\n",
    "\n",
    "\n",
    "#Set up\n",
    "if arcpy.Exists(agglines):\n",
    "    print(\"file is here. I will destroy it for you\")\n",
    "    arcpy.management.Delete(agglines) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "#select upstream 1 mile\n",
    "arcpy.env.addOutputsToMap = True\n",
    "oid_fieldname = arcpy.Describe(TM_trace_pts1).OIDFieldName\n",
    "i = 1\n",
    "list_length = len(oid_list)\n",
    "error_list_TM = [] #list of point oid that caused an error\n",
    "\n",
    "t = time.localtime()\n",
    "start_time = time.strftime(\"%H:%M:%S\", t)\n",
    "t1 = time.time()\n",
    "print(f\"start time is {start_time}\")\n",
    "      \n",
    "for pt in oid_list:\n",
    "    try:\n",
    "        where = f\"{oid_fieldname} = {pt}\"\n",
    "        start_pt = arcpy.conversion.ExportFeatures(TM_trace_pts1, os.path.join(lscratch,\"temp_point\"), where) \n",
    "        arcpy.tn.Trace(\n",
    "            in_trace_network=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\stream_buffers_1.gdb\\Stream_buffers\\CDW_streams_network\",\n",
    "            trace_type=\"UPSTREAM\",\n",
    "            starting_points= start_pt,\n",
    "            barriers=\"TN_Temp_Barriers\",\n",
    "            path_direction=\"NO_DIRECTION\",\n",
    "            shortest_path_network_attribute_name=\"\",\n",
    "            include_barriers=\"INCLUDE_BARRIERS\",\n",
    "            validate_consistency=\"VALIDATE_CONSISTENCY\",\n",
    "            ignore_barriers_at_starting_points=\"DO_NOT_IGNORE_BARRIERS_AT_STARTING_POINTS\",\n",
    "            allow_indeterminate_flow=\"IGNORE_INDETERMINATE_FLOW\",\n",
    "            condition_barriers=None,\n",
    "            function_barriers=\"ADD Segment_Length IS_GREATER_THAN_OR_EQUAL_TO 5280 true\",\n",
    "            traversability_scope=\"BOTH_JUNCTIONS_AND_EDGES\",\n",
    "            functions=None,\n",
    "            output_conditions=None,\n",
    "            result_types=\"AGGREGATED_GEOMETRY\",\n",
    "            selection_type=\"NEW_SELECTION\",\n",
    "            clear_all_previous_trace_results=\"DO_NOT_CLEAR_ALL_PREVIOUS_TRACE_RESULTS\",\n",
    "            trace_name=\"\",\n",
    "            aggregated_points=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\RiparianZones_20240109.gdb\\Trace_Results_Aggregated_Points\",\n",
    "            aggregated_lines= agglines, \n",
    "            out_network_layer=None\n",
    "        )#The output geometry from the current trace operation will be appended to the feature classes storing aggregated geometry.\n",
    "    except:\n",
    "        print(f\"{pt} failed\")\n",
    "        error_list_TM.append(pt)\n",
    "    finally:\n",
    "        print(f\"{i} of {list_length} complete\")\n",
    "        i = i+1\n",
    "print(error_list_TM)\n",
    "\n",
    "t = time.localtime()\n",
    "end_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(end_time)\n",
    "t2 = time.time()\n",
    "elapsed_time = ((t2 - t1)/60)\n",
    "print(f\"loop took {elapsed_time} minutes to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Error list\n",
    "\n",
    "[35, 56, 187, 188, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 203, 204, 205, 207, 208, 211, 212, 213, 214, 215, 216, 248, 249, 312, 313, 314, 315, 356, 357, 394, 395, 396, 397, 449, 450, 518, 519, 520, 552, 581, 647, 648, 649, 716, 717, 722, 723, 734, 735, 744, 745, 754, 755, 766, 767, 778, 779, 780, 781, 782, 783, 784, 785, 837, 839, 840, 841, 842, 845, 846, 849, 850, 851]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 25, 2024 10:43:20 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, January 25, 2024 10:43:29 PM (Elapsed Time: 8.93 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\TM_trace_results_erase'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get just the upstream lines with the TM removed\n",
    "agglines = os.path.join(lscratch, \"TM_trace_results_part1\")\n",
    "arcpy.analysis.Erase(agglines, \"TM_streams_lyr\", os.path.join(home, \"TM_trace_results_erase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, January 25, 2024 10:44:07 PM\",\"Succeeded at Thursday, January 25, 2024 10:44:08 PM (Elapsed Time: 0.26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'TM_trace_lyr'>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find any untraced points\n",
    "TM_trace_pts1 = os.path.join(scratch1, \"selected_TM_trace_pts\")\n",
    "\n",
    "arcpy.management.MakeFeatureLayer(TM_trace_pts1, \"TM_trace_lyr\")\n",
    "arcpy.management.SelectLayerByLocation(\"TM_trace_lyr\", \"INTERSECT\", os.path.join(home, \"TM_trace_results_erase\"), invert_spatial_relationship = \"INVERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final_TM_pts = arcpy.management.CopyFeatures(\"TM_trace_lyr\", os.path.join(scratch1, \"TM_temp\"))\n",
    "#arcpy.edit.Snap(final_TM_pts, [[r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_from_featureservice\", 'END', '5 feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#List Starting Points\n",
    "oid_fieldname = arcpy.Describe(final_TM_pts).OIDFieldName\n",
    "\n",
    "def unique_values(table , field):\n",
    "    with arcpy.da.SearchCursor(table, [field]) as cursor:\n",
    "        return sorted({row[0] for row in cursor})\n",
    "\n",
    "TM_trace_oids1 = unique_values(final_TM_pts, oid_fieldname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TM_trace_oids1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class doesn't exist\n",
      "start time is 22:52:49\n",
      "1 of 192 complete\n",
      "2 of 192 complete\n",
      "3 of 192 complete\n",
      "4 of 192 complete\n",
      "5 of 192 complete\n",
      "6 of 192 complete\n",
      "7 of 192 complete\n",
      "8 failed\n",
      "8 of 192 complete\n",
      "9 of 192 complete\n",
      "10 of 192 complete\n",
      "11 of 192 complete\n",
      "12 of 192 complete\n",
      "13 of 192 complete\n",
      "14 of 192 complete\n",
      "15 of 192 complete\n",
      "16 of 192 complete\n",
      "17 of 192 complete\n",
      "18 of 192 complete\n",
      "19 of 192 complete\n",
      "20 of 192 complete\n",
      "21 of 192 complete\n",
      "22 of 192 complete\n",
      "23 of 192 complete\n",
      "24 of 192 complete\n",
      "25 of 192 complete\n",
      "26 of 192 complete\n",
      "27 of 192 complete\n",
      "28 of 192 complete\n",
      "29 of 192 complete\n",
      "30 of 192 complete\n",
      "31 of 192 complete\n",
      "32 of 192 complete\n",
      "33 of 192 complete\n",
      "34 of 192 complete\n",
      "35 of 192 complete\n",
      "36 of 192 complete\n",
      "37 of 192 complete\n",
      "38 of 192 complete\n",
      "39 of 192 complete\n",
      "40 of 192 complete\n",
      "41 of 192 complete\n",
      "42 of 192 complete\n",
      "43 of 192 complete\n",
      "44 of 192 complete\n",
      "45 of 192 complete\n",
      "46 of 192 complete\n",
      "47 of 192 complete\n",
      "48 of 192 complete\n",
      "49 of 192 complete\n",
      "50 of 192 complete\n",
      "51 of 192 complete\n",
      "52 of 192 complete\n",
      "53 of 192 complete\n",
      "54 of 192 complete\n",
      "55 of 192 complete\n",
      "56 of 192 complete\n",
      "57 of 192 complete\n",
      "58 of 192 complete\n",
      "59 of 192 complete\n",
      "60 of 192 complete\n",
      "61 of 192 complete\n",
      "62 of 192 complete\n",
      "63 of 192 complete\n",
      "64 of 192 complete\n",
      "65 of 192 complete\n",
      "66 of 192 complete\n",
      "67 of 192 complete\n",
      "68 of 192 complete\n",
      "69 of 192 complete\n",
      "70 of 192 complete\n",
      "71 of 192 complete\n",
      "72 of 192 complete\n",
      "73 of 192 complete\n",
      "74 of 192 complete\n",
      "75 of 192 complete\n",
      "76 of 192 complete\n",
      "77 of 192 complete\n",
      "78 of 192 complete\n",
      "79 of 192 complete\n",
      "80 of 192 complete\n",
      "81 of 192 complete\n",
      "82 of 192 complete\n",
      "83 of 192 complete\n",
      "84 of 192 complete\n",
      "85 of 192 complete\n",
      "86 of 192 complete\n",
      "87 of 192 complete\n",
      "88 of 192 complete\n",
      "89 of 192 complete\n",
      "90 of 192 complete\n",
      "91 of 192 complete\n",
      "92 of 192 complete\n",
      "93 of 192 complete\n",
      "94 of 192 complete\n",
      "95 of 192 complete\n",
      "96 of 192 complete\n",
      "97 of 192 complete\n",
      "98 of 192 complete\n",
      "99 of 192 complete\n",
      "100 of 192 complete\n",
      "101 of 192 complete\n",
      "102 of 192 complete\n",
      "103 of 192 complete\n",
      "104 of 192 complete\n",
      "105 of 192 complete\n",
      "106 of 192 complete\n",
      "107 of 192 complete\n",
      "108 of 192 complete\n",
      "109 of 192 complete\n",
      "110 of 192 complete\n",
      "111 of 192 complete\n",
      "112 of 192 complete\n",
      "113 of 192 complete\n",
      "114 of 192 complete\n",
      "115 of 192 complete\n",
      "116 of 192 complete\n",
      "117 of 192 complete\n",
      "118 of 192 complete\n",
      "119 of 192 complete\n",
      "120 of 192 complete\n",
      "121 of 192 complete\n",
      "122 of 192 complete\n",
      "123 of 192 complete\n",
      "124 of 192 complete\n",
      "125 of 192 complete\n",
      "126 of 192 complete\n",
      "127 of 192 complete\n",
      "128 of 192 complete\n",
      "129 of 192 complete\n",
      "130 of 192 complete\n",
      "131 of 192 complete\n",
      "132 of 192 complete\n",
      "133 of 192 complete\n",
      "134 of 192 complete\n",
      "135 of 192 complete\n",
      "136 of 192 complete\n",
      "137 of 192 complete\n",
      "138 of 192 complete\n",
      "139 of 192 complete\n",
      "140 of 192 complete\n",
      "141 of 192 complete\n",
      "142 of 192 complete\n",
      "143 of 192 complete\n",
      "144 of 192 complete\n",
      "145 of 192 complete\n",
      "146 of 192 complete\n",
      "147 of 192 complete\n",
      "148 of 192 complete\n",
      "149 of 192 complete\n",
      "150 of 192 complete\n",
      "151 of 192 complete\n",
      "152 of 192 complete\n",
      "153 of 192 complete\n",
      "154 of 192 complete\n",
      "155 of 192 complete\n",
      "156 of 192 complete\n",
      "157 of 192 complete\n",
      "158 of 192 complete\n",
      "159 of 192 complete\n",
      "160 of 192 complete\n",
      "161 of 192 complete\n",
      "162 of 192 complete\n",
      "163 of 192 complete\n",
      "164 of 192 complete\n",
      "165 of 192 complete\n",
      "166 of 192 complete\n",
      "167 of 192 complete\n",
      "168 of 192 complete\n",
      "169 of 192 complete\n",
      "170 of 192 complete\n",
      "171 of 192 complete\n",
      "172 of 192 complete\n",
      "173 of 192 complete\n",
      "174 of 192 complete\n",
      "175 of 192 complete\n",
      "176 of 192 complete\n",
      "177 of 192 complete\n",
      "178 of 192 complete\n",
      "179 of 192 complete\n",
      "180 of 192 complete\n",
      "181 of 192 complete\n",
      "182 of 192 complete\n",
      "183 of 192 complete\n",
      "184 of 192 complete\n",
      "185 of 192 complete\n",
      "186 of 192 complete\n",
      "187 of 192 complete\n",
      "188 of 192 complete\n",
      "189 of 192 complete\n",
      "190 of 192 complete\n",
      "191 of 192 complete\n",
      "192 of 192 complete\n",
      "[8]\n",
      "23:41:09\n",
      "loop took 48.33464921712876 minutes to run\n"
     ]
    }
   ],
   "source": [
    "#Inputs\n",
    "final_TM_pts = os.path.join(scratch1, \"TM_temp\")\n",
    "oid_list = TM_trace_oids1\n",
    "agglines = os.path.join(lscratch, \"TM_trace_results_part2\")\n",
    "\n",
    "\n",
    "#Set up\n",
    "if arcpy.Exists(agglines):\n",
    "    print(\"file is here. I will destroy it for you\")\n",
    "    arcpy.management.Delete(agglines) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "#select upstream 1 mile\n",
    "arcpy.env.addOutputsToMap = True\n",
    "\n",
    "oid_fieldname = arcpy.Describe(final_TM_pts).OIDFieldName\n",
    "i = 1\n",
    "list_length = len(oid_list)\n",
    "error_list_TM = [] #list of point oid that caused an error\n",
    "t = time.localtime()\n",
    "start_time = time.strftime(\"%H:%M:%S\", t)\n",
    "t1 = time.time()\n",
    "print(f\"start time is {start_time}\")\n",
    "\n",
    "for pt in oid_list:\n",
    "    try:\n",
    "        where = f\"{oid_fieldname} = {pt}\"\n",
    "        start_pt = arcpy.conversion.ExportFeatures(final_TM_pts, os.path.join(scratch1,\"temp_point\"), where) \n",
    "        #print(\"Upstream trace done\")\n",
    "        arcpy.tn.Trace(\n",
    "            in_trace_network=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\",\n",
    "            trace_type=\"UPSTREAM\",\n",
    "            starting_points=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\scratch1.gdb\\temp_point\",\n",
    "            barriers=\"TN_Temp_Barriers\",\n",
    "            path_direction=\"NO_DIRECTION\",\n",
    "            shortest_path_network_attribute_name=\"\",\n",
    "            include_barriers=\"INCLUDE_BARRIERS\",\n",
    "            validate_consistency=\"VALIDATE_CONSISTENCY\",\n",
    "            ignore_barriers_at_starting_points=\"DO_NOT_IGNORE_BARRIERS_AT_STARTING_POINTS\",\n",
    "            allow_indeterminate_flow=\"IGNORE_INDETERMINATE_FLOW\",\n",
    "            condition_barriers=None,\n",
    "            function_barriers=\"ADD 'Shape length' IS_GREATER_THAN_OR_EQUAL_TO 5280 true\",\n",
    "            traversability_scope=\"BOTH_JUNCTIONS_AND_EDGES\",\n",
    "            functions=None,\n",
    "            output_conditions=None,\n",
    "            result_types=\"AGGREGATED_GEOMETRY\",\n",
    "            selection_type=\"NEW_SELECTION\",\n",
    "            clear_all_previous_trace_results=\"DO_NOT_CLEAR_ALL_PREVIOUS_TRACE_RESULTS\",\n",
    "            trace_name=\"\",\n",
    "            aggregated_points=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\RiparianZones_20240109.gdb\\Trace_Results_Aggregated_Points\",\n",
    "            aggregated_lines= agglines, #os.path.join(lscratch,\"TM_trace_part2\"),\n",
    "            out_network_layer=None)#The output geometry from the current trace operation will be appended to the feature classes storing aggregated geometry.\n",
    "    except:\n",
    "        print(f\"{pt} failed\")\n",
    "        error_list_TM.append(pt)\n",
    "    finally:\n",
    "        print(f\"{i} of {list_length} complete\")\n",
    "        i = i+1\n",
    "print(error_list_TM)\n",
    "\n",
    "t = time.localtime()\n",
    "end_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(end_time)\n",
    "t2 = time.time()\n",
    "elapsed_time = ((t2 - t1)/60)\n",
    "print(f\"loop took {elapsed_time} minutes to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 10:53:06 AM\",\"Dissolving...\",\"Succeeded at Friday, January 26, 2024 10:53:14 AM (Elapsed Time: 7.59 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\TM_Trace_results_all_dissolved'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge all results files\n",
    "#arcpy.management.Merge([os.path.join(home, \"TM_Trace_results_partbeween_upstream1a\"), os.path.join(lscratch, \"TM_trace_results_part1\"), os.path.join(lscratch,\"TM_trace_part2\")], os.path.join(home, \"TM_Trace_results_all_merged\"))\n",
    "arcpy.management.Dissolve(os.path.join(home, \"TM_Trace_results_all_merged\"), os.path.join(home,\"TM_Trace_results_all_dissolved\"), multi_part = \"SINGLE_PART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 11:58:08 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Friday, January 26, 2024 11:58:15 AM (Elapsed Time: 6.95 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\TM_trace_results_erase'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Erase(os.path.join(home,\"TM_Trace_results_all_dissolved\"), 'TM_streams_lyr', os.path.join(home, \"TM_trace_results_erase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 11:58:18 AM\",\"Succeeded at Friday, January 26, 2024 11:58:21 AM (Elapsed Time: 3.04 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'TM_1mile_upstream'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Erase TM lines from upstream traces\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(home, \"TM_trace_results_erase\"), \"TM_1mile_upstream\")\n",
    "arcpy.management.SelectLayerByLocation(\"TM_1mile_upstream\", \"SHARE_A_LINE_SEGMENT_WITH\", os.path.join(scratch1, \"TM_upstream_all_SP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 12:01:47 PM\",\"Succeeded at Friday, January 26, 2024 12:01:49 PM (Elapsed Time: 2.79 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\TM_1mile_upstream_final'>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(\"TM_1mile_upstream\", os.path.join(home, \"TM_1mile_upstream_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, February 12, 2024 1:26:37 PM\",\"Succeeded at Monday, February 12, 2024 1:26:39 PM (Elapsed Time: 2.19 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\Riparian_Zone_Input_Layers.gdb\\\\TM_upstream'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(os.path.join(home, \"TM_1mile_upstream_final\"), os.path.join(background, \"TM_upstream\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### CDW--Species Critically Dependent on the Watercourse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### CDW Trace Point selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Set workspace and create variable for new copy of lines\n",
    "nj2015_swqs = os.path.join(home,\"nhd_swqs_join\")\n",
    "nj2015_temp2 = os.path.join(home, \"stream_regs_with_exclusions_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "arcpy.env.addOutputsToMap = True\n",
    "arcpy.management.MakeFeatureLayer(nj2015_temp2, 'cdw_streams_lyr', where_clause = \"all_cdw = 1 And regulated = 1\")\n",
    "non_cdw = arcpy.management.MakeFeatureLayer(nj2015_temp2, \"non-cdw_lyr\", where_clause = \"all_cdw <> 1 Or regulated <> 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 3:39:03 PM\",\"Succeeded at Tuesday, February 20, 2024 3:39:08 PM (Elapsed Time: 4.83 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_clip_end_pts'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints('cdw_streams_lyr', os.path.join(scratch1, \"cdw_end_pts\"), 'END')\n",
    "arcpy.analysis.Buffer(os.path.join(scratch1, \"cdw_end_pts\"), \n",
    "                      os.path.join(scratch1, \"cdw_end_pt_buff\"), \n",
    "                      buffer_distance_or_field = '10 feet'\n",
    "                     )\n",
    "arcpy.analysis.Erase('cdw_streams_lyr', \n",
    "                    os.path.join(scratch1, \"cdw_end_pt_buff\"), \n",
    "                   os.path.join(scratch1, \"cdw_stream_buff_clips\"))\n",
    "arcpy.management.FeatureVerticesToPoints(os.path.join(scratch1, \"cdw_stream_buff_clips\"), os.path.join(scratch1, \"cdw_clip_end_pts\"), 'END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 2:21:30 PM\",\"Succeeded at Friday, January 26, 2024 2:21:35 PM (Elapsed Time: 4.34 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_mod_pts'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints('cdw_streams_lyr', os.path.join(scratch1, \"cdw_start_pts\"), 'START')\n",
    "arcpy.management.Merge([os.path.join(scratch1, \"cdw_start_pts\"), os.path.join(scratch1, \"cdw_clip_end_pts\")], os.path.join(scratch1, \"cdw_mod_pts\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if arcpy.Exists(os.path.join(scratch1, \"selected_cdw_mods\")):\n",
    "    print(\"File is here. Let me clean that up for you\")\n",
    "    arcpy.management.Delete(os.path.join(scratch1, \"selected_cdw_mods\")) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "\n",
    "arcpy.management.CopyFeatures(mod_pts, os.path.join(scratch1, \"selected_cdw_mods\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 2:23:03 PM\",\"Succeeded at Friday, January 26, 2024 2:24:06 PM (Elapsed Time: 1 minutes 3 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_mod_pts'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.edit.Snap(os.path.join(scratch1, \"cdw_mod_pts\"), \n",
    "                [[r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_from_featureservice\", 'EDGE', '5 feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class doesn't exist\n"
     ]
    }
   ],
   "source": [
    "#Get all upstream reaches\n",
    "streams_TN = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_featureservice_Network\"\n",
    "starting_pts = os.path.join(scratch1, \"cdw_mod_pts\")\n",
    "agglines = os.path.join(lscratch, \"cdw_upstream_all\")\n",
    "\n",
    "if arcpy.Exists(agglines):\n",
    "    print(\"File is here. Let me clean that up for you\")\n",
    "    arcpy.management.Delete(agglines) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "    \n",
    "selected_streams = arcpy.Trace_tn(in_trace_network=streams_TN, \n",
    "                                  trace_type=\"UPSTREAM\", \n",
    "                                  starting_points= starting_pts, \n",
    "                                  barriers=\"\", \n",
    "                                  result_types=\"AGGREGATED_GEOMETRY\", \n",
    "                                  aggregated_lines = agglines\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 2:40:17 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Friday, January 26, 2024 2:41:10 PM (Elapsed Time: 52.70 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_upstream_erase'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Erase actual cdw streams from upstream\n",
    "agglines = os.path.join(lscratch, \"cdw_upstream_all\")\n",
    "arcpy.management.MultipartToSinglepart(agglines,os.path.join(scratch1, \"cdw_upstream_all_SP\"))\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"cdw_upstream_all_SP\"), 'cdw_streams_lyr', os.path.join(scratch1, \"cdw_upstream_erase\"))\n",
    "arcpy.management.RepairGeometry(os.path.join(scratch1, \"cdw_upstream_erase\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field does not exist\n"
     ]
    }
   ],
   "source": [
    "#Create composite non-cdw segments to select between a and upstream segments that are already short enough and don't need to be traced\n",
    "#https://gis.stackexchange.com/questions/174752/dissolve-a-polyline-feature-class-so-that-touching-features-dissolve-into-a-sing\n",
    "\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"cdw_upstream_erase\"), os.path.join(scratch1, \"cdw_upstream_erase_SP\"))\n",
    "\n",
    "field_name = \"transfer_code\"\n",
    "target_lines = os.path.join(scratch1, \"cdw_upstream_erase_SP\")\n",
    "if len(arcpy.ListFields(target_lines, field_name)) == 0:\n",
    "    print(\"Field does not exist\")       \n",
    "else:\n",
    "    arcpy.management.DeleteField(target_lines, field_name)\n",
    "    \n",
    "buffer = arcpy.analysis.Buffer(target_lines, os.path.join(scratch1,\"non_cdw_buffer\"), \"1 Feet\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "buffer1 = arcpy.management.MultipartToSinglepart(os.path.join(scratch1,\"non_cdw_buffer\"), os.path.join(scratch1,\"cdw_upstream_buffer_MultipartToSi1\"))\n",
    "arcpy.management.CalculateField(buffer1, field_name, \"!OBJECTID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "buffer_join = arcpy.analysis.SpatialJoin(target_lines, \n",
    "                                         buffer1, \n",
    "                                         os.path.join(scratch1,\"non_cdw_buffer_join\"), \n",
    "                                         \"JOIN_ONE_TO_ONE\", \n",
    "                                         \"KEEP_ALL\")\n",
    "non_cdw_diss = arcpy.management.Dissolve(buffer_join, \n",
    "                                        os.path.join(scratch1, \"non_cdw_buffer_diss\"), \n",
    "                                        field_name, \n",
    "                                        None, \n",
    "                                        \"MULTI_PART\", \n",
    "                                        \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, February 14, 2024 3:25:42 PM\",\"Succeeded at Wednesday, February 14, 2024 3:25:44 PM (Elapsed Time: 1.41 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'non_cdw_disslyr'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select cdw upstream segments that already meet the criteria\n",
    "#cdw_starts = arcpy.MakeFeatureLayer_management(os.path.join(scratch1, \"cdw_start_pts\"), \"cdw_starts_lyr\")\n",
    "non_cdw_lyr = arcpy.MakeFeatureLayer_management(os.path.join(scratch1,\"non_cdw_buffer_diss\"), \"non_cdw_disslyr\")\n",
    "\n",
    "#Select non-cdw segments that intersect cdw but not the end point and are less than 5280'\n",
    "arcpy.management.SelectLayerByAttribute(non_cdw_lyr, \"NEW_SELECTION\", \"Shape_Length < 5280\", None)\n",
    "#arcpy.management.SelectLayerByLocation(non_cdw_lyr, \"INTERSECT\", cdw_starts, selection_type = \"SUBSET_SELECTION\")\n",
    "arcpy.management.SelectLayerByLocation(non_cdw_lyr, \"INTERSECT\", \"cdw_streams_lyr\", selection_type = \"SUBSET_SELECTION\")\n",
    "arcpy.management.SelectLayerByLocation(non_cdw_lyr, \"INTERSECT\", os.path.join(scratch1, \"cdw_end_pts\"), selection_type = \"SUBSET_SELECTION\", invert_spatial_relationship = \"INVERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class doesn't exist\n"
     ]
    }
   ],
   "source": [
    "if arcpy.Exists(os.path.join(home,\"cdw_Trace_results_partbeween_upstream\")):\n",
    "    arcpy.management.Delete(os.path.join(home,\"cdw_Trace_results_partbeween_upstream\")) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "bw_upstream = arcpy.management.CopyFeatures(non_cdw_lyr, os.path.join(home,\"cdw_Trace_results_partbeween_upstream\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#These are cdw upstream segments that can be added already. Any of the trace points that overlap the end points can be removed from the set\n",
    "os.path.join(home,\"cdw_Trace_results_partbeween_upstream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 8:31:02 PM\",\"Succeeded at Friday, January 26, 2024 8:31:40 PM (Elapsed Time: 37.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_non_cdw_int_SP'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the set of points at the intersection between cdw and non-cdw\n",
    "arcpy.analysis.Intersect(['cdw_streams_lyr', non_cdw], os.path.join(scratch1, \"cdw_non_cdw_intersections\"), output_type = \"POINT\")\n",
    "all_intersections = arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"cdw_non_cdw_intersections\"), os.path.join(scratch1, \"cdw_non_cdw_int_SP\"))\n",
    "arcpy.edit.Snap(all_intersections, [[r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\streams_from_featureservice\", 'EDGE', '5 feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 8:31:49 PM\",\"Succeeded at Friday, January 26, 2024 8:31:49 PM (Elapsed Time: 0.51 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'cdw_int_pts_lyr'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select start points that DO NOT intersect the between/upstream lines already seleced\n",
    "bw_upstream = os.path.join(home,\"cdw_Trace_results_partbeween_upstream\")\n",
    "cdw_int = arcpy.MakeFeatureLayer_management(all_intersections, \"cdw_int_pts_lyr\")\n",
    "arcpy.management.SelectLayerByLocation(cdw_int, \"INTERSECT\", bw_upstream, invert_spatial_relationship = \"INVERT\")\n",
    "arcpy.management.SelectLayerByLocation(cdw_int, \"INTERSECT\", \n",
    "                                       os.path.join(scratch1, \"cdw_end_pts\"), \n",
    "                                       selection_type = \"SUBSET_SELECTION\", \n",
    "                                       invert_spatial_relationship = \"INVERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature class doesn't exist\n"
     ]
    }
   ],
   "source": [
    "if arcpy.Exists(os.path.join(scratch1, \"selected_cdw_trace_pts\")):\n",
    "    print(\"file is here. Let me get rid of that for you.\")\n",
    "    arcpy.management.Delete(os.path.join(scratch1, \"selected_cdw_trace_pts\")) \n",
    "    arcpy.management.CopyFeatures(cdw_int, \n",
    "                              os.path.join(scratch1, \"selected_cdw_trace_pts\"))\n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "    arcpy.management.CopyFeatures(cdw_int, \n",
    "                              os.path.join(scratch1, \"selected_cdw_trace_pts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, January 26, 2024 8:39:50 PM\",\"Succeeded at Friday, January 26, 2024 8:39:58 PM (Elapsed Time: 7.90 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\selected_cdw_trace_pts'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Snap points to edited stream lines\n",
    "arcpy.edit.Snap(os.path.join(scratch1, \"selected_cdw_trace_pts\"), \n",
    "                r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\stream_buffers_1.gdb\\Stream_buffers\\CDW_264_split EDGE '5 Feet'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Network trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Get list of CDWstart points to trace\n",
    "cdw_trace_pts1 = os.path.join(scratch1, \"selected_cdw_trace_pts\")\n",
    "oid_fieldname = arcpy.Describe(cdw_trace_pts1).OIDFieldName\n",
    "\n",
    "def unique_values(table , field):\n",
    "    with arcpy.da.SearchCursor(table, [field]) as cursor:\n",
    "        return sorted({row[0] for row in cursor})\n",
    "\n",
    "cdw_start_oids = unique_values(cdw_trace_pts1, oid_fieldname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1419"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cdw_start_oids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Subset trace points if not tracing all in one loop\n",
    "#TM_trace_oids = unique_values(TM_trace_pts1, oid_fieldname)\n",
    "\n",
    "test_oids = [1, 3, 4, 5, 6, 8, 9, 10, 11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is here. I will destroy it for you\n",
      "start time is 20:54:09\n",
      "1 of 1419 complete\n",
      "2 of 1419 complete\n",
      "3 of 1419 complete\n",
      "4 of 1419 complete\n",
      "5 of 1419 complete\n",
      "6 of 1419 complete\n",
      "7 of 1419 complete\n",
      "8 of 1419 complete\n",
      "9 of 1419 complete\n",
      "10 of 1419 complete\n",
      "11 of 1419 complete\n",
      "12 of 1419 complete\n",
      "13 of 1419 complete\n",
      "14 of 1419 complete\n",
      "15 of 1419 complete\n",
      "16 of 1419 complete\n",
      "17 of 1419 complete\n",
      "18 of 1419 complete\n",
      "19 of 1419 complete\n",
      "20 of 1419 complete\n",
      "21 of 1419 complete\n",
      "22 of 1419 complete\n",
      "23 of 1419 complete\n",
      "24 of 1419 complete\n",
      "25 of 1419 complete\n",
      "26 of 1419 complete\n",
      "27 of 1419 complete\n",
      "28 of 1419 complete\n",
      "29 of 1419 complete\n",
      "30 of 1419 complete\n",
      "31 of 1419 complete\n",
      "32 of 1419 complete\n",
      "33 of 1419 complete\n",
      "34 of 1419 complete\n",
      "35 of 1419 complete\n",
      "36 of 1419 complete\n",
      "37 of 1419 complete\n",
      "38 of 1419 complete\n",
      "39 of 1419 complete\n",
      "40 of 1419 complete\n",
      "41 failed\n",
      "41 of 1419 complete\n",
      "42 of 1419 complete\n",
      "43 of 1419 complete\n",
      "44 of 1419 complete\n",
      "45 of 1419 complete\n",
      "46 of 1419 complete\n",
      "47 of 1419 complete\n",
      "48 of 1419 complete\n",
      "49 of 1419 complete\n",
      "50 of 1419 complete\n",
      "51 of 1419 complete\n",
      "52 of 1419 complete\n",
      "53 of 1419 complete\n",
      "54 of 1419 complete\n",
      "55 of 1419 complete\n",
      "56 of 1419 complete\n",
      "57 of 1419 complete\n",
      "58 of 1419 complete\n",
      "59 of 1419 complete\n",
      "60 of 1419 complete\n",
      "61 of 1419 complete\n",
      "62 of 1419 complete\n",
      "63 of 1419 complete\n",
      "64 of 1419 complete\n",
      "65 of 1419 complete\n",
      "66 of 1419 complete\n",
      "67 of 1419 complete\n",
      "68 of 1419 complete\n",
      "69 of 1419 complete\n",
      "70 of 1419 complete\n",
      "71 of 1419 complete\n",
      "72 of 1419 complete\n",
      "73 failed\n",
      "73 of 1419 complete\n",
      "74 of 1419 complete\n",
      "75 failed\n",
      "75 of 1419 complete\n",
      "76 of 1419 complete\n",
      "77 of 1419 complete\n",
      "78 of 1419 complete\n",
      "79 of 1419 complete\n",
      "80 of 1419 complete\n",
      "81 of 1419 complete\n",
      "82 of 1419 complete\n",
      "83 of 1419 complete\n",
      "84 of 1419 complete\n",
      "85 of 1419 complete\n",
      "86 of 1419 complete\n",
      "87 of 1419 complete\n",
      "88 of 1419 complete\n",
      "89 of 1419 complete\n",
      "90 of 1419 complete\n",
      "91 of 1419 complete\n",
      "92 of 1419 complete\n",
      "93 of 1419 complete\n",
      "94 of 1419 complete\n",
      "95 of 1419 complete\n",
      "96 failed\n",
      "96 of 1419 complete\n",
      "97 of 1419 complete\n",
      "98 of 1419 complete\n",
      "99 of 1419 complete\n",
      "100 of 1419 complete\n",
      "101 of 1419 complete\n",
      "102 of 1419 complete\n",
      "103 of 1419 complete\n",
      "104 of 1419 complete\n",
      "105 of 1419 complete\n",
      "106 of 1419 complete\n",
      "107 of 1419 complete\n",
      "108 of 1419 complete\n",
      "109 of 1419 complete\n",
      "110 of 1419 complete\n",
      "111 of 1419 complete\n",
      "112 of 1419 complete\n",
      "113 of 1419 complete\n",
      "114 of 1419 complete\n",
      "115 of 1419 complete\n",
      "116 of 1419 complete\n",
      "117 of 1419 complete\n",
      "118 of 1419 complete\n",
      "119 of 1419 complete\n",
      "120 of 1419 complete\n",
      "121 of 1419 complete\n",
      "122 of 1419 complete\n",
      "123 of 1419 complete\n",
      "124 of 1419 complete\n",
      "125 of 1419 complete\n",
      "126 of 1419 complete\n",
      "127 of 1419 complete\n",
      "128 failed\n",
      "128 of 1419 complete\n",
      "129 of 1419 complete\n",
      "130 failed\n",
      "130 of 1419 complete\n",
      "131 of 1419 complete\n",
      "132 failed\n",
      "132 of 1419 complete\n",
      "133 of 1419 complete\n",
      "134 of 1419 complete\n",
      "135 of 1419 complete\n",
      "136 of 1419 complete\n",
      "137 of 1419 complete\n",
      "138 of 1419 complete\n",
      "139 of 1419 complete\n",
      "140 of 1419 complete\n",
      "141 of 1419 complete\n",
      "142 of 1419 complete\n",
      "143 of 1419 complete\n",
      "144 of 1419 complete\n",
      "145 of 1419 complete\n",
      "146 of 1419 complete\n",
      "147 of 1419 complete\n",
      "148 of 1419 complete\n",
      "149 of 1419 complete\n",
      "150 of 1419 complete\n",
      "151 of 1419 complete\n",
      "152 of 1419 complete\n",
      "153 of 1419 complete\n",
      "154 of 1419 complete\n",
      "155 of 1419 complete\n",
      "156 of 1419 complete\n",
      "157 of 1419 complete\n",
      "158 of 1419 complete\n",
      "159 of 1419 complete\n",
      "160 of 1419 complete\n",
      "161 of 1419 complete\n",
      "162 of 1419 complete\n",
      "163 of 1419 complete\n",
      "164 of 1419 complete\n",
      "165 of 1419 complete\n",
      "166 of 1419 complete\n",
      "167 of 1419 complete\n",
      "168 of 1419 complete\n",
      "169 of 1419 complete\n",
      "170 of 1419 complete\n",
      "171 of 1419 complete\n",
      "172 failed\n",
      "172 of 1419 complete\n",
      "173 of 1419 complete\n",
      "174 of 1419 complete\n",
      "175 of 1419 complete\n",
      "176 of 1419 complete\n",
      "177 of 1419 complete\n",
      "178 of 1419 complete\n",
      "179 of 1419 complete\n",
      "180 of 1419 complete\n",
      "181 of 1419 complete\n",
      "182 of 1419 complete\n",
      "183 of 1419 complete\n",
      "184 of 1419 complete\n",
      "185 of 1419 complete\n",
      "186 of 1419 complete\n",
      "187 of 1419 complete\n",
      "188 of 1419 complete\n",
      "189 of 1419 complete\n",
      "190 of 1419 complete\n",
      "191 failed\n",
      "191 of 1419 complete\n",
      "192 of 1419 complete\n",
      "193 of 1419 complete\n",
      "194 of 1419 complete\n",
      "195 of 1419 complete\n",
      "196 of 1419 complete\n",
      "197 of 1419 complete\n",
      "198 of 1419 complete\n",
      "199 of 1419 complete\n",
      "200 of 1419 complete\n",
      "201 of 1419 complete\n",
      "202 of 1419 complete\n",
      "203 of 1419 complete\n",
      "204 of 1419 complete\n",
      "205 of 1419 complete\n",
      "206 of 1419 complete\n",
      "207 of 1419 complete\n",
      "208 of 1419 complete\n",
      "209 of 1419 complete\n",
      "210 of 1419 complete\n",
      "211 of 1419 complete\n",
      "212 of 1419 complete\n",
      "213 of 1419 complete\n",
      "214 of 1419 complete\n",
      "215 of 1419 complete\n",
      "216 of 1419 complete\n",
      "217 of 1419 complete\n",
      "218 of 1419 complete\n",
      "219 of 1419 complete\n",
      "220 of 1419 complete\n",
      "221 of 1419 complete\n",
      "222 of 1419 complete\n",
      "223 of 1419 complete\n",
      "224 of 1419 complete\n",
      "225 of 1419 complete\n",
      "226 of 1419 complete\n",
      "227 of 1419 complete\n",
      "228 of 1419 complete\n",
      "229 of 1419 complete\n",
      "230 of 1419 complete\n",
      "231 of 1419 complete\n",
      "232 of 1419 complete\n",
      "233 of 1419 complete\n",
      "234 of 1419 complete\n",
      "235 of 1419 complete\n",
      "236 of 1419 complete\n",
      "237 of 1419 complete\n",
      "238 of 1419 complete\n",
      "239 of 1419 complete\n",
      "240 of 1419 complete\n",
      "241 of 1419 complete\n",
      "242 of 1419 complete\n",
      "243 of 1419 complete\n",
      "244 of 1419 complete\n",
      "245 of 1419 complete\n",
      "246 of 1419 complete\n",
      "247 of 1419 complete\n",
      "248 of 1419 complete\n",
      "249 of 1419 complete\n",
      "250 of 1419 complete\n",
      "251 of 1419 complete\n",
      "252 of 1419 complete\n",
      "253 of 1419 complete\n",
      "254 of 1419 complete\n",
      "255 of 1419 complete\n",
      "256 of 1419 complete\n",
      "257 of 1419 complete\n",
      "258 of 1419 complete\n",
      "259 of 1419 complete\n",
      "260 of 1419 complete\n",
      "261 of 1419 complete\n",
      "262 of 1419 complete\n",
      "263 of 1419 complete\n",
      "264 of 1419 complete\n",
      "265 of 1419 complete\n",
      "266 of 1419 complete\n",
      "267 of 1419 complete\n",
      "268 of 1419 complete\n",
      "269 of 1419 complete\n",
      "270 of 1419 complete\n",
      "271 of 1419 complete\n",
      "272 of 1419 complete\n",
      "273 of 1419 complete\n",
      "274 of 1419 complete\n",
      "275 of 1419 complete\n",
      "276 of 1419 complete\n",
      "277 of 1419 complete\n",
      "278 of 1419 complete\n",
      "279 of 1419 complete\n",
      "280 of 1419 complete\n",
      "281 of 1419 complete\n",
      "282 of 1419 complete\n",
      "283 of 1419 complete\n",
      "284 of 1419 complete\n",
      "285 of 1419 complete\n",
      "286 of 1419 complete\n",
      "287 of 1419 complete\n",
      "288 of 1419 complete\n",
      "289 of 1419 complete\n",
      "290 of 1419 complete\n",
      "291 of 1419 complete\n",
      "292 failed\n",
      "292 of 1419 complete\n",
      "293 of 1419 complete\n",
      "294 of 1419 complete\n",
      "295 of 1419 complete\n",
      "296 of 1419 complete\n",
      "297 of 1419 complete\n",
      "298 of 1419 complete\n",
      "299 of 1419 complete\n",
      "300 of 1419 complete\n",
      "301 of 1419 complete\n",
      "302 of 1419 complete\n",
      "303 of 1419 complete\n",
      "304 of 1419 complete\n",
      "305 of 1419 complete\n",
      "306 of 1419 complete\n",
      "307 of 1419 complete\n",
      "308 of 1419 complete\n",
      "309 of 1419 complete\n",
      "310 of 1419 complete\n",
      "311 of 1419 complete\n",
      "312 of 1419 complete\n",
      "313 of 1419 complete\n",
      "314 of 1419 complete\n",
      "315 of 1419 complete\n",
      "316 of 1419 complete\n",
      "317 of 1419 complete\n",
      "318 of 1419 complete\n",
      "319 of 1419 complete\n",
      "320 of 1419 complete\n",
      "321 of 1419 complete\n",
      "322 of 1419 complete\n",
      "323 of 1419 complete\n",
      "324 of 1419 complete\n",
      "325 of 1419 complete\n",
      "326 of 1419 complete\n",
      "327 of 1419 complete\n",
      "328 of 1419 complete\n",
      "329 of 1419 complete\n",
      "330 of 1419 complete\n",
      "331 of 1419 complete\n",
      "332 of 1419 complete\n",
      "333 of 1419 complete\n",
      "334 of 1419 complete\n",
      "335 of 1419 complete\n",
      "336 of 1419 complete\n",
      "337 of 1419 complete\n",
      "338 of 1419 complete\n",
      "339 of 1419 complete\n",
      "340 of 1419 complete\n",
      "341 of 1419 complete\n",
      "342 of 1419 complete\n",
      "343 of 1419 complete\n",
      "344 of 1419 complete\n",
      "345 of 1419 complete\n",
      "346 of 1419 complete\n",
      "347 of 1419 complete\n",
      "348 of 1419 complete\n",
      "349 of 1419 complete\n",
      "350 of 1419 complete\n",
      "351 of 1419 complete\n",
      "352 of 1419 complete\n",
      "353 of 1419 complete\n",
      "354 of 1419 complete\n",
      "355 of 1419 complete\n",
      "356 of 1419 complete\n",
      "357 of 1419 complete\n",
      "358 of 1419 complete\n",
      "359 of 1419 complete\n",
      "360 of 1419 complete\n",
      "361 of 1419 complete\n",
      "362 of 1419 complete\n",
      "363 of 1419 complete\n",
      "364 of 1419 complete\n",
      "365 of 1419 complete\n",
      "366 of 1419 complete\n",
      "367 of 1419 complete\n",
      "368 of 1419 complete\n",
      "369 of 1419 complete\n",
      "370 of 1419 complete\n",
      "371 of 1419 complete\n",
      "372 of 1419 complete\n",
      "373 of 1419 complete\n",
      "374 of 1419 complete\n",
      "375 of 1419 complete\n",
      "376 of 1419 complete\n",
      "377 of 1419 complete\n",
      "378 of 1419 complete\n",
      "379 of 1419 complete\n",
      "380 of 1419 complete\n",
      "381 of 1419 complete\n",
      "382 of 1419 complete\n",
      "383 of 1419 complete\n",
      "384 failed\n",
      "384 of 1419 complete\n",
      "385 failed\n",
      "385 of 1419 complete\n",
      "386 of 1419 complete\n",
      "387 of 1419 complete\n",
      "388 of 1419 complete\n",
      "389 of 1419 complete\n",
      "390 of 1419 complete\n",
      "391 of 1419 complete\n",
      "392 of 1419 complete\n",
      "393 of 1419 complete\n",
      "394 of 1419 complete\n",
      "395 of 1419 complete\n",
      "396 of 1419 complete\n",
      "397 of 1419 complete\n",
      "398 of 1419 complete\n",
      "399 of 1419 complete\n",
      "400 of 1419 complete\n",
      "401 of 1419 complete\n",
      "402 of 1419 complete\n",
      "403 of 1419 complete\n",
      "404 of 1419 complete\n",
      "405 failed\n",
      "405 of 1419 complete\n",
      "406 of 1419 complete\n",
      "407 of 1419 complete\n",
      "408 of 1419 complete\n",
      "409 of 1419 complete\n",
      "410 of 1419 complete\n",
      "411 of 1419 complete\n",
      "412 of 1419 complete\n",
      "413 of 1419 complete\n",
      "414 of 1419 complete\n",
      "415 of 1419 complete\n",
      "416 of 1419 complete\n",
      "417 of 1419 complete\n",
      "418 of 1419 complete\n",
      "419 of 1419 complete\n",
      "420 of 1419 complete\n",
      "421 of 1419 complete\n",
      "422 of 1419 complete\n",
      "423 of 1419 complete\n",
      "424 of 1419 complete\n",
      "425 of 1419 complete\n",
      "426 of 1419 complete\n",
      "427 of 1419 complete\n",
      "428 of 1419 complete\n",
      "429 of 1419 complete\n",
      "430 of 1419 complete\n",
      "431 of 1419 complete\n",
      "432 of 1419 complete\n",
      "433 of 1419 complete\n",
      "434 of 1419 complete\n",
      "435 of 1419 complete\n",
      "436 of 1419 complete\n",
      "437 of 1419 complete\n",
      "438 of 1419 complete\n",
      "439 of 1419 complete\n",
      "440 of 1419 complete\n",
      "441 of 1419 complete\n",
      "442 of 1419 complete\n",
      "443 of 1419 complete\n",
      "444 of 1419 complete\n",
      "445 of 1419 complete\n",
      "446 of 1419 complete\n",
      "447 of 1419 complete\n",
      "448 of 1419 complete\n",
      "449 of 1419 complete\n",
      "450 of 1419 complete\n",
      "451 of 1419 complete\n",
      "452 of 1419 complete\n",
      "453 of 1419 complete\n",
      "454 of 1419 complete\n",
      "455 of 1419 complete\n",
      "456 of 1419 complete\n",
      "457 of 1419 complete\n",
      "458 of 1419 complete\n",
      "459 of 1419 complete\n",
      "460 of 1419 complete\n",
      "461 of 1419 complete\n",
      "462 of 1419 complete\n",
      "463 of 1419 complete\n",
      "464 of 1419 complete\n",
      "465 of 1419 complete\n",
      "466 of 1419 complete\n",
      "467 of 1419 complete\n",
      "468 of 1419 complete\n",
      "469 of 1419 complete\n",
      "470 of 1419 complete\n",
      "471 of 1419 complete\n",
      "472 of 1419 complete\n",
      "473 of 1419 complete\n",
      "474 of 1419 complete\n",
      "475 of 1419 complete\n",
      "476 of 1419 complete\n",
      "477 of 1419 complete\n",
      "478 of 1419 complete\n",
      "479 of 1419 complete\n",
      "480 of 1419 complete\n",
      "481 of 1419 complete\n",
      "482 of 1419 complete\n",
      "483 of 1419 complete\n",
      "484 of 1419 complete\n",
      "485 of 1419 complete\n",
      "486 of 1419 complete\n",
      "487 of 1419 complete\n",
      "488 of 1419 complete\n",
      "489 of 1419 complete\n",
      "490 of 1419 complete\n",
      "491 of 1419 complete\n",
      "492 of 1419 complete\n",
      "493 of 1419 complete\n",
      "494 of 1419 complete\n",
      "495 of 1419 complete\n",
      "496 of 1419 complete\n",
      "497 of 1419 complete\n",
      "498 of 1419 complete\n",
      "499 of 1419 complete\n",
      "500 of 1419 complete\n",
      "501 of 1419 complete\n",
      "502 of 1419 complete\n",
      "503 of 1419 complete\n",
      "504 of 1419 complete\n",
      "505 of 1419 complete\n",
      "506 of 1419 complete\n",
      "507 of 1419 complete\n",
      "508 of 1419 complete\n",
      "509 of 1419 complete\n",
      "510 of 1419 complete\n",
      "511 of 1419 complete\n",
      "512 of 1419 complete\n",
      "513 of 1419 complete\n",
      "514 of 1419 complete\n",
      "515 of 1419 complete\n",
      "516 of 1419 complete\n",
      "517 of 1419 complete\n",
      "518 of 1419 complete\n",
      "519 of 1419 complete\n",
      "520 of 1419 complete\n",
      "521 of 1419 complete\n",
      "522 of 1419 complete\n",
      "523 failed\n",
      "523 of 1419 complete\n",
      "524 of 1419 complete\n",
      "525 of 1419 complete\n",
      "526 of 1419 complete\n",
      "527 of 1419 complete\n",
      "528 of 1419 complete\n",
      "529 of 1419 complete\n",
      "530 of 1419 complete\n",
      "531 of 1419 complete\n",
      "532 of 1419 complete\n",
      "533 of 1419 complete\n",
      "534 of 1419 complete\n",
      "535 of 1419 complete\n",
      "536 of 1419 complete\n",
      "537 of 1419 complete\n",
      "538 of 1419 complete\n",
      "539 of 1419 complete\n",
      "540 of 1419 complete\n",
      "541 of 1419 complete\n",
      "542 of 1419 complete\n",
      "543 of 1419 complete\n",
      "544 of 1419 complete\n",
      "545 of 1419 complete\n",
      "546 of 1419 complete\n",
      "547 of 1419 complete\n",
      "548 of 1419 complete\n",
      "549 of 1419 complete\n",
      "550 of 1419 complete\n",
      "551 of 1419 complete\n",
      "552 of 1419 complete\n",
      "553 of 1419 complete\n",
      "554 of 1419 complete\n",
      "555 of 1419 complete\n",
      "556 of 1419 complete\n",
      "557 of 1419 complete\n",
      "558 of 1419 complete\n",
      "559 of 1419 complete\n",
      "560 of 1419 complete\n",
      "561 of 1419 complete\n",
      "562 of 1419 complete\n",
      "563 of 1419 complete\n",
      "564 failed\n",
      "564 of 1419 complete\n",
      "565 failed\n",
      "565 of 1419 complete\n",
      "566 of 1419 complete\n",
      "567 of 1419 complete\n",
      "568 of 1419 complete\n",
      "569 of 1419 complete\n",
      "570 of 1419 complete\n",
      "571 of 1419 complete\n",
      "572 of 1419 complete\n",
      "573 of 1419 complete\n",
      "574 of 1419 complete\n",
      "575 of 1419 complete\n",
      "576 of 1419 complete\n",
      "577 of 1419 complete\n",
      "578 of 1419 complete\n",
      "579 of 1419 complete\n",
      "580 of 1419 complete\n",
      "581 of 1419 complete\n",
      "582 of 1419 complete\n",
      "583 of 1419 complete\n",
      "584 of 1419 complete\n",
      "585 of 1419 complete\n",
      "586 of 1419 complete\n",
      "587 of 1419 complete\n",
      "588 of 1419 complete\n",
      "589 of 1419 complete\n",
      "590 of 1419 complete\n",
      "591 of 1419 complete\n",
      "592 of 1419 complete\n",
      "593 failed\n",
      "593 of 1419 complete\n",
      "594 of 1419 complete\n",
      "595 of 1419 complete\n",
      "596 of 1419 complete\n",
      "597 of 1419 complete\n",
      "598 of 1419 complete\n",
      "599 failed\n",
      "599 of 1419 complete\n",
      "600 of 1419 complete\n",
      "601 of 1419 complete\n",
      "602 of 1419 complete\n",
      "603 of 1419 complete\n",
      "604 of 1419 complete\n",
      "605 of 1419 complete\n",
      "606 of 1419 complete\n",
      "607 of 1419 complete\n",
      "608 of 1419 complete\n",
      "609 of 1419 complete\n",
      "610 of 1419 complete\n",
      "611 of 1419 complete\n",
      "612 of 1419 complete\n",
      "613 of 1419 complete\n",
      "614 of 1419 complete\n",
      "615 of 1419 complete\n",
      "616 failed\n",
      "616 of 1419 complete\n",
      "617 of 1419 complete\n",
      "618 of 1419 complete\n",
      "619 of 1419 complete\n",
      "620 of 1419 complete\n",
      "621 failed\n",
      "621 of 1419 complete\n",
      "622 of 1419 complete\n",
      "623 of 1419 complete\n",
      "624 of 1419 complete\n",
      "625 of 1419 complete\n",
      "626 of 1419 complete\n",
      "627 of 1419 complete\n",
      "628 of 1419 complete\n",
      "629 of 1419 complete\n",
      "630 of 1419 complete\n",
      "631 of 1419 complete\n",
      "632 of 1419 complete\n",
      "633 of 1419 complete\n",
      "634 of 1419 complete\n",
      "635 of 1419 complete\n",
      "636 of 1419 complete\n",
      "637 of 1419 complete\n",
      "638 of 1419 complete\n",
      "639 of 1419 complete\n",
      "640 of 1419 complete\n",
      "641 of 1419 complete\n",
      "642 of 1419 complete\n",
      "643 of 1419 complete\n",
      "644 of 1419 complete\n",
      "645 failed\n",
      "645 of 1419 complete\n",
      "646 of 1419 complete\n",
      "647 of 1419 complete\n",
      "648 of 1419 complete\n",
      "649 of 1419 complete\n",
      "650 of 1419 complete\n",
      "651 of 1419 complete\n",
      "652 of 1419 complete\n",
      "653 of 1419 complete\n",
      "654 of 1419 complete\n",
      "655 of 1419 complete\n",
      "656 of 1419 complete\n",
      "657 of 1419 complete\n",
      "658 of 1419 complete\n",
      "659 of 1419 complete\n",
      "660 of 1419 complete\n",
      "661 of 1419 complete\n",
      "662 of 1419 complete\n",
      "663 failed\n",
      "663 of 1419 complete\n",
      "664 of 1419 complete\n",
      "665 of 1419 complete\n",
      "666 of 1419 complete\n",
      "667 of 1419 complete\n",
      "668 of 1419 complete\n",
      "669 of 1419 complete\n",
      "670 of 1419 complete\n",
      "671 of 1419 complete\n",
      "672 of 1419 complete\n",
      "673 of 1419 complete\n",
      "674 of 1419 complete\n",
      "675 of 1419 complete\n",
      "676 of 1419 complete\n",
      "677 of 1419 complete\n",
      "678 of 1419 complete\n",
      "679 of 1419 complete\n",
      "680 of 1419 complete\n",
      "681 of 1419 complete\n",
      "682 of 1419 complete\n",
      "683 of 1419 complete\n",
      "684 of 1419 complete\n",
      "685 of 1419 complete\n",
      "686 failed\n",
      "686 of 1419 complete\n",
      "687 of 1419 complete\n",
      "688 of 1419 complete\n",
      "689 of 1419 complete\n",
      "690 of 1419 complete\n",
      "691 of 1419 complete\n",
      "692 of 1419 complete\n",
      "693 of 1419 complete\n",
      "694 of 1419 complete\n",
      "695 of 1419 complete\n",
      "696 of 1419 complete\n",
      "697 of 1419 complete\n",
      "698 of 1419 complete\n",
      "699 of 1419 complete\n",
      "700 of 1419 complete\n",
      "701 of 1419 complete\n",
      "702 of 1419 complete\n",
      "703 of 1419 complete\n",
      "704 of 1419 complete\n",
      "705 of 1419 complete\n",
      "706 of 1419 complete\n",
      "707 of 1419 complete\n",
      "708 of 1419 complete\n",
      "709 of 1419 complete\n",
      "710 of 1419 complete\n",
      "711 of 1419 complete\n",
      "712 of 1419 complete\n",
      "713 of 1419 complete\n",
      "714 of 1419 complete\n",
      "715 of 1419 complete\n",
      "716 of 1419 complete\n",
      "717 of 1419 complete\n",
      "718 of 1419 complete\n",
      "719 of 1419 complete\n",
      "720 of 1419 complete\n",
      "721 of 1419 complete\n",
      "722 of 1419 complete\n",
      "723 of 1419 complete\n",
      "724 of 1419 complete\n",
      "725 of 1419 complete\n",
      "726 of 1419 complete\n",
      "727 of 1419 complete\n",
      "728 of 1419 complete\n",
      "729 of 1419 complete\n",
      "730 of 1419 complete\n",
      "731 of 1419 complete\n",
      "732 of 1419 complete\n",
      "733 of 1419 complete\n",
      "734 of 1419 complete\n",
      "735 of 1419 complete\n",
      "736 of 1419 complete\n",
      "737 of 1419 complete\n",
      "738 of 1419 complete\n",
      "739 of 1419 complete\n",
      "740 of 1419 complete\n",
      "741 of 1419 complete\n",
      "742 of 1419 complete\n",
      "743 of 1419 complete\n",
      "744 of 1419 complete\n",
      "745 of 1419 complete\n",
      "746 of 1419 complete\n",
      "747 of 1419 complete\n",
      "748 of 1419 complete\n",
      "749 of 1419 complete\n",
      "750 of 1419 complete\n",
      "751 of 1419 complete\n",
      "752 of 1419 complete\n",
      "753 of 1419 complete\n",
      "754 of 1419 complete\n",
      "755 of 1419 complete\n",
      "756 of 1419 complete\n",
      "757 of 1419 complete\n",
      "758 of 1419 complete\n",
      "759 of 1419 complete\n",
      "760 of 1419 complete\n",
      "761 of 1419 complete\n",
      "762 of 1419 complete\n",
      "763 of 1419 complete\n",
      "764 of 1419 complete\n",
      "765 of 1419 complete\n",
      "766 of 1419 complete\n",
      "767 of 1419 complete\n",
      "768 of 1419 complete\n",
      "769 failed\n",
      "769 of 1419 complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770 of 1419 complete\n",
      "771 of 1419 complete\n",
      "772 of 1419 complete\n",
      "773 of 1419 complete\n",
      "774 of 1419 complete\n",
      "775 of 1419 complete\n",
      "776 of 1419 complete\n",
      "777 of 1419 complete\n",
      "778 of 1419 complete\n",
      "779 of 1419 complete\n",
      "780 of 1419 complete\n",
      "781 of 1419 complete\n",
      "782 of 1419 complete\n",
      "783 of 1419 complete\n",
      "784 of 1419 complete\n",
      "785 of 1419 complete\n",
      "786 of 1419 complete\n",
      "787 of 1419 complete\n",
      "788 of 1419 complete\n",
      "789 of 1419 complete\n",
      "790 of 1419 complete\n",
      "791 of 1419 complete\n",
      "792 of 1419 complete\n",
      "793 of 1419 complete\n",
      "794 of 1419 complete\n",
      "795 of 1419 complete\n",
      "796 of 1419 complete\n",
      "797 of 1419 complete\n",
      "798 of 1419 complete\n",
      "799 of 1419 complete\n",
      "800 of 1419 complete\n",
      "801 of 1419 complete\n",
      "802 of 1419 complete\n",
      "803 of 1419 complete\n",
      "804 of 1419 complete\n",
      "805 of 1419 complete\n",
      "806 of 1419 complete\n",
      "807 of 1419 complete\n",
      "808 of 1419 complete\n",
      "809 of 1419 complete\n",
      "810 of 1419 complete\n",
      "811 of 1419 complete\n",
      "812 of 1419 complete\n",
      "813 of 1419 complete\n",
      "814 of 1419 complete\n",
      "815 of 1419 complete\n",
      "816 of 1419 complete\n",
      "817 of 1419 complete\n",
      "818 of 1419 complete\n",
      "819 of 1419 complete\n",
      "820 of 1419 complete\n",
      "821 of 1419 complete\n",
      "822 of 1419 complete\n",
      "823 of 1419 complete\n",
      "824 of 1419 complete\n",
      "825 of 1419 complete\n",
      "826 of 1419 complete\n",
      "827 of 1419 complete\n",
      "828 of 1419 complete\n",
      "829 of 1419 complete\n",
      "830 of 1419 complete\n",
      "831 of 1419 complete\n",
      "832 of 1419 complete\n",
      "833 of 1419 complete\n",
      "834 of 1419 complete\n",
      "835 of 1419 complete\n",
      "836 of 1419 complete\n",
      "837 of 1419 complete\n",
      "838 of 1419 complete\n",
      "839 of 1419 complete\n",
      "840 failed\n",
      "840 of 1419 complete\n",
      "841 of 1419 complete\n",
      "842 of 1419 complete\n",
      "843 of 1419 complete\n",
      "844 of 1419 complete\n",
      "845 of 1419 complete\n",
      "846 of 1419 complete\n",
      "847 of 1419 complete\n",
      "848 of 1419 complete\n",
      "849 of 1419 complete\n",
      "850 of 1419 complete\n",
      "851 of 1419 complete\n",
      "852 of 1419 complete\n",
      "853 of 1419 complete\n",
      "854 of 1419 complete\n",
      "855 of 1419 complete\n",
      "856 of 1419 complete\n",
      "857 of 1419 complete\n",
      "858 of 1419 complete\n",
      "859 of 1419 complete\n",
      "860 of 1419 complete\n",
      "861 of 1419 complete\n",
      "862 of 1419 complete\n",
      "863 of 1419 complete\n",
      "864 of 1419 complete\n",
      "865 of 1419 complete\n",
      "866 of 1419 complete\n",
      "867 of 1419 complete\n",
      "868 of 1419 complete\n",
      "869 of 1419 complete\n",
      "870 of 1419 complete\n",
      "871 of 1419 complete\n",
      "872 of 1419 complete\n",
      "873 of 1419 complete\n",
      "874 of 1419 complete\n",
      "875 of 1419 complete\n",
      "876 of 1419 complete\n",
      "877 failed\n",
      "877 of 1419 complete\n",
      "878 of 1419 complete\n",
      "879 of 1419 complete\n",
      "880 of 1419 complete\n",
      "881 of 1419 complete\n",
      "882 of 1419 complete\n",
      "883 of 1419 complete\n",
      "884 of 1419 complete\n",
      "885 of 1419 complete\n",
      "886 of 1419 complete\n",
      "887 of 1419 complete\n",
      "888 of 1419 complete\n",
      "889 of 1419 complete\n",
      "890 of 1419 complete\n",
      "891 of 1419 complete\n",
      "892 of 1419 complete\n",
      "893 of 1419 complete\n",
      "894 of 1419 complete\n",
      "895 of 1419 complete\n",
      "896 of 1419 complete\n",
      "897 of 1419 complete\n",
      "898 of 1419 complete\n",
      "899 of 1419 complete\n",
      "900 of 1419 complete\n",
      "901 of 1419 complete\n",
      "902 of 1419 complete\n",
      "903 of 1419 complete\n",
      "904 of 1419 complete\n",
      "905 of 1419 complete\n",
      "906 failed\n",
      "906 of 1419 complete\n",
      "907 failed\n",
      "907 of 1419 complete\n",
      "908 of 1419 complete\n",
      "909 of 1419 complete\n",
      "910 of 1419 complete\n",
      "911 of 1419 complete\n",
      "912 of 1419 complete\n",
      "913 of 1419 complete\n",
      "914 of 1419 complete\n",
      "915 of 1419 complete\n",
      "916 of 1419 complete\n",
      "917 of 1419 complete\n",
      "918 of 1419 complete\n",
      "919 of 1419 complete\n",
      "920 of 1419 complete\n",
      "921 of 1419 complete\n",
      "922 of 1419 complete\n",
      "923 of 1419 complete\n",
      "924 of 1419 complete\n",
      "925 of 1419 complete\n",
      "926 of 1419 complete\n",
      "927 of 1419 complete\n",
      "928 of 1419 complete\n",
      "929 of 1419 complete\n",
      "930 of 1419 complete\n",
      "931 of 1419 complete\n",
      "932 of 1419 complete\n",
      "933 of 1419 complete\n",
      "934 of 1419 complete\n",
      "935 of 1419 complete\n",
      "936 of 1419 complete\n",
      "937 of 1419 complete\n",
      "938 of 1419 complete\n",
      "939 of 1419 complete\n",
      "940 of 1419 complete\n",
      "941 of 1419 complete\n",
      "942 of 1419 complete\n",
      "943 of 1419 complete\n",
      "944 of 1419 complete\n",
      "945 of 1419 complete\n",
      "946 of 1419 complete\n",
      "947 of 1419 complete\n",
      "948 of 1419 complete\n",
      "949 of 1419 complete\n",
      "950 of 1419 complete\n",
      "951 of 1419 complete\n",
      "952 of 1419 complete\n",
      "953 of 1419 complete\n",
      "954 of 1419 complete\n",
      "955 of 1419 complete\n",
      "956 of 1419 complete\n",
      "957 of 1419 complete\n",
      "958 of 1419 complete\n",
      "959 of 1419 complete\n",
      "960 of 1419 complete\n",
      "961 of 1419 complete\n",
      "962 of 1419 complete\n",
      "963 of 1419 complete\n",
      "964 of 1419 complete\n",
      "965 failed\n",
      "965 of 1419 complete\n",
      "966 of 1419 complete\n",
      "967 of 1419 complete\n",
      "968 of 1419 complete\n",
      "969 of 1419 complete\n",
      "970 of 1419 complete\n",
      "971 of 1419 complete\n",
      "972 of 1419 complete\n",
      "973 of 1419 complete\n",
      "974 of 1419 complete\n",
      "975 of 1419 complete\n",
      "976 of 1419 complete\n",
      "977 of 1419 complete\n",
      "978 of 1419 complete\n",
      "979 of 1419 complete\n",
      "980 of 1419 complete\n",
      "981 of 1419 complete\n",
      "982 of 1419 complete\n",
      "983 of 1419 complete\n",
      "984 of 1419 complete\n",
      "985 of 1419 complete\n",
      "986 of 1419 complete\n",
      "987 of 1419 complete\n",
      "988 of 1419 complete\n",
      "989 of 1419 complete\n",
      "990 of 1419 complete\n",
      "991 of 1419 complete\n",
      "992 of 1419 complete\n",
      "993 of 1419 complete\n",
      "994 of 1419 complete\n",
      "995 of 1419 complete\n",
      "996 of 1419 complete\n",
      "997 of 1419 complete\n",
      "998 of 1419 complete\n",
      "999 of 1419 complete\n",
      "1000 of 1419 complete\n",
      "1001 of 1419 complete\n",
      "1002 of 1419 complete\n",
      "1003 of 1419 complete\n",
      "1004 of 1419 complete\n",
      "1005 of 1419 complete\n",
      "1006 of 1419 complete\n",
      "1007 failed\n",
      "1007 of 1419 complete\n",
      "1008 of 1419 complete\n",
      "1009 of 1419 complete\n",
      "1010 of 1419 complete\n",
      "1011 of 1419 complete\n",
      "1012 of 1419 complete\n",
      "1013 failed\n",
      "1013 of 1419 complete\n",
      "1014 of 1419 complete\n",
      "1015 of 1419 complete\n",
      "1016 of 1419 complete\n",
      "1017 of 1419 complete\n",
      "1018 of 1419 complete\n",
      "1019 of 1419 complete\n",
      "1020 of 1419 complete\n",
      "1021 of 1419 complete\n",
      "1022 of 1419 complete\n",
      "1023 of 1419 complete\n",
      "1024 of 1419 complete\n",
      "1025 of 1419 complete\n",
      "1026 of 1419 complete\n",
      "1027 of 1419 complete\n",
      "1028 of 1419 complete\n",
      "1029 of 1419 complete\n",
      "1030 of 1419 complete\n",
      "1031 of 1419 complete\n",
      "1032 of 1419 complete\n",
      "1033 of 1419 complete\n",
      "1034 failed\n",
      "1034 of 1419 complete\n",
      "1035 of 1419 complete\n",
      "1036 of 1419 complete\n",
      "1037 of 1419 complete\n",
      "1038 of 1419 complete\n",
      "1039 of 1419 complete\n",
      "1040 of 1419 complete\n",
      "1041 of 1419 complete\n",
      "1042 of 1419 complete\n",
      "1043 of 1419 complete\n",
      "1044 of 1419 complete\n",
      "1045 failed\n",
      "1045 of 1419 complete\n",
      "1046 of 1419 complete\n",
      "1047 of 1419 complete\n",
      "1048 of 1419 complete\n",
      "1049 of 1419 complete\n",
      "1050 of 1419 complete\n",
      "1051 of 1419 complete\n",
      "1052 of 1419 complete\n",
      "1053 of 1419 complete\n",
      "1054 of 1419 complete\n",
      "1055 of 1419 complete\n",
      "1056 of 1419 complete\n",
      "1057 of 1419 complete\n",
      "1058 of 1419 complete\n",
      "1059 of 1419 complete\n",
      "1060 of 1419 complete\n",
      "1061 of 1419 complete\n",
      "1062 of 1419 complete\n",
      "1063 of 1419 complete\n",
      "1064 of 1419 complete\n",
      "1065 of 1419 complete\n",
      "1066 of 1419 complete\n",
      "1067 of 1419 complete\n",
      "1068 of 1419 complete\n",
      "1069 of 1419 complete\n",
      "1070 of 1419 complete\n",
      "1071 of 1419 complete\n",
      "1072 of 1419 complete\n",
      "1073 of 1419 complete\n",
      "1074 of 1419 complete\n",
      "1075 of 1419 complete\n",
      "1076 of 1419 complete\n",
      "1077 of 1419 complete\n",
      "1078 of 1419 complete\n",
      "1079 of 1419 complete\n",
      "1080 of 1419 complete\n",
      "1081 of 1419 complete\n",
      "1082 of 1419 complete\n",
      "1083 of 1419 complete\n",
      "1084 of 1419 complete\n",
      "1085 of 1419 complete\n",
      "1086 of 1419 complete\n",
      "1087 of 1419 complete\n",
      "1088 of 1419 complete\n",
      "1089 of 1419 complete\n",
      "1090 of 1419 complete\n",
      "1091 of 1419 complete\n",
      "1092 of 1419 complete\n",
      "1093 of 1419 complete\n",
      "1094 of 1419 complete\n",
      "1095 of 1419 complete\n",
      "1096 of 1419 complete\n",
      "1097 of 1419 complete\n",
      "1098 of 1419 complete\n",
      "1099 of 1419 complete\n",
      "1100 of 1419 complete\n",
      "1101 of 1419 complete\n",
      "1102 of 1419 complete\n",
      "1103 of 1419 complete\n",
      "1104 of 1419 complete\n",
      "1105 of 1419 complete\n",
      "1106 of 1419 complete\n",
      "1107 of 1419 complete\n",
      "1108 of 1419 complete\n",
      "1109 of 1419 complete\n",
      "1110 of 1419 complete\n",
      "1111 of 1419 complete\n",
      "1112 of 1419 complete\n",
      "1113 of 1419 complete\n",
      "1114 of 1419 complete\n",
      "1115 of 1419 complete\n",
      "1116 of 1419 complete\n",
      "1117 of 1419 complete\n",
      "1118 of 1419 complete\n",
      "1119 of 1419 complete\n",
      "1120 of 1419 complete\n",
      "1121 of 1419 complete\n",
      "1122 of 1419 complete\n",
      "1123 of 1419 complete\n",
      "1124 of 1419 complete\n",
      "1125 of 1419 complete\n",
      "1126 of 1419 complete\n",
      "1127 of 1419 complete\n",
      "1128 of 1419 complete\n",
      "1129 of 1419 complete\n",
      "1130 of 1419 complete\n",
      "1131 of 1419 complete\n",
      "1132 of 1419 complete\n",
      "1133 of 1419 complete\n",
      "1134 of 1419 complete\n",
      "1135 of 1419 complete\n",
      "1136 failed\n",
      "1136 of 1419 complete\n",
      "1137 of 1419 complete\n",
      "1138 of 1419 complete\n",
      "1139 of 1419 complete\n",
      "1140 of 1419 complete\n",
      "1141 of 1419 complete\n",
      "1142 of 1419 complete\n",
      "1143 failed\n",
      "1143 of 1419 complete\n",
      "1144 of 1419 complete\n",
      "1145 of 1419 complete\n",
      "1146 of 1419 complete\n",
      "1147 of 1419 complete\n",
      "1148 of 1419 complete\n",
      "1149 of 1419 complete\n",
      "1150 of 1419 complete\n",
      "1151 of 1419 complete\n",
      "1152 of 1419 complete\n",
      "1153 of 1419 complete\n",
      "1154 of 1419 complete\n",
      "1155 of 1419 complete\n",
      "1156 of 1419 complete\n",
      "1157 of 1419 complete\n",
      "1158 of 1419 complete\n",
      "1159 of 1419 complete\n",
      "1160 of 1419 complete\n",
      "1161 of 1419 complete\n",
      "1162 of 1419 complete\n",
      "1163 of 1419 complete\n",
      "1164 of 1419 complete\n",
      "1165 of 1419 complete\n",
      "1166 of 1419 complete\n",
      "1167 of 1419 complete\n",
      "1168 of 1419 complete\n",
      "1169 of 1419 complete\n",
      "1170 of 1419 complete\n",
      "1171 of 1419 complete\n",
      "1172 of 1419 complete\n",
      "1173 of 1419 complete\n",
      "1174 of 1419 complete\n",
      "1175 of 1419 complete\n",
      "1176 of 1419 complete\n",
      "1177 of 1419 complete\n",
      "1178 of 1419 complete\n",
      "1179 failed\n",
      "1179 of 1419 complete\n",
      "1180 of 1419 complete\n",
      "1181 of 1419 complete\n",
      "1182 failed\n",
      "1182 of 1419 complete\n",
      "1183 failed\n",
      "1183 of 1419 complete\n",
      "1184 of 1419 complete\n",
      "1185 failed\n",
      "1185 of 1419 complete\n",
      "1186 failed\n",
      "1186 of 1419 complete\n",
      "1187 of 1419 complete\n",
      "1188 of 1419 complete\n",
      "1189 failed\n",
      "1189 of 1419 complete\n",
      "1190 failed\n",
      "1190 of 1419 complete\n",
      "1191 failed\n",
      "1191 of 1419 complete\n",
      "1192 failed\n",
      "1192 of 1419 complete\n",
      "1193 failed\n",
      "1193 of 1419 complete\n",
      "1194 failed\n",
      "1194 of 1419 complete\n",
      "1195 failed\n",
      "1195 of 1419 complete\n",
      "1196 of 1419 complete\n",
      "1197 of 1419 complete\n",
      "1198 of 1419 complete\n",
      "1199 of 1419 complete\n",
      "1200 of 1419 complete\n",
      "1201 of 1419 complete\n",
      "1202 of 1419 complete\n",
      "1203 failed\n",
      "1203 of 1419 complete\n",
      "1204 of 1419 complete\n",
      "1205 of 1419 complete\n",
      "1206 of 1419 complete\n",
      "1207 of 1419 complete\n",
      "1208 of 1419 complete\n",
      "1209 failed\n",
      "1209 of 1419 complete\n",
      "1210 of 1419 complete\n",
      "1211 of 1419 complete\n",
      "1212 of 1419 complete\n",
      "1213 of 1419 complete\n",
      "1214 of 1419 complete\n",
      "1215 of 1419 complete\n",
      "1216 of 1419 complete\n",
      "1217 of 1419 complete\n",
      "1218 of 1419 complete\n",
      "1219 of 1419 complete\n",
      "1220 of 1419 complete\n",
      "1221 of 1419 complete\n",
      "1222 of 1419 complete\n",
      "1223 of 1419 complete\n",
      "1224 of 1419 complete\n",
      "1225 of 1419 complete\n",
      "1226 of 1419 complete\n",
      "1227 of 1419 complete\n",
      "1228 of 1419 complete\n",
      "1229 failed\n",
      "1229 of 1419 complete\n",
      "1230 of 1419 complete\n",
      "1231 of 1419 complete\n",
      "1232 of 1419 complete\n",
      "1233 of 1419 complete\n",
      "1234 of 1419 complete\n",
      "1235 of 1419 complete\n",
      "1236 of 1419 complete\n",
      "1237 of 1419 complete\n",
      "1238 of 1419 complete\n",
      "1239 of 1419 complete\n",
      "1240 of 1419 complete\n",
      "1241 of 1419 complete\n",
      "1242 of 1419 complete\n",
      "1243 of 1419 complete\n",
      "1244 of 1419 complete\n",
      "1245 of 1419 complete\n",
      "1246 of 1419 complete\n",
      "1247 of 1419 complete\n",
      "1248 of 1419 complete\n",
      "1249 of 1419 complete\n",
      "1250 of 1419 complete\n",
      "1251 of 1419 complete\n",
      "1252 of 1419 complete\n",
      "1253 of 1419 complete\n",
      "1254 of 1419 complete\n",
      "1255 of 1419 complete\n",
      "1256 of 1419 complete\n",
      "1257 of 1419 complete\n",
      "1258 of 1419 complete\n",
      "1259 of 1419 complete\n",
      "1260 of 1419 complete\n",
      "1261 of 1419 complete\n",
      "1262 of 1419 complete\n",
      "1263 of 1419 complete\n",
      "1264 of 1419 complete\n",
      "1265 of 1419 complete\n",
      "1266 of 1419 complete\n",
      "1267 of 1419 complete\n",
      "1268 of 1419 complete\n",
      "1269 of 1419 complete\n",
      "1270 of 1419 complete\n",
      "1271 of 1419 complete\n",
      "1272 of 1419 complete\n",
      "1273 of 1419 complete\n",
      "1274 of 1419 complete\n",
      "1275 of 1419 complete\n",
      "1276 of 1419 complete\n",
      "1277 of 1419 complete\n",
      "1278 of 1419 complete\n",
      "1279 of 1419 complete\n",
      "1280 of 1419 complete\n",
      "1281 of 1419 complete\n",
      "1282 of 1419 complete\n",
      "1283 of 1419 complete\n",
      "1284 of 1419 complete\n",
      "1285 of 1419 complete\n",
      "1286 of 1419 complete\n",
      "1287 of 1419 complete\n",
      "1288 of 1419 complete\n",
      "1289 of 1419 complete\n",
      "1290 of 1419 complete\n",
      "1291 of 1419 complete\n",
      "1292 of 1419 complete\n",
      "1293 of 1419 complete\n",
      "1294 of 1419 complete\n",
      "1295 of 1419 complete\n",
      "1296 of 1419 complete\n",
      "1297 of 1419 complete\n",
      "1298 of 1419 complete\n",
      "1299 of 1419 complete\n",
      "1300 of 1419 complete\n",
      "1301 of 1419 complete\n",
      "1302 of 1419 complete\n",
      "1303 of 1419 complete\n",
      "1304 of 1419 complete\n",
      "1305 of 1419 complete\n",
      "1306 of 1419 complete\n",
      "1307 of 1419 complete\n",
      "1308 of 1419 complete\n",
      "1309 of 1419 complete\n",
      "1310 of 1419 complete\n",
      "1311 of 1419 complete\n",
      "1312 of 1419 complete\n",
      "1313 of 1419 complete\n",
      "1314 of 1419 complete\n",
      "1315 of 1419 complete\n",
      "1316 of 1419 complete\n",
      "1317 of 1419 complete\n",
      "1318 of 1419 complete\n",
      "1319 of 1419 complete\n",
      "1320 of 1419 complete\n",
      "1321 of 1419 complete\n",
      "1322 of 1419 complete\n",
      "1323 of 1419 complete\n",
      "1324 of 1419 complete\n",
      "1325 of 1419 complete\n",
      "1326 of 1419 complete\n",
      "1327 of 1419 complete\n",
      "1328 of 1419 complete\n",
      "1329 of 1419 complete\n",
      "1330 of 1419 complete\n",
      "1331 of 1419 complete\n",
      "1332 of 1419 complete\n",
      "1333 of 1419 complete\n",
      "1334 of 1419 complete\n",
      "1335 of 1419 complete\n",
      "1336 of 1419 complete\n",
      "1337 of 1419 complete\n",
      "1338 of 1419 complete\n",
      "1339 of 1419 complete\n",
      "1340 of 1419 complete\n",
      "1341 of 1419 complete\n",
      "1342 of 1419 complete\n",
      "1343 of 1419 complete\n",
      "1344 of 1419 complete\n",
      "1345 of 1419 complete\n",
      "1346 of 1419 complete\n",
      "1347 of 1419 complete\n",
      "1348 of 1419 complete\n",
      "1349 of 1419 complete\n",
      "1350 of 1419 complete\n",
      "1351 of 1419 complete\n",
      "1352 of 1419 complete\n",
      "1353 of 1419 complete\n",
      "1354 of 1419 complete\n",
      "1355 of 1419 complete\n",
      "1356 of 1419 complete\n",
      "1357 of 1419 complete\n",
      "1358 of 1419 complete\n",
      "1359 of 1419 complete\n",
      "1360 of 1419 complete\n",
      "1361 of 1419 complete\n",
      "1362 of 1419 complete\n",
      "1363 of 1419 complete\n",
      "1364 of 1419 complete\n",
      "1365 of 1419 complete\n",
      "1366 of 1419 complete\n",
      "1367 of 1419 complete\n",
      "1368 of 1419 complete\n",
      "1369 of 1419 complete\n",
      "1370 of 1419 complete\n",
      "1371 of 1419 complete\n",
      "1372 of 1419 complete\n",
      "1373 of 1419 complete\n",
      "1374 of 1419 complete\n",
      "1375 of 1419 complete\n",
      "1376 of 1419 complete\n",
      "1377 of 1419 complete\n",
      "1378 of 1419 complete\n",
      "1379 of 1419 complete\n",
      "1380 of 1419 complete\n",
      "1381 of 1419 complete\n",
      "1382 of 1419 complete\n",
      "1383 of 1419 complete\n",
      "1384 of 1419 complete\n",
      "1385 of 1419 complete\n",
      "1386 of 1419 complete\n",
      "1387 of 1419 complete\n",
      "1388 of 1419 complete\n",
      "1389 of 1419 complete\n",
      "1390 of 1419 complete\n",
      "1391 of 1419 complete\n",
      "1392 of 1419 complete\n",
      "1393 of 1419 complete\n",
      "1394 of 1419 complete\n",
      "1395 of 1419 complete\n",
      "1396 of 1419 complete\n",
      "1397 of 1419 complete\n",
      "1398 of 1419 complete\n",
      "1399 of 1419 complete\n",
      "1400 of 1419 complete\n",
      "1401 of 1419 complete\n",
      "1402 of 1419 complete\n",
      "1403 of 1419 complete\n",
      "1404 of 1419 complete\n",
      "1405 of 1419 complete\n",
      "1406 of 1419 complete\n",
      "1407 of 1419 complete\n",
      "1408 of 1419 complete\n",
      "1409 of 1419 complete\n",
      "1410 of 1419 complete\n",
      "1411 of 1419 complete\n",
      "1412 of 1419 complete\n",
      "1413 of 1419 complete\n",
      "1414 of 1419 complete\n",
      "1415 of 1419 complete\n",
      "1416 of 1419 complete\n",
      "1417 of 1419 complete\n",
      "1418 of 1419 complete\n",
      "1419 of 1419 complete\n",
      "[41, 73, 75, 96, 128, 130, 132, 172, 191, 292, 384, 385, 405, 523, 564, 565, 593, 599, 616, 621, 645, 663, 686, 769, 840, 877, 906, 907, 965, 1007, 1013, 1034, 1045, 1136, 1143, 1179, 1182, 1183, 1185, 1186, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1203, 1209, 1229]\n",
      "02:22:27\n",
      "loop took 328.2881730357806 minutes to run\n"
     ]
    }
   ],
   "source": [
    "#Inputs\n",
    "cdw_trace_pts1 = os.path.join(scratch1,\"selected_cdw_trace_pts\")\n",
    "oid_list = cdw_start_oids\n",
    "agglines = os.path.join(lscratch, \"cdw_trace_results_part1\")\n",
    "\n",
    "\n",
    "#Set up\n",
    "if arcpy.Exists(agglines):\n",
    "    print(\"file is here. I will destroy it for you\")\n",
    "    arcpy.management.Delete(agglines) \n",
    "else: \n",
    "    print(\"Feature class doesn't exist\")\n",
    "#select upstream 1 mile\n",
    "arcpy.env.addOutputsToMap = True\n",
    "oid_fieldname = arcpy.Describe(cdw_trace_pts1).OIDFieldName\n",
    "i = 1\n",
    "list_length = len(oid_list)\n",
    "error_list_cdw = [] #list of point oid that caused an error\n",
    "\n",
    "t = time.localtime()\n",
    "start_time = time.strftime(\"%H:%M:%S\", t)\n",
    "t1 = time.time()\n",
    "print(f\"start time is {start_time}\")\n",
    "      \n",
    "for pt in oid_list:\n",
    "    try:\n",
    "        where = f\"{oid_fieldname} = {pt}\"\n",
    "        start_pt = arcpy.conversion.ExportFeatures(cdw_trace_pts1, os.path.join(lscratch,\"temp_point\"), where) \n",
    "        arcpy.tn.Trace(\n",
    "            in_trace_network=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\stream_buffers_1.gdb\\Stream_buffers\\CDW_streams_network\",\n",
    "            trace_type=\"UPSTREAM\",\n",
    "            starting_points= start_pt,\n",
    "            barriers=\"TN_Temp_Barriers\",\n",
    "            path_direction=\"NO_DIRECTION\",\n",
    "            shortest_path_network_attribute_name=\"\",\n",
    "            include_barriers=\"INCLUDE_BARRIERS\",\n",
    "            validate_consistency=\"VALIDATE_CONSISTENCY\",\n",
    "            ignore_barriers_at_starting_points=\"DO_NOT_IGNORE_BARRIERS_AT_STARTING_POINTS\",\n",
    "            allow_indeterminate_flow=\"IGNORE_INDETERMINATE_FLOW\",\n",
    "            condition_barriers=None,\n",
    "            function_barriers=\"ADD Segment_Length IS_GREATER_THAN_OR_EQUAL_TO 5280 true\",\n",
    "            traversability_scope=\"BOTH_JUNCTIONS_AND_EDGES\",\n",
    "            functions=None,\n",
    "            output_conditions=None,\n",
    "            result_types=\"AGGREGATED_GEOMETRY\",\n",
    "            selection_type=\"NEW_SELECTION\",\n",
    "            clear_all_previous_trace_results=\"DO_NOT_CLEAR_ALL_PREVIOUS_TRACE_RESULTS\",\n",
    "            trace_name=\"\",\n",
    "            #aggregated_points=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\RiparianZones_20240109.gdb\\Trace_Results_Aggregated_Points\",\n",
    "            aggregated_lines= agglines, \n",
    "            out_network_layer=None\n",
    "        )\n",
    "    except:\n",
    "        print(f\"{pt} failed\")\n",
    "        error_list_cdw.append(pt)\n",
    "    finally:\n",
    "        print(f\"{i} of {list_length} complete\")\n",
    "        i = i+1\n",
    "print(error_list_cdw)\n",
    "\n",
    "t = time.localtime()\n",
    "end_time = time.strftime(\"%H:%M:%S\", t)\n",
    "print(end_time)\n",
    "t2 = time.time()\n",
    "elapsed_time = ((t2 - t1)/60)\n",
    "print(f\"loop took {elapsed_time} minutes to run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_oids = [41, 73, 75, 96, 128, 130, 132, 172, 191, 292, 384, 385, 405, 523, 564, 565, 593, 599, 616, 621, 645, 663, 686, 769, 840, 877, 906, 907, 965, 1007, 1013, 1034, 1045, 1136, 1143, 1179, 1182, 1183, 1185, 1186, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1203, 1209, 1229]\n",
    "len(error_oids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, February 14, 2024 3:49:02 PM\",\"Succeeded at Wednesday, February 14, 2024 3:49:07 PM (Elapsed Time: 5.10 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_results_merged'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(home, 'CDW_Trace_results_partbeween_upstream'), os.path.join(lscratch, \"cdw_trace_results_part1\")],\n",
    "                       os.path.join(scratch1,\"cdw_trace_results_merged\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, February 14, 2024 3:49:08 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Wednesday, February 14, 2024 3:49:32 PM (Elapsed Time: 24.68 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_results_erase'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge results and erase from cdw upstream erase lines to get remaining streams\n",
    "arcpy.analysis.Erase(os.path.join(scratch1,\"non_cdw_buffer_diss\"), \n",
    "                     os.path.join(scratch1,\"cdw_trace_results_merged\"), \n",
    "                     os.path.join(scratch1, \"cdw_trace_results_erase\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, February 14, 2024 3:49:33 PM\",\"Succeeded at Wednesday, February 14, 2024 3:49:39 PM (Elapsed Time: 6.07 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_erase_SP'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MultipartToSinglepart(in_features = os.path.join(scratch1, \"cdw_trace_results_erase\"),\n",
    "                                       out_feature_class = os.path.join(scratch1, \"cdw_trace_erase_SP\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, February 14, 2024 3:37:16 PM\",\"Succeeded at Wednesday, February 14, 2024 3:37:17 PM (Elapsed Time: 1.11 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'cdw_trace_erase_lyr'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints(os.path.join(lscratch, \"cdw_trace_results_part1\"), os.path.join(scratch1, \"cdw_trace_results_bothpts\"), 'BOTH_ENDS')\n",
    "#Select remaining upstream non-cdw lines that intersect with end point (or just not start point maybe) of part1 results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, February 14, 2024 3:49:40 PM\",\"Succeeded at Wednesday, February 14, 2024 3:49:41 PM (Elapsed Time: 0.26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'cdw_trace_erase_lyr'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"cdw_trace_erase_SP\"), \"cdw_trace_erase_lyr\")\n",
    "arcpy.management.SelectLayerByLocation(\"cdw_trace_erase_lyr\", 'INTERSECT', os.path.join(scratch1,\"cdw_trace_results_merged\"))\n",
    "arcpy.management.SelectLayerByLocation(\"cdw_trace_erase_lyr\", 'INTERSECT', os.path.join(scratch1, \"cdw_trace_results_bothpts\"), selection_type = \"SUBSET_SELECTION\", invert_spatial_relationship = \"INVERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, February 14, 2024 3:57:10 PM\",\"Succeeded at Wednesday, February 14, 2024 3:57:13 PM (Elapsed Time: 2.87 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_results_missed'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(\"cdw_trace_erase_lyr\", os.path.join(scratch1,\"cdw_trace_results_missed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#For some reason the upstream trace did not always get to the desired length, so some are trace short. \n",
    "\n",
    "#merge cdw_trace_results_missed with other results\n",
    "#erase merge results from non-cdw\n",
    "#buffer dissolve the remaining non cdw erase segments\n",
    "#select from upstream merge any segments that are < 5280\n",
    "#make starting points or just make a layer from them\n",
    "#Select non-cdw that intersect starting points and are < ? 5280? 2640? Trial and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 2:48:01 PM\",\"Succeeded at Tuesday, February 20, 2024 2:48:04 PM (Elapsed Time: 3.50 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_results2'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(scratch1,\"cdw_trace_results_merged\"), os.path.join(scratch1,\"cdw_trace_results_missed\")],\n",
    "                       os.path.join(scratch1, \"cdw_trace_results2\")\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 2:48:22 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Tuesday, February 20, 2024 2:48:46 PM (Elapsed Time: 24.05 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_results_erase2'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge results and erase from cdw upstream erase lines to get remaining streams\n",
    "arcpy.analysis.Erase(os.path.join(scratch1,\"non_cdw_buffer_diss\"), \n",
    "                     os.path.join(scratch1,\"cdw_trace_results2\"), \n",
    "                     os.path.join(scratch1, \"cdw_trace_results_erase2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Making individual mutipart features from any connected portions of a linear network\n",
    "#https://gis.stackexchange.com/questions/174752/dissolve-a-polyline-feature-class-so-that-touching-features-dissolve-into-a-sing\n",
    "\n",
    "mp_input = os.path.join(scratch1, \"cdw_trace_results_erase2\")#Multipart polylines\n",
    "target_lines = os.path.join(scratch1, \"cdw_upstream_erase_SP\") #Singlepart target lines\n",
    "field_name = \"transfer_code\"\n",
    "\n",
    "arcpy.management.MultipartToSinglepart(mp_input, target_lines)\n",
    "\n",
    "if len(arcpy.ListFields(target_lines, field_name)) == 0:\n",
    "    print(\"Field does not exist\")       \n",
    "else:\n",
    "    arcpy.management.DeleteField(target_lines, field_name)\n",
    "    \n",
    "buffer = arcpy.analysis.Buffer(target_lines, os.path.join(scratch1,\"non_cdw_buffer\"), \"1 Feet\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "buffer1 = arcpy.management.MultipartToSinglepart(os.path.join(scratch1,\"non_cdw_buffer\"), os.path.join(scratch1,\"cdw_upstream_buffer_MultipartToSi1\"))\n",
    "arcpy.management.CalculateField(buffer1, field_name, \"!OBJECTID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "buffer_join = arcpy.analysis.SpatialJoin(target_lines, \n",
    "                                         buffer1, \n",
    "                                         os.path.join(scratch1,\"non_cdw_buffer_join\"), \n",
    "                                         \"JOIN_ONE_TO_ONE\", \n",
    "                                         \"KEEP_ALL\")\n",
    "non_cdw_diss1 = arcpy.management.Dissolve(buffer_join, \n",
    "                                        os.path.join(scratch1, \"non_cdw_buffer_diss1\"), \n",
    "                                        field_name, \n",
    "                                        None, \n",
    "                                        \"MULTI_PART\", \n",
    "                                        \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Making individual mutipart features from any connected portions of a linear network\n",
    "#https://gis.stackexchange.com/questions/174752/dissolve-a-polyline-feature-class-so-that-touching-features-dissolve-into-a-sing\n",
    "\n",
    "mp_input = os.path.join(scratch1, \"cdw_trace_results2\")#Multipart polylines\n",
    "target_lines = os.path.join(scratch1, \"cdw_upstream_SP1\") #Singlepart target lines\n",
    "field_name = \"transfer_code\"\n",
    "\n",
    "arcpy.management.MultipartToSinglepart(mp_input, target_lines)\n",
    "\n",
    "if len(arcpy.ListFields(target_lines, field_name)) == 0:\n",
    "    print(\"Field does not exist\")       \n",
    "else:\n",
    "    arcpy.management.DeleteField(target_lines, field_name)\n",
    "    \n",
    "buffer = arcpy.analysis.Buffer(target_lines, os.path.join(scratch1,\"cdw_upbuffer\"), \"1 Feet\", \"FULL\", \"ROUND\", \"ALL\", None, \"PLANAR\")\n",
    "buffer1 = arcpy.management.MultipartToSinglepart(os.path.join(scratch1,\"cdw_upbuffer\"), os.path.join(scratch1,\"cdw_upbuffer_MultipartToSi1\"))\n",
    "arcpy.management.CalculateField(buffer1, field_name, \"!OBJECTID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "buffer_join = arcpy.analysis.SpatialJoin(target_lines, \n",
    "                                         buffer1, \n",
    "                                         os.path.join(scratch1,\"cdw_upbuffer_join\"), \n",
    "                                         \"JOIN_ONE_TO_ONE\", \n",
    "                                         \"KEEP_ALL\")\n",
    "cdw_up_diss = arcpy.management.Dissolve(buffer_join, \n",
    "                                        os.path.join(scratch1, \"cdw_upbuffer_diss\"), \n",
    "                                        field_name, \n",
    "                                        None, \n",
    "                                        \"MULTI_PART\", \n",
    "                                        \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cdw_upresults = arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"cdw_upbuffer_diss\"), \"cdw_upstream\", where_clause = \"Shape_Length < 5280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Select start points that DO NOT intersect the between/upstream lines already seleced\n",
    "cdw_upresults = arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"cdw_upbuffer_diss\"), \"cdw_upstream\", where_clause = \"Shape_Length < 5280\")\n",
    "\n",
    "arcpy.management.SelectLayerByLocation(cdw_upresults, \n",
    "                                       overlap_type = \"INTERSECT\", \n",
    "                                       select_features = non_cdw_diss1, \n",
    "                                       #search_distance, \n",
    "                                       selection_type = \"SUBSET_SELECTION\"\n",
    "                                       #invert_spatial_relationship\n",
    "                                      )\n",
    "cdw__sel = arcpy.management.MakeFeatureLayer(cdw_upresults, \"cdw_up_sel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 3:58:33 PM\",\"Succeeded at Tuesday, February 20, 2024 3:58:36 PM (Elapsed Time: 3.58 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\temp_end_pts'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints(cdw__sel, os.path.join(scratch1, \"temp_end_pts\"), 'END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "non_cdw_erase = arcpy.management.MakeFeatureLayer(non_cdw_diss1, \"non_cdw_erase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 4:29:09 PM\",\"Succeeded at Tuesday, February 20, 2024 4:29:09 PM (Elapsed Time: 0.43 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'non_cdw_erase'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.SelectLayerByLocation(non_cdw_erase, \n",
    "                                       overlap_type = \"INTERSECT\", \n",
    "                                       select_features = cdw__sel, \n",
    "                                       #search_distance, \n",
    "                                       selection_type = \"SUBSET_SELECTION\"\n",
    "                                       #invert_spatial_relationship\n",
    "                                      )\n",
    "\n",
    "arcpy.management.SelectLayerByLocation(non_cdw_erase, \n",
    "                                       overlap_type = \"INTERSECT\", \n",
    "                                       select_features = os.path.join(scratch1, \"temp_end_pts\"), \n",
    "                                       #search_distance, \n",
    "                                       selection_type = \"SUBSET_SELECTION\",\n",
    "                                       invert_spatial_relationship = \"INVERT\"\n",
    "                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 4:27:03 PM\",\"Succeeded at Tuesday, February 20, 2024 4:27:07 PM (Elapsed Time: 3.96 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_results_missed1'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.conversion.ExportFeatures(non_cdw_erase, \n",
    "                                os.path.join(scratch1,\"cdw_trace_results_missed1\"),\n",
    "                                where_clause = \"Shape_Length < 3200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 4:31:03 PM\",\"Succeeded at Tuesday, February 20, 2024 4:31:06 PM (Elapsed Time: 2.71 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\non_cdw_long_strags'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(non_cdw_erase, os.path.join(scratch1, \"non_cdw_long_strags\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 4:31:06 PM\",\"Succeeded at Tuesday, February 20, 2024 4:31:06 PM (Elapsed Time: 0.21 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'non_cdw_erase_long'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"non_cdw_long_strags\"), \n",
    "                                  \"non_cdw_erase_long\", \n",
    "                                  where_clause = \"Shape_Length > 3200\")\n",
    "#Manual checking and edits on these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 5:08:37 PM\",\"Succeeded at Tuesday, February 20, 2024 5:08:40 PM (Elapsed Time: 2.86 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\cdw_trace_results_missed2'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.CopyFeatures(\"non_cdw_erase_long\", \n",
    "                              os.path.join(scratch1,\"cdw_trace_results_missed2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 5:24:06 PM\",\"Succeeded at Tuesday, February 20, 2024 5:24:09 PM (Elapsed Time: 3.75 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\cdw_trace_results3'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(scratch1, \"cdw_trace_results2\"), os.path.join(scratch1,\"cdw_trace_results_missed1\"), os.path.join(scratch1,\"cdw_trace_results_missed2\")],\n",
    "                       os.path.join(home, \"cdw_trace_results3\")\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, February 20, 2024 5:29:17 PM\",\"Dissolving...\",\"Succeeded at Tuesday, February 20, 2024 5:29:34 PM (Elapsed Time: 16.68 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\CDW_1mile_upstream_final'>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Dissolve(\n",
    "    in_features=os.path.join(home, \"cdw_trace_results3\"),\n",
    "    out_feature_class= os.path.join(home, \"CDW_1mile_upstream_final\"),\n",
    "    dissolve_field=None,\n",
    "    statistics_fields=None,\n",
    "    multi_part=\"MULTI_PART\",\n",
    "    unsplit_lines=\"DISSOLVE_LINES\",\n",
    "    concatenation_separator=\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Code Streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# streams to merge\n",
    "nj2015_temp2 = os.path.join(home, \"stream_regs_with_exclusions_v2\")\n",
    "\n",
    "c1_upstream = os.path.join(home, \"C1_upstream_final\")\n",
    "tm_upstream = os.path.join(home, \"TM_1mile_upstream_final\")\n",
    "cdw_upstream = os.path.join(home, \"CDW_1mile_upstream_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Align upstream lines with nhd network due to edits in network\n",
    "#arcpy.edit.AlignFeatures(tm_upstream, nj2015_temp2, 50)\n",
    "#arcpy.edit.AlignFeatures(cdw_upstream, nj2015_temp2, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 2:18:22 PM\",\"Succeeded at Friday, March 1, 2024 2:18:26 PM (Elapsed Time: 3.39 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\tm_up_pts'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.FeatureVerticesToPoints(c1_upstream, os.path.join(scratch1, \"c1_up_pts\"), \"BOTH_ENDS\")\n",
    "arcpy.management.FeatureVerticesToPoints(tm_upstream, os.path.join(scratch1, \"tm_up_pts\"), \"BOTH_ENDS\")\n",
    "arcpy.management.FeatureVerticesToPoints(cdw_upstream, os.path.join(scratch1, \"cdw_up_pts\"), \"BOTH_ENDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 2:20:45 PM\",\"Succeeded at Friday, March 1, 2024 2:20:50 PM (Elapsed Time: 5.63 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\up_ends_merge'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(scratch1,\"c1_up_pts\"),os.path.join(scratch1,\"tm_up_pts\"),os.path.join(scratch1,\"cdw_up_pts\")],\n",
    "                      os.path.join(scratch1, \"up_ends_merge\"))\n",
    "arcpy.management.DeleteIdentical(os.path.join(scratch1, \"up_ends_merge\"), \"Shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 2:24:06 PM\",\"Succeeded at Friday, March 1, 2024 2:27:03 PM (Elapsed Time: 2 minutes 57 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\up_ends_merge_SP'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"up_ends_merge\"), \n",
    "                                       os.path.join(scratch1, \"up_ends_merge_SP\"))\n",
    "\n",
    "#snap intersected points to nhd points\n",
    "arcpy.edit.Snap(os.path.join(scratch1, \"up_ends_merge_SP\"), \n",
    "                [[nj2015_temp2, 'EDGE', '10 feet']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 3:06:08 PM\",\"Succeeded at Friday, March 1, 2024 3:10:54 PM (Elapsed Time: 4 minutes 46 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\stream_regs_with_exclusions_v3'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.SplitLineAtPoint(nj2015_temp2, \n",
    "                                  os.path.join(scratch1, \"up_ends_merge\"), \n",
    "                                  os.path.join(home, \"stream_regs_with_exclusions_v3\"),\n",
    "                                  '5 feet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 3:10:55 PM\",\"Succeeded at Friday, March 1, 2024 3:10:55 PM (Elapsed Time: 0.19 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'nhd_lines'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(os.path.join(home, \"stream_regs_with_exclusions_v3\"), \"nhd_lines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Add upstream columns\n",
    "arcpy.management.SelectLayerByLocation(\"nhd_lines\", \n",
    "                                       \"SHARE_A_LINE_SEGMENT_WITH\", \n",
    "                                       c1_upstream\n",
    "                                      )\n",
    "\n",
    "input_fc = os.path.join(home, \"stream_regs_with_exclusions_v3\")\n",
    "field_name = \"C1_upstream\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"nhd_lines\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"nhd_lines\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        else:\n",
    "            row[1] = 0\n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Add upstream columns\n",
    "arcpy.management.SelectLayerByLocation(\"nhd_lines\", \n",
    "                                       \"SHARE_A_LINE_SEGMENT_WITH\", \n",
    "                                       tm_upstream\n",
    "                                      )\n",
    "\n",
    "input_fc = os.path.join(home, \"stream_regs_with_exclusions_v3\")\n",
    "field_name = \"TM_upstream\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"nhd_lines\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"nhd_lines\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        else:\n",
    "            row[1] = 0\n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Add upstream columns\n",
    "arcpy.management.SelectLayerByLocation(\"nhd_lines\", \n",
    "                                       \"SHARE_A_LINE_SEGMENT_WITH\", \n",
    "                                       cdw_upstream\n",
    "                                      )\n",
    "\n",
    "input_fc = os.path.join(home, \"stream_regs_with_exclusions_v3\")\n",
    "field_name = \"CDW_upstream\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"nhd_lines\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"nhd_lines\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        else:\n",
    "            row[1] = 0\n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up and finishing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Assembling Background Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 11:59:27 AM\",\"Succeeded at Friday, March 1, 2024 11:59:31 AM (Elapsed Time: 3.73 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\Riparian_Zone_Input_Layers.gdb\\\\CategoryOneStreams'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nj2015_swqs = os.path.join(home,\"nhd_swqs_join\")\n",
    "\n",
    "#Export a layer for each category\n",
    "arcpy.conversion.ExportFeatures(nj2015_swqs, os.path.join(blayers, \"Streams_TroutProduction\"), where_clause = \"TP = 1\")\n",
    "arcpy.conversion.ExportFeatures(nj2015_swqs, os.path.join(blayers, \"Streams_TroutMaintenance\"), where_clause = \"TM = 1\")\n",
    "arcpy.conversion.ExportFeatures(nj2015_swqs, os.path.join(blayers, \"Streams_C1\"), where_clause = \"C1 = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 12:08:59 PM\",\"Succeeded at Friday, March 1, 2024 12:09:02 PM (Elapsed Time: 3.36 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\Riparian_Zone_Input_Layers.gdb\\\\LP_FHASCDW_inclusive'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Landscape Project CDW streams\n",
    "LP_all = os.path.join(newgdb, \"Landscape_proj_all_cdw\")\n",
    "arcpy.conversion.ExportFeatures(LP_all, os.path.join(blayers, \"LP_FHASCDW\"), where_clause = \"FHA_SCDW = 'Yes'\")\n",
    "arcpy.management.CopyFeatures(os.path.join(home, \"CDW_all_regions\"), os.path.join(blayers, \"LP_FHASCDW_inclusive\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 3:01:19 PM\",\"Succeeded at Friday, March 1, 2024 3:01:25 PM (Elapsed Time: 5.53 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\Riparian_Zone_Input_Layers.gdb\\\\All_SCDW_Features'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.conversion.ExportFeatures(os.path.join(home, \"nhd_cdw_split1\"), \n",
    "                               os.path.join(blayers, \"CDW_All_Features_LP\"),\n",
    "                                where_clause = \"all_cdw = 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 1, 2024 12:26:38 PM\",\"Succeeded at Friday, March 1, 2024 12:26:41 PM (Elapsed Time: 3.50 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\Riparian_Zone_Input_Layers.gdb\\\\UnregulatedCanals'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unregulated LULC and canals\n",
    "lulc = r\"X:\\projects\\njwrap\\Data\\NJDEP_LULUC\\Land_lu_2015.gdb\\Land_lu_2015\"\n",
    "arcpy.conversion.ExportFeatures(lulc, \n",
    "                                os.path.join(blayers, \"UnregulatedLULC\"), \n",
    "                                where_clause = \"LU15 = 5120 Or LU15 = 7310 Or LU15 = 7320 Or LU15 = 7330 Or LU15 = 5430 Or LU15 = 6111 Or LU15 = 6112 Or LU15 = 6130 OR LU15 = 6141\"\n",
    "                               )\n",
    "\n",
    "arcpy.conversion.ExportFeatures(os.path.join(home, \"stream_regs_with_exclusions_v2\"),\n",
    "                                os.path.join(blayers, \"UnregulatedCanals\"),\n",
    "                                where_clause = \"Canal = 1\"\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Add some extra field information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Label Segments that aren't in SWQS\n",
    "    #Erase SWQS-aligned from nj2015\n",
    "    #Intersect to create points\n",
    "    #Split at points\n",
    "    #Select areas that don't share a segment/not identical (test results)\n",
    "    #Label selected areas as outside of SWQS mapping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Add possibly unregulated reason from LULC that are treated as unregulated but also from LULC and nhd that aren't exluded: stormwater basins, pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#1499 (Stormwater Basins)\n",
    "lulc = r\"X:\\projects\\njwrap\\Data\\NJDEP_LULUC\\Land_lu_2015.gdb\\Land_lu_2015\"\n",
    "splitting_polygon2 = arcpy.management.MakeFeatureLayer(lulc, \n",
    "                                                       \"sw_basin\", \n",
    "                                                       where_clause = \"LU15 = 1499\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Label segments that are in pipelines and probably not regulated\n",
    "#FTYPE = 428\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Adding buffer width columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Coding unregulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "streams_ed = os.path.join(home, \"stream_regs_with_exclusions_v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 8, 2024 3:51:15 PM\",\"Dissolving...\",\"Succeeded at Friday, March 8, 2024 3:51:27 PM (Elapsed Time: 11.88 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\lulc_exclusions_diss'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LULC excluded classes--identify them so that there is no upstream trace from theres\n",
    "\n",
    "#5120 (Canals) \n",
    "#7310, 7320, 7330 (Stone Quarries, Sand and Gravel Pits (Borrow Pits), Other Mining)\n",
    "#5430 (Atlantic Ocean) \n",
    "#5420 (Dredged Lagoon)\n",
    "#6111      Saline Marsh (Low marsh) \n",
    "#6112      Saline Marsh (High marsh) \n",
    "#6130      Vegetated Dune Communities \n",
    "#6141      Phragmites Dominate Coastal Wetlands \n",
    "\n",
    "\n",
    "nj2020_lulc = arcpy.management.MakeFeatureLayer(r\"https://services1.arcgis.com/QWdNfRs7lkPq4g4Q/arcgis/rest/services/Land_Use_2020/FeatureServer/5\", \"lulc2020\")\n",
    "unregulatedlulc = arcpy.management.MakeFeatureLayer(nj2020_lulc, \n",
    "                                                       \"lulc_unregulated\", \n",
    "                                                       where_clause = \"LU15 = 5120 Or LU15 = 7310 Or LU15 = 7320 Or LU15 = 7330 Or LU15 = 5430 Or LU15 = 6111 Or LU15 = 6112 Or LU15 = 6130 OR LU15 = 6141\"\n",
    "                                                       )\n",
    "\n",
    "arcpy.management.Dissolve(\"lulc_unregulated\", os.path.join(home,\"lulc_exclusions_diss\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "#Add exclusion field for LULC\n",
    "input_lines = streams_ed\n",
    "splitting_polygon = os.path.join(home,\"lulc_exclusions_diss\")\n",
    "field_name = \"regulated\"\n",
    "output =  os.path.join(home, \"stream_regs_with_exclusions_v4\")\n",
    "\n",
    "split_by_polygon_zero(input_lines, splitting_polygon, field_name, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Labeling canals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buffer2 = arcpy.analysis.Buffer(os.path.join(scratch1, \"canals_PolygonToCenterline\"), \n",
    "                                os.path.join(scratch1,\"temp_buffer2\"), \n",
    "                                \"80 Feet\", \n",
    "                                \"FULL\", \n",
    "                                \"FLAT\", \"ALL\", None, \"PLANAR\")                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 8, 2024 3:59:33 PM\",\"Succeeded at Friday, March 8, 2024 3:59:33 PM (Elapsed Time: 0.22 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'lyr_lines1'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(os.path.join(home, \"stream_regs_with_exclusions_v4\"), \"lyr_lines1\")\n",
    "\n",
    "arcpy.management.SelectLayerByLocation(\"lyr_lines1\", \n",
    "                                       \"WITHIN\", \n",
    "                                       buffer2)\n",
    "arcpy.management.SelectLayerByAttribute(\"lyr_lines1\",\n",
    "                                        selection_type = \"ADD_TO_SELECTION\",\n",
    "                                        where_clause = \"GNIS_NAME LIKE '%Canal'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "input_fc = os.path.join(home, \"stream_regs_with_exclusions_v4\")\n",
    "field_name = \"regulated\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"lyr_lines1\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"lyr_lines1\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 0\n",
    "        else:\n",
    "            row[0] = 1 \n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "input_fc = os.path.join(home, \"stream_regs_with_exclusions_v4\")\n",
    "field_name = \"Canal\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Make a list from the selected features\n",
    "oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"lyr_lines1\",[\"OID@\"])]\n",
    "oidfield = arcpy.Describe(\"lyr_lines1\").OIDFieldName\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "#Code features in the list \n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 1\n",
    "        else:\n",
    "            row[0] = 0 \n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "streams_ed = os.path.join(home, \"stream_regs_with_exclusions_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Clean up some of the extraneous fields\n",
    "# Use ListFields to get a list of field objects\n",
    "fieldObjList = arcpy.ListFields(streams_ed, \"ORIG*\")\n",
    "\n",
    "# Create an empty list that will be populated with field names        \n",
    "fieldNameList = []\n",
    "\n",
    "# For each field in the object list, add the field name to the\n",
    "# name list. Exclude required fields to prevent errors\n",
    "for field in fieldObjList:\n",
    "    if not field.required:\n",
    "        fieldNameList.append(field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORIG_FID', 'ORIG_SEQ']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldNameList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 8, 2024 4:00:06 PM\",\"Succeeded at Friday, March 8, 2024 4:00:15 PM (Elapsed Time: 8.99 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\stream_regs_with_exclusions_v4'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.DeleteField(in_table = streams_ed, \n",
    "                             drop_field = fieldNameList, \n",
    "                             method = \"DELETE_FIELDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "# Add field to for each buffer width\n",
    "if len(arcpy.ListFields(streams_ed, \"buffer_width_300\")) == 0:\n",
    "         arcpy.AddField_management(streams_ed, \"buffer_width_300\", \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#300' Buffer\n",
    "fields = ['C1', 'C1_upstream', 'buffer_width_300']  \n",
    "\n",
    "with arcpy.da.UpdateCursor(streams_ed, fields) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] + row[1] > 0:\n",
    "            row[2] = 1\n",
    "        else:\n",
    "            row[2] = 0\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "#150' buffer\n",
    "if len(arcpy.ListFields(streams_ed, \"buffer_width_150\")) == 0:\n",
    "         arcpy.AddField_management(streams_ed, \"buffer_width_150\", \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "fields1 = ['TP', 'TP_upstream', 'TM', 'TM_upstream', 'all_cdw', 'CDW_upstream', 'buffer_width_150']\n",
    "with arcpy.da.UpdateCursor(streams_ed, fields1) as cursor:\n",
    "    for row in cursor:\n",
    "        res_list = [x for x in row[0:6]]\n",
    "        result = sum(res_list)\n",
    "        if result > 0:\n",
    "            row[6] = 1\n",
    "        else:\n",
    "            row[6] = 0\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "#50 buffer\n",
    "if len(arcpy.ListFields(streams_ed, \"buffer_width_50\")) == 0:\n",
    "         arcpy.AddField_management(streams_ed, \"buffer_width_50\", \"SHORT\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "fields2 = ['buffer_width_300', 'buffer_width_150', 'buffer_width_50']\n",
    "\n",
    "with arcpy.da.UpdateCursor(streams_ed, fields2) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] + row[1] > 0:\n",
    "            row[2] = 0\n",
    "        else:\n",
    "            row[2] = 1\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Widest buffer\n",
    "\n",
    "arcpy.management.AddField(streams_ed, \"widest_buffer_width\", 'SHORT')\n",
    "fields3 = ['buffer_width_300', 'buffer_width_150', 'regulated', 'widest_buffer_width']\n",
    "\n",
    "with arcpy.da.UpdateCursor(streams_ed, fields3) as cursor:\n",
    "    for row in cursor:\n",
    "        if row [2] == 0:\n",
    "            row[3] = 0\n",
    "        elif row[0] == 1:\n",
    "            row[3] = 300\n",
    "        elif row[1] == 1:\n",
    "            row[3] = 150\n",
    "        else:        \n",
    "            row[3] = 50\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240308_160120\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 8, 2024 4:01:21 PM\",\"Succeeded at Friday, March 8, 2024 4:01:29 PM (Elapsed Time: 8.78 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_RiparianZones_20240308_160120'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(timestr)\n",
    "arcpy.management.CopyFeatures(streams_ed, os.path.join(home, f\"FHA_RiparianZones_{timestr}\"), '', None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "streams_ed = os.path.join(home, f\"FHA_RiparianZones_{timestr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GNIS_NAME', 'C1', 'TP', 'TM', 'all_cdw', 'regulated', 'Canal', 'TP_upstream', 'C1_upstream', 'TM_upstream', 'CDW_upstream', 'buffer_width_300', 'buffer_width_150', 'buffer_width_50', 'widest_buffer_width']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of keeper fields and delete the rest\n",
    "#If these terms are in the field names, keep the field\n",
    "keeper_txt = ['cdw', 'C1', 'c1', 'TP', 'TM', 'CDW', 'buffer', 'regulated', 'GNIS', 'Canal']\n",
    "\n",
    "# Add all fields from inputs.\n",
    "flist = [f.name for f in arcpy.ListFields(streams_ed)]\n",
    "\n",
    "# Name fields you want. Could get these names programmatically too.\n",
    "keepers = [f for f in flist if(any(ele in f for ele in keeper_txt))]\n",
    "\n",
    "keepers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 8, 2024 4:01:30 PM\",\"Succeeded at Friday, March 8, 2024 4:01:43 PM (Elapsed Time: 13.23 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_RiparianZones_20240308_160120'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Delete fields\n",
    "arcpy.management.DeleteField(streams_ed, keepers, \"KEEP_FIELDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C1', 'TP', 'TM', 'all_cdw', 'regulated', 'Canal', 'TP_upstream', 'C1_upstream', 'TM_upstream', 'CDW_upstream', 'buffer_width_300', 'buffer_width_150', 'buffer_width_50']\n"
     ]
    }
   ],
   "source": [
    "field_names = [f.name for f in arcpy.ListFields(streams_ed, field_type= 'SmallInteger')]\n",
    "field_names.remove('widest_buffer_width')\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Translate fields to more user-friendly yes/no instead of 1/0\n",
    "#Calculate field if oldfield = 1, return 'Yes'\n",
    "\n",
    "#New field, string\n",
    "for field in field_names:\n",
    "    new_field = f\"{field}_a\"\n",
    "    arcpy.management.AddField(streams_ed, new_field, 'TEXT')\n",
    "    fields2 = [field, new_field]\n",
    "    \n",
    "    with arcpy.da.UpdateCursor(streams_ed, fields2) as cursor:\n",
    "        for row in cursor:\n",
    "            if row[0] == 1:\n",
    "                row[1] = \"Yes\"\n",
    "            else:\n",
    "                row[1] = \"No\"\n",
    "# Update the cursor with the updated list\n",
    "            cursor.updateRow(row)\n",
    "    del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fields clean up from making new text fields\n",
    "arcpy.management.DeleteField(streams_ed, field_names)\n",
    "\n",
    "#update field names\n",
    "fieldList = arcpy.ListFields(streams_ed)\n",
    "for field in fieldList:\n",
    "    if field.name.endswith('_a'):\n",
    "        new_field = field.name[:-2]\n",
    "        arcpy.management.AlterField(streams_ed, field.name, new_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OBJECTID', 'SHAPE', 'GNIS_NAME', 'widest_buffer_width', 'SHAPE_Length', 'C1', 'TP', 'TM', 'all_cdw', 'regulated', 'Canal', 'TP_upstream', 'C1_upstream', 'TM_upstream', 'CDW_upstream', 'buffer_width_300', 'buffer_width_150', 'buffer_width_50']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_names = [f.name for f in arcpy.ListFields(streams_ed)]\n",
    "field_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# make things mutually exclusive:\n",
    "\n",
    "with arcpy.da.UpdateCursor(streams_ed, field_names) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[5] == 'Yes': #C1\n",
    "            row[12] = 'No'  #C1 upstream\n",
    "        elif row[6] == 'Yes':\n",
    "            row[11] = 'No'\n",
    "        elif row [7] == 'Yes':\n",
    "            row[13] = 'No'\n",
    "        elif row[8] == 'Yes':        \n",
    "            row[14] = 'No'\n",
    "# Update the cursor with the updated list\n",
    "        cursor.updateRow(row)\n",
    "del cursor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'SHAPE', 'GNIS_NAME', 'widest_buffer_width', 'SHAPE_Length', 'C1', 'TP', 'TM', 'all_cdw', 'regulated', 'Canal', 'TP_upstream', 'C1_upstream', 'TM_upstream', 'CDW_upstream', 'buffer_width_300', 'buffer_width_150', 'buffer_width_50']\n"
     ]
    }
   ],
   "source": [
    "#Reorder fields. Could do above when I translate from 0/1 to yes/no\n",
    "messy_input_file = streams_ed\n",
    "#Get the field names in your file\n",
    "field_names = [f.name for f in arcpy.ListFields(messy_input_file)]\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Reorder them however you want. Just include the fields you want to keep. Keep OBJECTID but don't keep any of the other standard fields (Shape, Shape_Length, Shape_Area)\n",
    "new_field_order = ['OBJECTID', 'widest_buffer_width', 'GNIS_NAME', 'regulated', 'Canal',  'C1', 'TP', 'TM', 'all_cdw', 'C1_upstream', 'TP_upstream', 'TM_upstream', 'CDW_upstream', 'buffer_width_300', 'buffer_width_150', 'buffer_width_50']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "messy_input_file = streams_ed\n",
    "out_path = home\n",
    "out_name = f\"FHA_RiparianZones_{timestr}\"\n",
    "#new_field_order = \n",
    "reorder_streams = os.path.join(home, f\"FHA_RiparianZones_{timestr}\") \n",
    "\n",
    "reorderfields(messy_input_file, out_path, out_name, new_field_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 8, 2024 4:11:05 PM\",\"Succeeded at Friday, March 8, 2024 4:11:06 PM (Elapsed Time: 0.64 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_RiparianZones_20240308_160842'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reorder_streams = os.path.join(home, f\"FHA_RiparianZones_{timestr}\") \n",
    "\n",
    "#Clean up of fields, rename and give aliases\n",
    "arcpy.management.AlterField(reorder_streams, 'all_cdw', new_field_name = 'FHA_SCDW', new_field_alias = \"FHA_SCDW\")\n",
    "arcpy.management.AlterField(reorder_streams, 'CDW_upstream', new_field_name = 'FHA_SCDW_upstream', new_field_alias = \"Drains to E&T habitat stream\")\n",
    "\n",
    "#arcpy.management.AlterField(reorder_streams, 'FHA_SCDW', new_field_alias = \"FHA_SCDW\")\n",
    "#arcpy.management.AlterField(reorder_streams, 'FHA_SCDW_upstream', new_field_alias = \"Drains to E&T habitat stream\")\n",
    "\n",
    "\n",
    "arcpy.management.AlterField(reorder_streams, 'buffer_width_300', new_field_alias = \"300 foot buffer\")\n",
    "arcpy.management.AlterField(reorder_streams, 'buffer_width_150', new_field_alias = '150 foot buffer')\n",
    "arcpy.management.AlterField(reorder_streams, 'buffer_width_50', new_field_alias = '50 foot buffer')\n",
    "arcpy.management.AlterField(reorder_streams, 'widest_buffer_width', new_field_alias = 'Widest Applicable Buffer')\n",
    "arcpy.management.AlterField(reorder_streams, \"C1\", '', \"Category One\")\n",
    "arcpy.management.AlterField(reorder_streams, \"TP\", '', \"Trout Production\")\n",
    "arcpy.management.AlterField(reorder_streams, \"TM\", '', \"Trout Maintenance\")\n",
    "arcpy.management.AlterField(reorder_streams, 'regulated', new_field_alias = \"Regulated by FHA\")\n",
    "arcpy.management.AlterField(reorder_streams, 'Canal', new_field_alias = \"Unregulated Canal\")\n",
    "\n",
    "#Alias the upstreams\n",
    "arcpy.management.AlterField(reorder_streams, \"c1_upstream\", '', \"Drains to C1 stream\")\n",
    "arcpy.management.AlterField(reorder_streams, \"TP_upstream\", '', \"Drains to Trout Production stream\")\n",
    "arcpy.management.AlterField(reorder_streams, \"TM_upstream\", '', \"Drains to Trout Maintenance stream\")\n",
    "\n",
    "#Shape field\n",
    "arcpy.management.AlterField(reorder_streams, \"Shape_Length\", '', \"Lenth (ft)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FHA_RiparianZones_20240308_160842\n"
     ]
    }
   ],
   "source": [
    "print(f\"FHA_RiparianZones_{timestr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating buffer polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream water bodies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams = arcpy.management.MakeFeatureLayer(os.path.join(home, \"FHA_RiparianZones_20240308_160842\"), \"stream_classes_lyr\") #, \"FTYPE <> 566\") #exclude coastlines\n",
    "nj2015_polys = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\Hydr_NHD_2015_waterbody'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Non-Delaware River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Stream polys without the delware river. Run Delware separately because it needs to be wider and has some other issues\n",
    "stream_polysND = arcpy.management.MakeFeatureLayer(nj2015_polys, \"stream_polys\", \"FTYPE = 460 And GNIS_NAME <> 'Delaware River'\") #Include estuaries? FTYPE 493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Select only stream polys (not ponds/lakes/estuaries) and corresponding centerlines\n",
    "#if arcpy.Exists(os.path.join(scratch1, \"stream_polys_Dissolve1\")):\n",
    "#    print(\"File exists\")\n",
    "#else:\n",
    "arcpy.management.Dissolve(stream_polysND, \n",
    "                        os.path.join(scratch1, \"stream_polys_Dissolve1\"), \n",
    "                        dissolve_field = ['GNIS_NAME'],\n",
    "                        multi_part = \"SINGLE_PART\"\n",
    "                             )\n",
    "    \n",
    "stream_polys_diss = os.path.join(scratch1, \"stream_polys_Dissolve1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stream_polys_diss = os.path.join(scratch1, \"stream_polys_Dissolve1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 11, 2024 11:33:57 AM\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Monday, March 11, 2024 11:36:56 AM (Elapsed Time: 2 minutes 58 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\streampolys_clip'>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Clip(streams, stream_polys_diss, os.path.join(scratch1, \"streampolys_clip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Get list of unique values from a field\n",
    "# def unique_values(table, field):\n",
    "#     with arcpy.da.SearchCursor(table, [field]) as cursor:\n",
    "#         return sorted({row[0] for row in cursor})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Add upstream columns\n",
    "# stream_clips = arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"streampolys_clip\"), \"stream_clips\")\n",
    "\n",
    "# input_fc = stream_clips\n",
    "# field_name = \"PolygonNameMatch\"\n",
    "\n",
    "# if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "#          arcpy.AddField_management(input_fc, field_name, \"SHORT\")\n",
    "# else:\n",
    "#     print(\"Field exists\")\n",
    "\n",
    "# #Make a list of GNIS names for polygons\n",
    "# sp_list = unique_values(stream_polys_diss, \"GNIS_NAME\")\n",
    "# fields = [\"GNIS_Name\", field_name]\n",
    "\n",
    "# #Code features in the list \n",
    "# with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "#     for row in curs:\n",
    "#         if row[0] in sp_list: \n",
    "#             row[1] = 1\n",
    "#         else:\n",
    "#             row[1] = 0\n",
    "#         curs.updateRow(row)\n",
    "# del curs\n",
    "\n",
    "# #select streams in list \n",
    "# arcpy.management.SelectLayerByAttribute(stream_clips, where_clause = \"PolygonNameMatch = 1\") #, {invert_where_clause})\n",
    "\n",
    "# arcpy.management.CopyFeatures(stream_clips, os.path.join(scratch1, \"streampolyNameMatch\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buffer = arcpy.analysis.Buffer(os.path.join(scratch1, \"streampolys_clip\"), os.path.join(scratch1, \"streams_temp_buffer\"), \"1 Feet\", \"FULL\", \"ROUND\", \"LIST\", ['widest_buffer_width'])\n",
    "buffer1 = arcpy.management.MultipartToSinglepart(buffer, os.path.join(scratch1, \"temp_MultipartToSi1\"))\n",
    "arcpy.management.CalculateField(buffer1, \"transfer_code\", \"!OBJECTID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "buffer_join = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"streampolys_clip\"), buffer1, os.path.join(scratch1, \"clip_streams_by_width_ND\"), \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", match_option = \"WITHIN\")\n",
    "temp1 = arcpy.management.Dissolve(buffer_join, os.path.join(scratch1, \"clip_streams_diss_by_width_ND\"), [\"transfer_code\", \"widest_buffer_width\"], None, \"MULTI_PART\", \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "long_streams1 = arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"clip_streams_diss_by_width_ND\"), \"long_streams_only\", \"Shape_Length > 700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 4:12:04 PM\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Wednesday, March 13, 2024 4:13:25 PM (Elapsed Time: 1 minutes 21 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_poly_streams_clip'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.SelectLayerByLocation(streams, \"SHARE_A_LINE_SEGMENT_WITH\", long_streams1)\n",
    "arcpy.management.CopyFeatures(streams, os.path.join(scratch1, \"stream_poly_streams\"))\n",
    "arcpy.analysis.Clip(os.path.join(scratch1, \"stream_poly_streams\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"stream_poly_streams_clip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 4:13:26 PM\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Wednesday, March 13, 2024 4:14:47 PM (Elapsed Time: 1 minutes 20 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_poly_streams_clip'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Clip(os.path.join(scratch1, \"stream_poly_streams\"), stream_polys_diss, os.path.join(scratch1, \"stream_poly_streams_clip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "long_streams = os.path.join(scratch1, \"stream_poly_streams_clip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 12:25:04 PM\",\"Succeeded at Wednesday, March 13, 2024 12:25:17 PM (Elapsed Time: 12.35 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects300_transitions'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"300ft_buffer\", \"widest_buffer_width = 300\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"300ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,\"Transects_300ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"500 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_300ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip300\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip300\"), os.path.join(scratch1, \"transects_clip300_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip300_SP\"), \"transects_300\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_300\", \"widest_buffer_width <> 300\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_300\", \"INTERSECT\", \"300ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_300\", \"INTERSECT\", \"non_300\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_300\", os.path.join(scratch1, \"transects300_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 12:26:42 PM\",\"Succeeded at Wednesday, March 13, 2024 12:26:53 PM (Elapsed Time: 11.26 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects150_transitions'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"150ft_buffer\", \"widest_buffer_width = 150\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"150ft_buffer\",\n",
    "    out_feature_class= os.path.join(scratch1,\"Transects_150ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"900 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_150ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip150\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip150\"), os.path.join(scratch1, \"transects_clip150_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip150_SP\"), \"transects_150\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_150\", \"widest_buffer_width <> 150\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_150\", \"INTERSECT\", \"150ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_150\", \"INTERSECT\", \"non_150\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_150\", os.path.join(scratch1, \"transects150_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 12:29:02 PM\",\"Succeeded at Wednesday, March 13, 2024 12:29:12 PM (Elapsed Time: 10.50 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects50_transitions'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"50ft_buffer\", \"widest_buffer_width = 50\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"50ft_buffer\",\n",
    "    out_feature_class= os.path.join(scratch1,\"Transects_50ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"900 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_50ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip50\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip50\"), os.path.join(scratch1, \"transects_clip50_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip50_SP\"), \"transects_50\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_50\", \"widest_buffer_width <> 50\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_50\", \"INTERSECT\", \"50ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_50\", \"INTERSECT\", \"non_50\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_50\", os.path.join(scratch1, \"transects50_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 12:30:21 PM\",\"Succeeded at Wednesday, March 13, 2024 12:30:30 PM (Elapsed Time: 9.40 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects0_transitions'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"0ft_buffer\", \"widest_buffer_width = 0\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"0ft_buffer\",\n",
    "    out_feature_class= os.path.join(scratch1,\"Transects_0ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"900 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_0ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip0\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip0\"), os.path.join(scratch1, \"transects_clip0_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip0_SP\"), \"transects_0\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_0\", \"widest_buffer_width <> 0\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_0\", \"INTERSECT\", \"0ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_0\", \"INTERSECT\", \"non_0\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_0\", os.path.join(scratch1, \"transects0_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 12:30:31 PM\",\"Succeeded at Wednesday, March 13, 2024 12:30:44 PM (Elapsed Time: 12.63 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transect_transitions_merge'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(scratch1, \"transects300_transitions\"), os.path.join(scratch1, \"transects150_transitions\"), os.path.join(scratch1, \"transects50_transitions\"), os.path.join(scratch1, \"transects0_transitions\")], \n",
    "                      os.path.join(scratch1, \"transect_transitions_merge\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Manual edits on Manasquan River, Rancocas Creek, Back Channel, Flat Creek, Swimming River, Mullica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 4:33:18 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Wednesday, March 13, 2024 4:33:37 PM (Elapsed Time: 19.32 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_polys_temp_split'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subdivide waterbodies by transects:\n",
    "arcpy.management.FeatureToPolygon([stream_polys_diss, os.path.join(scratch1, \"transect_transitions_merge\")], \n",
    "                                  os.path.join(scratch1, \"stream_polys_temp_split\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 4:33:54 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Wednesday, March 13, 2024 4:34:10 PM (Elapsed Time: 15.57 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_polys_split1'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#That process filled spaces that were not meant to be water\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"stream_polys_temp_split\"), \n",
    "                     os.path.join(scratch1, \"stream_polys_Dissolve1\"),\n",
    "                     os.path.join(scratch1, \"filled_holes\")\n",
    "                    )\n",
    "\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"stream_polys_temp_split\"), \n",
    "                     os.path.join(scratch1, \"filled_holes\"),\n",
    "                     os.path.join(scratch1, \"stream_polys_split1\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 4:34:30 PM\",\"Succeeded at Wednesday, March 13, 2024 4:35:14 PM (Elapsed Time: 44.56 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_buff'>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split stream lines at all polygon divisions, both preexisting in the dataset and from the transects\n",
    "arcpy.analysis.Intersect([os.path.join(scratch1, \"stream_polys_split1\"), long_streams1], \n",
    "                         os.path.join(scratch1, \"temp_split_pts\"), \n",
    "                         output_type = \"POINT\")\n",
    "\n",
    "arcpy.management.SplitLineAtPoint(long_streams1, \n",
    "                                  os.path.join(scratch1, \"temp_split_pts\"),\n",
    "                                  os.path.join(scratch1, \"split_streams_for_buff\"), \n",
    "                                  \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Wednesday, March 13, 2024 4:35:15 PM\",\"Succeeded at Wednesday, March 13, 2024 4:35:23 PM (Elapsed Time: 8.65 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_buff_sort'>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Sort(os.path.join(scratch1, \"split_streams_for_buff\"), \n",
    "                      os.path.join(scratch1, \"split_streams_for_buff_sort\"), \n",
    "                      [[\"Shape_Length\", \"DESCENDING\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poly_buffwidth = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"stream_polys_split1\"),\n",
    "                                            os.path.join(scratch1, \"split_streams_for_buff_sort\"), \n",
    "                                            os.path.join(home,\"stream_polys_buffwidth_join\"), \n",
    "                                            match_option = \"CONTAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#polygons with buffer widths joined\n",
    "spolys = arcpy.management.MakeFeatureLayer(os.path.join(home,\"stream_polys_buffwidth_join\"), \"spolys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fill nulls with values of adjacent polygons\n",
    "widths = [300, 150, 50, 0]\n",
    "\n",
    "for i in widths:\n",
    "    arcpy.management.MakeFeatureLayer(spolys, \"spoly_nulls\", where_clause = \"widest_buffer_width IS NULL\")\n",
    "    arcpy.management.MakeFeatureLayer(spolys, f\"{i}_buff\", where_clause = f\"widest_buffer_width = {i}\")\n",
    "    arcpy.management.SelectLayerByLocation(\"spoly_nulls\", \"BOUNDARY_TOUCHES\", f\"{i}_buff\")\n",
    "    \n",
    "    input_fc = os.path.join(home,\"stream_polys_buffwidth_join\")\n",
    "    field_name = \"widest_buffer_width\"\n",
    "\n",
    "    #Make a list from the selected features\n",
    "    oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"spoly_nulls\",[\"OID@\"])]\n",
    "    oidfield = arcpy.Describe(input_fc).OIDFieldName\n",
    "    fields = [oidfield, field_name]\n",
    "\n",
    "    #Code features in the list \n",
    "    with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "        for row in curs:\n",
    "            if row[0] in oidList: \n",
    "                row[1] = f\"{i}\"\n",
    "            curs.updateRow(row)\n",
    "    del curs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 12:23:25 PM\",\"Succeeded at Thursday, March 14, 2024 12:23:35 PM (Elapsed Time: 10.04 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\streams_lake_split'>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split lines at points\n",
    "arcpy.management.SplitLineAtPoint(os.path.join(scratch1, \"stream_lake_clip\"), \n",
    "                                  os.path.join(scratch1, \"lake_split_pts\"), \n",
    "                                  os.path.join(scratch1, \"streams_lake_split\"), \n",
    "                                  \"5 feet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Delaware River"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Stream polys without the delware river. Run Delware separately because it needs to be wider and has some other issues\n",
    "stream_polysD = arcpy.management.MakeFeatureLayer(nj2015_polys, \"stream_polys\", \"FTYPE = 460 And GNIS_NAME = 'Delaware River'\") #Include estuaries? FTYPE 493"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Select only stream polys (not ponds/lakes/estuaries) and corresponding centerlines\n",
    "#if arcpy.Exists(os.path.join(scratch1, \"stream_polys_Dissolve1\")):\n",
    "#    print(\"File exists\")\n",
    "#else:\n",
    "arcpy.management.Dissolve(stream_polysD, \n",
    "                        os.path.join(scratch1, \"stream_polys_DissolveD\"), \n",
    "                        dissolve_field = ['GNIS_NAME'],\n",
    "                        multi_part = \"SINGLE_PART\"\n",
    "                             )\n",
    "    \n",
    "stream_polys_diss = os.path.join(scratch1, \"stream_polys_DissolveD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stream_polys_diss = os.path.join(scratch1, \"stream_polys_DissolveD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:04:44 AM\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Thursday, March 14, 2024 11:05:13 AM (Elapsed Time: 28.43 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\streampolys_clip'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Clip(streams, stream_polys_diss, os.path.join(scratch1, \"streampolys_clip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "buffer = arcpy.analysis.Buffer(os.path.join(scratch1, \"streampolys_clip\"), os.path.join(scratch1, \"streams_temp_buffer\"), \"1 Feet\", \"FULL\", \"ROUND\", \"LIST\", ['widest_buffer_width'])\n",
    "buffer1 = arcpy.management.MultipartToSinglepart(buffer, os.path.join(scratch1, \"temp_MultipartToSi1\"))\n",
    "arcpy.management.CalculateField(buffer1, \"transfer_code\", \"!OBJECTID!\", \"PYTHON3\", '', \"LONG\", \"NO_ENFORCE_DOMAINS\")\n",
    "buffer_join = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"streampolys_clip\"), buffer1, os.path.join(scratch1, \"clip_streams_by_width_D\"), \"JOIN_ONE_TO_ONE\", \"KEEP_ALL\", match_option = \"WITHIN\")\n",
    "temp1 = arcpy.management.Dissolve(buffer_join, os.path.join(scratch1, \"clip_streams_diss_by_widthD\"), [\"transfer_code\", \"widest_buffer_width\"], None, \"MULTI_PART\", \"DISSOLVE_LINES\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "long_streams1 = arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"clip_streams_diss_by_widthD\"), \"long_streams_only\", \"Shape_Length > 700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:08:01 AM\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Thursday, March 14, 2024 11:08:04 AM (Elapsed Time: 2.97 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_poly_streams_clipD'>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.SelectLayerByLocation(streams, \"SHARE_A_LINE_SEGMENT_WITH\", long_streams1)\n",
    "arcpy.management.CopyFeatures(streams, os.path.join(scratch1, \"stream_poly_streams\"))\n",
    "arcpy.analysis.Clip(os.path.join(scratch1, \"stream_poly_streams\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"stream_poly_streams_clipD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "long_streams = os.path.join(scratch1, \"stream_poly_streams_clipD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:09:21 AM\",\"Succeeded at Thursday, March 14, 2024 11:09:24 AM (Elapsed Time: 3.28 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects300_transitions'>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"300ft_buffer\", \"widest_buffer_width = 300\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"300ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,\"Transects_300ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"5000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_300ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip300\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip300\"), os.path.join(scratch1, \"transects_clip300_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip300_SP\"), \"transects_300\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_300\", \"widest_buffer_width <> 300\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_300\", \"INTERSECT\", \"300ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_300\", \"INTERSECT\", \"non_300\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_300\", os.path.join(scratch1, \"transects300_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:09:42 AM\",\"Succeeded at Thursday, March 14, 2024 11:09:48 AM (Elapsed Time: 5.25 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects150_transitions'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"150ft_buffer\", \"widest_buffer_width = 150\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"150ft_buffer\",\n",
    "    out_feature_class= os.path.join(scratch1,\"Transects_150ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"5000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_150ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip150\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip150\"), os.path.join(scratch1, \"transects_clip150_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip150_SP\"), \"transects_150\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_150\", \"widest_buffer_width <> 150\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_150\", \"INTERSECT\", \"150ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_150\", \"INTERSECT\", \"non_150\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_150\", os.path.join(scratch1, \"transects150_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:10:09 AM\",\"Succeeded at Thursday, March 14, 2024 11:10:14 AM (Elapsed Time: 5.27 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects50_transitions'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"50ft_buffer\", \"widest_buffer_width = 50\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"50ft_buffer\",\n",
    "    out_feature_class= os.path.join(scratch1,\"Transects_50ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"5000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_50ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip50\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip50\"), os.path.join(scratch1, \"transects_clip50_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip50_SP\"), \"transects_50\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_50\", \"widest_buffer_width <> 50\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_50\", \"INTERSECT\", \"50ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_50\", \"INTERSECT\", \"non_50\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_50\", os.path.join(scratch1, \"transects50_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:10:35 AM\",\"Succeeded at Thursday, March 14, 2024 11:10:40 AM (Elapsed Time: 5.04 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects0_transitions'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.MakeFeatureLayer(long_streams, \"0ft_buffer\", \"widest_buffer_width = 0\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= \"0ft_buffer\",\n",
    "    out_feature_class= os.path.join(scratch1,\"Transects_0ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"5000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,\"Transects_0ft\"), \n",
    "                    stream_polys_diss, \n",
    "                    os.path.join(scratch1, \"transects_clip0\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, \"transects_clip0\"), os.path.join(scratch1, \"transects_clip0_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, \"transects_clip0_SP\"), \"transects_0\")\n",
    "arcpy.management.MakeFeatureLayer(long_streams, \"non_0\", \"widest_buffer_width <> 0\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_0\", \"INTERSECT\", \"0ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(\"transects_0\", \"INTERSECT\", \"non_0\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(\"transects_0\", os.path.join(scratch1, \"transects0_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:10:41 AM\",\"Succeeded at Thursday, March 14, 2024 11:10:46 AM (Elapsed Time: 4.54 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transect_transitions_mergeD'>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Merge([os.path.join(scratch1, \"transects300_transitions\"), os.path.join(scratch1, \"transects150_transitions\"), os.path.join(scratch1, \"transects50_transitions\"), os.path.join(scratch1, \"transects0_transitions\")], \n",
    "                      os.path.join(scratch1, \"transect_transitions_mergeD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Manual edits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:37:56 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, March 14, 2024 11:38:02 AM (Elapsed Time: 5.64 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_polys_temp_splitD'>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subdivide waterbodies by transects:\n",
    "arcpy.management.FeatureToPolygon([stream_polys_diss, os.path.join(scratch1, \"transect_transitions_mergeD\")], \n",
    "                                  os.path.join(scratch1, \"stream_polys_temp_splitD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:38:08 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, March 14, 2024 11:38:13 AM (Elapsed Time: 5.17 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_polys_splitD'>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#That process filled spaces that were not meant to be water\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"stream_polys_temp_splitD\"), \n",
    "                     stream_polys_diss,\n",
    "                     os.path.join(scratch1, \"filled_holes\")\n",
    "                    )\n",
    "\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"stream_polys_temp_splitD\"), \n",
    "                     os.path.join(scratch1, \"filled_holes\"),\n",
    "                     os.path.join(scratch1, \"stream_polys_splitD\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:38:19 AM\",\"Succeeded at Thursday, March 14, 2024 11:38:23 AM (Elapsed Time: 4.94 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_buffD'>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split stream lines at all polygon divisions, both preexisting in the dataset and from the transects\n",
    "arcpy.analysis.Intersect([os.path.join(scratch1, \"stream_polys_splitD\"), long_streams1], \n",
    "                         os.path.join(scratch1, \"temp_split_pts\"), \n",
    "                         output_type = \"POINT\")\n",
    "\n",
    "arcpy.management.SplitLineAtPoint(long_streams1, \n",
    "                                  os.path.join(scratch1, \"temp_split_pts\"),\n",
    "                                  os.path.join(scratch1, \"split_streams_for_buffD\"), \n",
    "                                  \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 11:38:24 AM\",\"Succeeded at Thursday, March 14, 2024 11:38:29 AM (Elapsed Time: 4.83 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_buffD_sort'>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Sort(os.path.join(scratch1, \"split_streams_for_buffD\"), \n",
    "                      os.path.join(scratch1, \"split_streams_for_buffD_sort\"), \n",
    "                      [[\"Shape_Length\", \"DESCENDING\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poly_buffwidth = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"stream_polys_splitD\"),\n",
    "                                            os.path.join(scratch1, \"split_streams_for_buffD_sort\"), \n",
    "                                            os.path.join(home,\"stream_polys_buffwidth_joinD\"), \n",
    "                                            match_option = \"CONTAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#polygons with buffer widths joined\n",
    "spolys = arcpy.management.MakeFeatureLayer(os.path.join(home,\"stream_polys_buffwidth_joinD\"), \"spolys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fill nulls with values of adjacent polygons\n",
    "widths = [300, 150, 50, 0]\n",
    "\n",
    "for i in widths:\n",
    "    arcpy.management.MakeFeatureLayer(spolys, \"spoly_nulls\", where_clause = \"widest_buffer_width IS NULL\")\n",
    "    arcpy.management.MakeFeatureLayer(spolys, f\"{i}_buff\", where_clause = f\"widest_buffer_width = {i}\")\n",
    "    arcpy.management.SelectLayerByLocation(\"spoly_nulls\", \"BOUNDARY_TOUCHES\", f\"{i}_buff\")\n",
    "    \n",
    "    input_fc = os.path.join(home,\"stream_polys_buffwidth_joinD\")\n",
    "    field_name = \"widest_buffer_width\"\n",
    "\n",
    "    #Make a list from the selected features\n",
    "    oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"spoly_nulls\",[\"OID@\"])]\n",
    "    oidfield = arcpy.Describe(input_fc).OIDFieldName\n",
    "    fields = [oidfield, field_name]\n",
    "\n",
    "    #Code features in the list \n",
    "    with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "        for row in curs:\n",
    "            if row[0] in oidList: \n",
    "                row[1] = f\"{i}\"\n",
    "            curs.updateRow(row)\n",
    "    del curs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Buffer other waterbodies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Buffer the remaining polygons that aren't streams, canals/ditches, or the ocean\n",
    "lake_polys = arcpy.management.MakeFeatureLayer(nj2015_polys, \"lake_polys\", \"FTYPE <> 460 And FTYPE <> 336 And FTYPE <> 445 And FTYPE <> 493\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Clip streams to lakes so that they will be \"within\"\n",
    "arcpy.analysis.Clip(streams, lake_polys, os.path.join(scratch1, \"stream_lake_clip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field exists\n"
     ]
    }
   ],
   "source": [
    "input_fc = lake_polys\n",
    "field_name = \"transfer_code_lakes\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.management.CalculateField(input_fc,\n",
    "                                         field_name, \n",
    "                                         \"!OBJECTID!\", \n",
    "                                         \"PYTHON3\", '', \n",
    "                                         \"LONG\", \n",
    "                                         \"NO_ENFORCE_DOMAINS\")\n",
    "else:\n",
    "    print(\"Field exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Make dissolved network of same width\n",
    "buffer_join = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"streams_lake_clip\"),\n",
    "                                         lake_polys, \n",
    "                                         os.path.join(scratch1, \"temp_buffer_join\"), \n",
    "                                         \"JOIN_ONE_TO_ONE\", \n",
    "                                         \"KEEP_ALL\", \n",
    "                                         match_option = \"WITHIN\")\n",
    "\n",
    "stream_clip = arcpy.management.Dissolve(os.path.join(scratch1,\"temp_buffer_join\"), \n",
    "                                        os.path.join(scratch1, \"lakes_clip_diss\"), \n",
    "                                        dissolve_field=[\"widest_buffer_width\", \"transfer_code_lakes\"], \n",
    "                                        multi_part= \"MULTI_PART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:08:40 PM\",\"Succeeded at Thursday, March 14, 2024 4:08:45 PM (Elapsed Time: 5.30 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects300_transitions'>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = lake_polys\n",
    "dis = 300\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:13:30 PM\",\"Succeeded at Thursday, March 14, 2024 4:13:36 PM (Elapsed Time: 5.29 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects150_transitions'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = lake_polys\n",
    "dis = 150\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:16:16 PM\",\"Succeeded at Thursday, March 14, 2024 4:16:22 PM (Elapsed Time: 5.36 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects50_transitions'>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = lake_polys\n",
    "dis = 50\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:18:14 PM\",\"Succeeded at Thursday, March 14, 2024 4:18:20 PM (Elapsed Time: 5.32 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects0_transitions'>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = lake_polys\n",
    "dis = 0\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:18:21 PM\",\"Succeeded at Thursday, March 14, 2024 4:18:25 PM (Elapsed Time: 4.60 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transect_transitions_mergeL'>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = True\n",
    "\n",
    "arcpy.management.Merge([os.path.join(scratch1, \"transects300_transitions\"), os.path.join(scratch1, \"transects150_transitions\"), os.path.join(scratch1, \"transects50_transitions\"), os.path.join(scratch1, \"transects0_transitions\")], \n",
    "                      os.path.join(scratch1, \"transect_transitions_mergeL\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Manual edits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Subdivide waterbodies by transects:\n",
    "arcpy.management.FeatureToPolygon(\n",
    "    in_features=\"transect_transitions_mergeL;lake_polys\",\n",
    "    out_feature_class= os.path.join(scratch1,\"lake_polys_FTP\"),\n",
    "    cluster_tolerance=None,\n",
    "    attributes=\"ATTRIBUTES\",\n",
    "    label_features=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:45:37 PM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Thursday, March 14, 2024 4:45:52 PM (Elapsed Time: 15.15 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\lake_polys_split1'>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#That process filled spaces that were not meant to be water\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"lake_polys_FTP\"), \n",
    "                     lake_polys,\n",
    "                     os.path.join(scratch1, \"filled_holes\")\n",
    "                    )\n",
    "\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"lake_polys_FTP\"), \n",
    "                     os.path.join(scratch1, \"filled_holes\"),\n",
    "                     os.path.join(scratch1, \"lake_polys_split1\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:47:05 PM\",\"Succeeded at Thursday, March 14, 2024 4:47:12 PM (Elapsed Time: 7.68 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_Lbuff'>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split stream lines at all polygon divisions, both preexisting in the dataset and from the transects\n",
    "arcpy.analysis.Intersect([os.path.join(scratch1, \"lake_polys_split1\"), stream_clip], \n",
    "                         os.path.join(scratch1, \"temp_split_pts\"), \n",
    "                         output_type = \"POINT\")\n",
    "\n",
    "arcpy.management.SplitLineAtPoint(stream_clip, \n",
    "                                  os.path.join(scratch1, \"temp_split_pts\"),\n",
    "                                  os.path.join(scratch1, \"split_streams_for_Lbuff\"), \n",
    "                                  \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:47:13 PM\",\"Succeeded at Thursday, March 14, 2024 4:47:17 PM (Elapsed Time: 4.42 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_Lbuff_sort'>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Sort(os.path.join(scratch1, \"split_streams_for_Lbuff\"), \n",
    "                      os.path.join(scratch1, \"split_streams_for_Lbuff_sort\"), \n",
    "                      [[\"Shape_Length\", \"DESCENDING\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poly_buffwidth = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"lake_polys_split1\"),\n",
    "                                            os.path.join(scratch1, \"split_streams_for_Lbuff_sort\"), \n",
    "                                            os.path.join(home,\"lake_polys_buffwidth_join\"), \n",
    "                                            match_option = \"CONTAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fill nulls with values of adjacent polygons\n",
    "widths = [300, 150, 50, 0]\n",
    "\n",
    "for i in widths:\n",
    "    arcpy.management.MakeFeatureLayer(poly_buffwidth, \"poly_nulls\", where_clause = \"widest_buffer_width IS NULL\")\n",
    "    arcpy.management.MakeFeatureLayer(poly_buffwidth, f\"{i}_buff\", where_clause = f\"widest_buffer_width = {i}\")\n",
    "    arcpy.management.SelectLayerByLocation(\"poly_nulls\", \"BOUNDARY_TOUCHES\", f\"{i}_buff\")\n",
    "    \n",
    "    input_fc = poly_buffwidth\n",
    "    field_name = \"widest_buffer_width\"\n",
    "\n",
    "    #Make a list from the selected features\n",
    "    oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"poly_nulls\",[\"OID@\"])]\n",
    "    oidfield = arcpy.Describe(input_fc).OIDFieldName\n",
    "    fields = [oidfield, field_name]\n",
    "\n",
    "    #Code features in the list \n",
    "    with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "        for row in curs:\n",
    "            if row[0] in oidList: \n",
    "                row[1] = f\"{i}\"\n",
    "            curs.updateRow(row)\n",
    "    del curs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Estuaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Buffer the remaining polygons that aren't streams, canals/ditches, or the ocean\n",
    "est_polys = arcpy.management.MakeFeatureLayer(nj2015_polys, \"est_polys\", \"FTYPE = 493\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Thursday, March 14, 2024 4:47:52 PM\",\"Assembling Features...\",\"Reading Features...\",\"Cracking Features...\",\"Succeeded at Thursday, March 14, 2024 4:49:47 PM (Elapsed Time: 1 minutes 54 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\stream_est_clip'>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clip streams to lakes so that they will be \"within\"\n",
    "arcpy.analysis.Clip(streams, \n",
    "                    est_polys, \n",
    "                    os.path.join(scratch1, \"stream_est_clip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "input_fc = est_polys\n",
    "field_name = \"transfer_code_est\"\n",
    "\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.management.CalculateField(input_fc,\n",
    "                                         field_name, \n",
    "                                         \"!OBJECTID!\", \n",
    "                                         \"PYTHON3\", '', \n",
    "                                         \"LONG\", \n",
    "                                         \"NO_ENFORCE_DOMAINS\")\n",
    "else:\n",
    "    print(\"Field exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Make dissolved network of same width\n",
    "buffer_join = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"stream_est_clip\"),\n",
    "                                         est_polys, \n",
    "                                         os.path.join(scratch1, \"temp_buffer_join\"), \n",
    "                                         \"JOIN_ONE_TO_ONE\", \n",
    "                                         \"KEEP_ALL\", \n",
    "                                         match_option = \"WITHIN\")\n",
    "\n",
    "stream_clip = arcpy.management.Dissolve(os.path.join(scratch1,\"temp_buffer_join\"), \n",
    "                                        os.path.join(scratch1, \"ests_clip_diss\"), \n",
    "                                        dissolve_field=[\"widest_buffer_width\", \"transfer_code_est\"], \n",
    "                                        multi_part= \"MULTI_PART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:00:29 AM\",\"Succeeded at Friday, March 15, 2024 10:00:33 AM (Elapsed Time: 4.67 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects300_transitions'>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = est_polys\n",
    "dis = 300\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:12:00 AM\",\"Succeeded at Friday, March 15, 2024 10:12:04 AM (Elapsed Time: 4.65 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects150_transitions'>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = est_polys\n",
    "dis = 150\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:12:47 AM\",\"Succeeded at Friday, March 15, 2024 10:12:52 AM (Elapsed Time: 4.59 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects50_transitions'>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = est_polys\n",
    "dis = 50\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:13:32 AM\",\"Succeeded at Friday, March 15, 2024 10:13:37 AM (Elapsed Time: 4.66 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects0_transitions'>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = stream_clip\n",
    "clip_fc = est_polys\n",
    "dis = 0\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_buffer\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"2000 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_buffer\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:13:55 AM\",\"Succeeded at Friday, March 15, 2024 10:14:02 AM (Elapsed Time: 7.06 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transect_transitions_mergeE'>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.addOutputsToMap = True\n",
    "\n",
    "arcpy.management.Merge([os.path.join(scratch1, \"transects300_transitions\"), os.path.join(scratch1, \"transects150_transitions\"), os.path.join(scratch1, \"transects50_transitions\"), os.path.join(scratch1, \"transects0_transitions\")], \n",
    "                      os.path.join(scratch1, \"transect_transitions_mergeE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Manual edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:35:27 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Friday, March 15, 2024 10:35:34 AM (Elapsed Time: 6.35 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\est_polys_FTP'>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Subdivide waterbodies by transects:\n",
    "arcpy.management.FeatureToPolygon(\n",
    "    in_features= [os.path.join(scratch1, \"transect_transitions_mergeE\"),est_polys],\n",
    "    out_feature_class= os.path.join(scratch1,\"est_polys_FTP\"),\n",
    "    cluster_tolerance=None,\n",
    "    attributes=\"ATTRIBUTES\",\n",
    "    label_features=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:36:02 AM\",\"Reading Features...\",\"Cracking Features...\",\"Assembling Features...\",\"Succeeded at Friday, March 15, 2024 10:36:07 AM (Elapsed Time: 4.86 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\est_polys_split1'>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#That process filled spaces that were not meant to be water\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"est_polys_FTP\"), \n",
    "                     est_polys,\n",
    "                     os.path.join(scratch1, \"filled_holes\")\n",
    "                    )\n",
    "\n",
    "arcpy.analysis.Erase(os.path.join(scratch1, \"est_polys_FTP\"), \n",
    "                     os.path.join(scratch1, \"filled_holes\"),\n",
    "                     os.path.join(scratch1, \"est_polys_split1\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:36:36 AM\",\"Succeeded at Friday, March 15, 2024 10:36:43 AM (Elapsed Time: 7.32 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_Lbuff'>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split stream lines at all polygon divisions, both preexisting in the dataset and from the transects\n",
    "arcpy.analysis.Intersect([os.path.join(scratch1, \"est_polys_split1\"), stream_clip], \n",
    "                         os.path.join(scratch1, \"temp_split_pts\"), \n",
    "                         output_type = \"POINT\")\n",
    "\n",
    "arcpy.management.SplitLineAtPoint(stream_clip, \n",
    "                                  os.path.join(scratch1, \"temp_split_pts\"),\n",
    "                                  os.path.join(scratch1, \"split_streams_for_Ebuff\"), \n",
    "                                  \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:39:07 AM\",\"Succeeded at Friday, March 15, 2024 10:39:13 AM (Elapsed Time: 5.75 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_Ebuff'>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.SplitLineAtPoint(stream_clip, \n",
    "                                  os.path.join(scratch1, \"temp_split_pts\"),\n",
    "                                  os.path.join(scratch1, \"split_streams_for_Ebuff\"), \n",
    "                                  \"5 feet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Friday, March 15, 2024 10:39:14 AM\",\"Succeeded at Friday, March 15, 2024 10:39:18 AM (Elapsed Time: 3.97 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\split_streams_for_Ebuff_sort'>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.Sort(os.path.join(scratch1, \"split_streams_for_Ebuff\"), \n",
    "                      os.path.join(scratch1, \"split_streams_for_Ebuff_sort\"), \n",
    "                      [[\"Shape_Length\", \"DESCENDING\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "poly_buffwidth = arcpy.analysis.SpatialJoin(os.path.join(scratch1, \"est_polys_split1\"),\n",
    "                                            os.path.join(scratch1, \"split_streams_for_Ebuff_sort\"), \n",
    "                                            os.path.join(home,\"est_polys_buffwidth_join\"), \n",
    "                                            match_option = \"CONTAINS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Fill nulls with values of adjacent polygons\n",
    "widths = [300, 150, 50, 0]\n",
    "\n",
    "for i in widths:\n",
    "    arcpy.management.MakeFeatureLayer(poly_buffwidth, \"poly_nulls\", where_clause = \"widest_buffer_width IS NULL\")\n",
    "    arcpy.management.MakeFeatureLayer(poly_buffwidth, f\"{i}_buff\", where_clause = f\"widest_buffer_width = {i}\")\n",
    "    arcpy.management.SelectLayerByLocation(\"poly_nulls\", \"BOUNDARY_TOUCHES\", f\"{i}_buff\")\n",
    "    \n",
    "    input_fc = poly_buffwidth\n",
    "    field_name = \"widest_buffer_width\"\n",
    "\n",
    "    #Make a list from the selected features\n",
    "    oidList = [oid[0] for oid in arcpy.da.SearchCursor(\"poly_nulls\",[\"OID@\"])]\n",
    "    oidfield = arcpy.Describe(input_fc).OIDFieldName\n",
    "    fields = [oidfield, field_name]\n",
    "\n",
    "    #Code features in the list \n",
    "    with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "        for row in curs:\n",
    "            if row[0] in oidList: \n",
    "                row[1] = f\"{i}\"\n",
    "            curs.updateRow(row)\n",
    "    del curs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Code features in the list \n",
    "\n",
    "oidList = [324, 346, 884]\n",
    "\n",
    "input_fc = poly_buffwidth\n",
    "field_name = \"widest_buffer_width\"\n",
    "fields = [oidfield, field_name]\n",
    "\n",
    "with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "    for row in curs:\n",
    "        if row[0] in oidList: \n",
    "            row[1] = 50\n",
    "        curs.updateRow(row)\n",
    "del curs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Combine Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Merge ND, Delaware, Lakes, Estuaries\n",
    "all_polys = arcpy.management.Merge([os.path.join(home,\"stream_polys_buffwidth_join\"), os.path.join(home,\"stream_polys_buffwidth_joinD\"), os.path.join(home,\"lake_polys_buffwidth_join\"), os.path.join(home,\"est_polys_buffwidth_join\")], \n",
    "                                  os.path.join(scratch1, \"all_polybuffwidth_merge\"))#classified_polys_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_polys = os.path.join(scratch1, \"all_polybuffwidth_merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Code features in the list \n",
    "\n",
    "# oidList = [33610, 33611]\n",
    "\n",
    "# input_fc = os.path.join(scratch1, \"all_polybuffwidth_merge\")\n",
    "# field_name = \"widest_buffer_width\"\n",
    "# fields = ['OBJECTID', field_name]\n",
    "\n",
    "# with arcpy.da.UpdateCursor(input_fc, fields) as curs:\n",
    "#     for row in curs:\n",
    "#         if row[0] in oidList: \n",
    "#             row[1] = 0\n",
    "#         curs.updateRow(row)\n",
    "# del curs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_poly_diss = arcpy.management.Dissolve(in_features = all_polys, \n",
    "                          out_feature_class = os.path.join(home, \"all_polybuffwidth_diss\"), \n",
    "                          dissolve_field = \"widest_buffer_width\", \n",
    "                          multi_part = \"SINGLE_PART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "non_null = arcpy.management.MakeFeatureLayer(all_poly_diss, \"polys_non_null\", where_clause = \"widest_buffer_width > 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Buffer and dissolve by buffer width\n",
    "polys_buff = arcpy.analysis.Buffer(non_null, \n",
    "                      os.path.join(scratch1, \"Final_buffer_polygons\"),\n",
    "                      buffer_distance_or_field = \"widest_buffer_width\",\n",
    "                      dissolve_option = \"LIST\",\n",
    "                      dissolve_field = [\"widest_buffer_width\"]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Centerline buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "streams1 = arcpy.management.MakeFeatureLayer(os.path.join(home, \"FHA_RiparianZones_20240308_160842\"), \"stream_classes_lyr\") #exclude coastlines \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#buffer centerlines\n",
    "centerlines_buff = arcpy.analysis.Buffer(\"stream_classes_lyr\", \n",
    "                                         os.path.join(scratch1, \"Final_buffer_centerlines\"), \n",
    "                                         buffer_distance_or_field = \"widest_buffer_width\", \n",
    "                                         line_end_type=\"ROUND\", \n",
    "                                         dissolve_option=\"LIST\",\n",
    "                                         dissolve_field = \"widest_buffer_width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys_buff = os.path.join(scratch1, \"Final_buffer_polygons\")\n",
    "centerlines_buff = os.path.join(scratch1, \"Final_buffer_centerlines\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge and Dissolve centerline and waterbodies buffers\n",
    "\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "allbuff = arcpy.management.Merge([polys_buff, centerlines_buff], \n",
    "                                 os.path.join(home,f\"FHA_buffers_merge{timestr}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20240318_164834'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 18, 2024 5:04:26 PM\",\"Sorting Attributes...\",\"Dissolving...\",\"Succeeded at Monday, March 18, 2024 5:46:04 PM (Elapsed Time: 41 minutes 38 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_buffers_20240318_164834'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dissolve by buffer width\n",
    "arcpy.management.Dissolve(allbuff, \n",
    "                          os.path.join(home,f\"FHA_buffers_{timestr}\"),\n",
    "                          dissolve_field=\"widest_buffer_width\", \n",
    "                          multi_part = \"SINGLE_PART\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Trim ends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "streams = arcpy.management.MakeFeatureLayer(os.path.join(home, \"FHA_RiparianZones_20240308_160842\"), \"streams_lyr\") #, \"FTYPE <> 566\") #exclude coastlines\n",
    "buffs = os.path.join(home,f\"FHA_buffers_{timestr}\")\n",
    "\n",
    "#nj2015_polys = r'X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\Hydr_NHD_2015.gdb\\Hydr_NHD_2015\\Hydr_NHD_2015_waterbody'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 18, 2024 4:20:43 PM\",\"Succeeded at Monday, March 18, 2024 4:20:52 PM (Elapsed Time: 8.61 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\scratch1.gdb\\\\transects300_transitions'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arcpy.env.addOutputsToMap = False\n",
    "\n",
    "input_fc = streams\n",
    "dis = 300\n",
    "clip_fc = arcpy.management.MakeFeatureLayer(buffs, f\"{dis}ft_buffer\", f\"widest_buffer_width = {dis}\")\n",
    "\n",
    "####\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"{dis}ft_stream\", f\"widest_buffer_width = {dis}\")\n",
    "end_pts = arcpy.management.FeatureVerticesToPoints(f\"{dis}ft_stream\", os.path.join(scratch1, \"TM_end_pts\"), 'END')\n",
    "buffs_invert = arcpy.management.MakeFeatureLayer(buffs, f\"{dis}ft_buffer\", f\"widest_buffer_width <> {dis}\")\n",
    "\n",
    "arcpy.management.GenerateTransectsAlongLines(\n",
    "    in_features= f\"{dis}ft_stream\",\n",
    "    out_feature_class=os.path.join(scratch1,f\"Transects_{dis}ft\"),\n",
    "    interval=\"30000 Feet\",\n",
    "    transect_length=\"600 Feet\",\n",
    "    include_ends=\"END_POINTS\"\n",
    ")\n",
    "\n",
    "arcpy.analysis.Clip(os.path.join(scratch1,f\"Transects_{dis}ft\"), \n",
    "                    clip_fc, \n",
    "                    os.path.join(scratch1, f\"transects_clip{dis}\"))\n",
    "\n",
    "#Multipart to singlepart\n",
    "arcpy.management.MultipartToSinglepart(os.path.join(scratch1, f\"transects_clip{dis}\"), os.path.join(scratch1, f\"transects_clip{dis}_SP\"))\n",
    "\n",
    "#Select and retain only the transect at transitions between riparian widths\n",
    "arcpy.management.MakeFeatureLayer(os.path.join(scratch1, f\"transects_clip{dis}_SP\"), f\"transects_{dis}\")\n",
    "arcpy.management.MakeFeatureLayer(input_fc, f\"non_{dis}\", f\"widest_buffer_width <> {dis}\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"{dis}ft_stream\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", f\"non_{dis}\", selection_type = \"SUBSET_SELECTION\")\n",
    "arcpy.management.SelectLayerByLocation(f\"transects_{dis}\", \"INTERSECT\", end_pts, selection_type = \"SUBSET_SELECTION\")\n",
    "\n",
    "\n",
    "arcpy.management.CopyFeatures(f\"transects_{dis}\", os.path.join(scratch1, f\"transects{dis}_transitions\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Reconcile conflicts where buffers of different widths overlap\n",
    "#Create dupe id field\n",
    "input_fc\n",
    "field_name = \"DuplicateID\"\n",
    "if len(arcpy.ListFields(input_fc, field_name)) == 0:\n",
    "         arcpy.management.CalculateField(input_fc, field_name, \"!OBJECTID!\", field_type = \"LONG\")\n",
    "else:\n",
    "    print(\"Field exists\")\n",
    "\n",
    "#Feature to polygon transects and each width\n",
    "arcpy.management.FeatureToPolygon(\n",
    "    in_features=\"transect_transitions_mergeL;lake_polys\",\n",
    "    out_feature_class= os.path.join(scratch1,\"lake_polys_FTP\"),\n",
    "    cluster_tolerance=None,\n",
    "    attributes=\"ATTRIBUTES\",\n",
    "    label_features=None\n",
    ")\n",
    "\n",
    "#Multipart to singlepart\n",
    "#Sort by area\n",
    "#delete identical dupe id field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 18, 2024 5:46:05 PM\",\"WARNING 000986: C:\\\\Users\\\\kdd56\\\\AppData\\\\Local\\\\Temp\\\\ArcGISProTemp1756\\\\FHA_buffers_merge20240318_1648340.txt contains the full list of non simple features.\",\"WARNING 000461: Repaired feature 4 because of self intersections\",\"WARNING 000461: Repaired feature 5 because of self intersections\",\"WARNING 000461: Repaired feature 6 because of self intersections\",\"WARNING 003598: Updated feature class extent.\",\"Succeeded at Monday, March 18, 2024 6:45:19 PM (Elapsed Time: 59 minutes 13 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_buffers_merge20240318_164834'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.RepairGeometry(allbuff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 18, 2024 6:45:20 PM\",\"Reading Features...\",\"Processing Tiles...\",\"Assembling Tile Features...\",\"Succeeded at Monday, March 18, 2024 6:59:15 PM (Elapsed Time: 13 minutes 55 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_buffers_erase20240318_164834'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.analysis.Erase(os.path.join(home,f\"FHA_buffers_{timestr}\"), \n",
    "                    os.path.join(home, \"lulc_exclusions_diss\"),\n",
    "                    os.path.join(home,f\"FHA_buffers_erase{timestr}\")\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FHA_buffers_erase20240318_164834\n"
     ]
    }
   ],
   "source": [
    "print(f\"FHA_buffers_erase{timestr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up fields and field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffs = os.path.join(home,f\"FHA_buffers_erase{timestr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Monday, March 18, 2024 6:59:21 PM\",\"Succeeded at Monday, March 18, 2024 6:59:24 PM (Elapsed Time: 3.24 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_buffers_erase20240318_164834'>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean up of fields, rename and give aliases\n",
    "arcpy.management.AlterField(buffs, 'widest_buffer_width', new_field_alias = 'Widest Applicable Buffer')\n",
    "\n",
    "#Shape field\n",
    "arcpy.management.AlterField(buffs, \"Shape_Length\", '', \"Lenth (ft)\")\n",
    "arcpy.management.AlterField(buffs, \"Shape_Area\", '', \"Area (sq ft)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = \"20240318_164834\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, March 19, 2024 9:25:19 AM\",\"Succeeded at Tuesday, March 19, 2024 9:26:39 AM (Elapsed Time: 1 minutes 19 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_buffers_erase20240318_164834a'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.EliminatePolygonPart(\n",
    "    in_features=os.path.join(home, f\"FHA_buffers_erase{timestr}\"),\n",
    "    out_feature_class= os.path.join(home, f\"FHA_buffers_erase{timestr}a\"),\n",
    "    condition=\"AREA\",\n",
    "    part_area=\"60000 SquareFeetUS\",\n",
    "    part_area_percent=5,\n",
    "    part_option=\"CONTAINED_ONLY\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, March 19, 2024 9:39:30 AM\",\"WARNING 000986: C:\\\\Users\\\\kdd56\\\\AppData\\\\Local\\\\Temp\\\\ArcGISProTemp3152\\\\FHA_buffers_erase20240318_164834a0.txt contains the full list of non simple features.\",\"WARNING 000461: Repaired feature 806 because of self intersections\",\"WARNING 000461: Repaired feature 1050 because of self intersections\",\"WARNING 000461: Repaired feature 1165 because of self intersections\",\"WARNING 000461: Repaired feature 1557 because of self intersections\",\"WARNING 000461: Repaired feature 1753 because of self intersections\",\"WARNING 000461: Repaired feature 3210 because of self intersections\",\"WARNING 000461: Repaired feature 3642 because of self intersections\",\"WARNING 000461: Repaired feature 3711 because of self intersections\",\"WARNING 000461: Repaired feature 3726 because of self intersections\",\"WARNING 003598: Updated feature class extent.\",\"Succeeded at Tuesday, March 19, 2024 9:44:39 AM (Elapsed Time: 5 minutes 9 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_buffers_erase20240318_164834a'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.RepairGeometry(os.path.join(home, f\"FHA_buffers_erase{timestr}a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, March 19, 2024 9:44:40 AM\",\"Dissolving...\",\"Succeeded at Tuesday, March 19, 2024 10:17:08 AM (Elapsed Time: 32 minutes 28 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\RiparianZones_20240109.gdb\\\\FHA_buffers_20240318_164834_dissolved'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dissolve by buffer width\n",
    "arcpy.management.Dissolve(#buffs, \n",
    "                          os.path.join(home, f\"FHA_buffers_erase{timestr}a\"),\n",
    "                          os.path.join(home,f\"FHA_buffers_{timestr}_dissolved\"),\n",
    "                          multi_part = \"SINGLE_PART\"\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDB exists\n"
     ]
    }
   ],
   "source": [
    "# Set local variables\n",
    "out_folder_path = r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\"\n",
    "out_name = \"FHARiparianZoneMaps_20240319.gdb\"\n",
    "fmaps = os.path.join(out_folder_path, out_name)\n",
    "\n",
    "if arcpy.Exists(fmaps):\n",
    "    print(\"GDB exists\")\n",
    "else: \n",
    "    print(\"Creating GDB\")\n",
    "    # Execute CreateFileGDB\n",
    "    arcpy.CreateFileGDB_management(out_folder_path, out_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, March 19, 2024 10:18:10 AM\",\"Succeeded at Tuesday, March 19, 2024 10:18:46 AM (Elapsed Time: 36.32 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'X:\\\\projects\\\\njwrap\\\\Task_2\\\\task2a_Regulatory_buffers\\\\RiparianZones_20240109\\\\FHARiparianZoneMaps_20240319.gdb\\\\C_FHA_BuffersDissolved_20240319'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copy final maps to fresh gdb\n",
    "fdate = \"20240319\"\n",
    "\n",
    "#lines\n",
    "arcpy.management.CopyFeatures(os.path.join(home, \"FHA_RiparianZones_20240308_160842\"), os.path.join(fmaps, f\"A_FHA_Lines_{fdate}\"))\n",
    "\n",
    "#Polygons\n",
    "arcpy.management.CopyFeatures(s.path.join(home, \"all_polybuffwidth_diss\"), os.path.join(fmaps, f\"B_FHA_Polygons_{fdate}\"))\n",
    "\n",
    "#Buffers by width\n",
    "arcpy.management.CopyFeatures(os.path.join(home, f\"FHA_buffers_erase{timestr}a\"), os.path.join(fmaps, f\"C_FHA_Buffers_{fdate}\"))\n",
    "\n",
    "#Buffers Dissolved\n",
    "arcpy.management.CopyFeatures(os.path.join(home,f\"FHA_buffers_{timestr}_dissolved\"), os.path.join(fmaps, f\"D_FHA_BuffersDissolved_{fdate}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class='gpresult'><h2>Messages</h2><div id='messages' data-messages='[\"Start Time: Tuesday, March 19, 2024 1:52:38 PM\",\"Succeeded at Tuesday, March 19, 2024 1:52:50 PM (Elapsed Time: 11.14 seconds)\"]' data-show='true'><div id = 'default' /></div></div>"
      ],
      "text/plain": [
       "<Result 'B_FHA_Polygons_20240319'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.management.ApplySymbologyFromLayer(\n",
    "    in_layer=os.path.join(fmaps, f\"C_FHA_Buffers_{fdate}\"),\n",
    "    in_symbology_layer=r\"X:\\projects\\njwrap\\Task_2\\task2a_Regulatory_buffers\\RiparianZones_20240109\\FHA_Buffers_PairedColors.lyrx\",\n",
    "    symbology_fields=\"VALUE_FIELD widest_buffer_width widest_buffer_width\",\n",
    "    update_symbology=\"DEFAULT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Create visualization\n",
    "https://loading.io/color/feature/Paired-12/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Set symbology\n",
    "#Share > Save as Layer\n",
    "#Apply symbology from layer (Data Management Tool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
